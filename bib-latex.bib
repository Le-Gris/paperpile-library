@ARTICLE{Gandhi2021-hw,
  title         = "Baby {{Intuitions Benchmark}} ({{{BIB}})}: {{Discerning}}
                   the Goals, Preferences, and Actions of Others",
  author        = "Gandhi, Kanishk and Stojnic, Gala and Lake, Brenden M and
                   Dillon, Moira R",
  journal       = "CoRR",
  volume        = "abs/2102.11938",
  year          =  2021,
  keywords      = "Computer Science - Artificial Intelligence,Computer Science
                   - Machine Learning;comp-cog-sci",
  archivePrefix = "arXiv",
  eprint        = "2102.11938",
  arxivid       = "2102.11938"
}

@MISC{Goyal2021-ki,
  title         = "Inductive {{Biases}} for {{Deep Learning}} of
                   {{{Higher-Level} Cognition}}",
  author        = "Goyal, Anirudh and Bengio, Yoshua",
  abstract      = "A fascinating hypothesis is that human and animal
                   intelligence could be explained by a few principles (rather
                   than an encyclopedic list of heuristics). If that hypothesis
                   was correct, we could more easily both understand our own
                   intelligence and build intelligent machines. Just like in
                   physics, the principles themselves would not be sufficient
                   to predict the behavior of complex systems like brains, and
                   substantial computation might be needed to simulate
                   human-like intelligence. This hypothesis would suggest that
                   studying the kind of inductive biases that humans and
                   animals exploit could help both clarify these principles and
                   provide inspiration for AI research and neuroscience
                   theories. Deep learning already exploits several key
                   inductive biases, and this work considers a larger list,
                   focusing on those which concern mostly higher-level and
                   sequential conscious processing. The objective of clarifying
                   these particular principles is that they could potentially
                   help us build AI systems benefiting from humans' abilities
                   in terms of flexible out-of-distribution and systematic
                   generalization, which is currently an area where a large gap
                   exists between state-of-the-art machine learning and human
                   intelligence.",
  journal       = "arXiv [cs, stat]",
  publisher     = "arXiv",
  number        = "arXiv:2011.15091",
  month         =  feb,
  year          =  2021,
  keywords      = "Computer Science - Artificial Intelligence,Computer Science
                   - Machine Learning,Statistics - Machine
                   Learning;comp-cog-sci;machine-learning",
  archivePrefix = "arXiv",
  eprint        = "2011.15091",
  primaryClass  = "cs, stat",
  arxivid       = "2011.15091"
}

@UNPUBLISHED{Grosse2012-pf,
  title    = "Exploiting Compositionality to Explore a Large Space of Model
              Structures",
  author   = "Grosse, Roger and Salakhutdinov, Ruslan R and Freeman, William T
              and Tenenbaum, Joshua B",
  abstract = "The recent proliferation of richly structured probabilistic
              models raises the question of how to automatically determine an
              appropriate model for a dataset. We investigate this question for
              a space of matrix decomposition models which can express a
              variety of widely used models from unsupervised learning. To
              enable model selection, we organize these models into a
              context-free grammar which generates a wide variety of structures
              through the compositional application of a few simple rules. We
              use our grammar to generically and efficiently infer latent
              components and estimate predictive likelihood for nearly 2500
              structures using a small toolbox of reusable algorithms. Using a
              greedy search over our grammar, we automatically choose the
              decomposition structure from raw data by evaluating only a small
              fraction of all models. The proposed method typically finds the
              correct structure for synthetic data and backs off gracefully to
              simpler models under heavy noise. It learns sensible structures
              for datasets as diverse as image patches, motion capture, 20
              Questions, and U.S. Senate votes, all using exactly the same
              code.",
  month    =  oct,
  year     =  2012,
  keywords = "Computer Science - Machine Learning,Statistics - Machine
              Learning;comp-cog-sci"
}

@UNPUBLISHED{Johnson2021-mw,
  title    = "Fast and Flexible: {{Human}} Program Induction in Abstract
              Reasoning Tasks",
  author   = "Johnson, Aysja and Vong, Wai Keen and Lake, Brenden M and
              Gureckis, Todd M",
  abstract = "The Abstraction and Reasoning Corpus (ARC) is a challenging
              program induction dataset that was recently proposed by Chollet
              (2019). Here, we report the first set of results collected from a
              behavioral study of humans solving a subset of tasks from ARC (40
              out of 1000). Although this subset of tasks contains considerable
              variation, our results showed that humans were able to infer the
              underlying program and generate the correct test output for a
              novel test input example, with an average of 80\% of tasks solved
              per participant, and with 65\% of tasks being solved by more than
              80\% of participants. Additionally, we find interesting patterns
              of behavioral consistency and variability within the action
              sequences during the generation process, the natural language
              descriptions to describe the transformations for each task, and
              the errors people made. Our findings suggest that people can
              quickly and reliably determine the relevant features and
              properties of a task to compose a correct solution. Future
              modeling work could incorporate these findings, potentially by
              connecting the natural language descriptions we collected here to
              the underlying semantics of ARC.",
  month    =  mar,
  year     =  2021,
  keywords = "Computer Science - Artificial Intelligence,Computer Science -
              Human-Computer Interaction,Computer Science - Machine
              Learning;read;comp-cog-sci;ARC Project"
}

@UNPUBLISHED{Lake2016-zm,
  title    = "Building {{Machines That Learn}} and {{Think Like People}}",
  author   = "Lake, Brenden M and Ullman, Tomer D and Tenenbaum, Joshua B and
              Gershman, Samuel J",
  abstract = "Recent progress in artificial intelligence (AI) has renewed
              interest in building systems that learn and think like people.
              Many advances have come from using deep neural networks trained
              end-to-end in tasks such as object recognition, video games, and
              board games, achieving performance that equals or even beats
              humans in some respects. Despite their biological inspiration and
              performance achievements, these systems differ from human
              intelligence in crucial ways. We review progress in cognitive
              science suggesting that truly human-like learning and thinking
              machines will have to reach beyond current engineering trends in
              both what they learn, and how they learn it. Specifically, we
              argue that these machines should (a) build causal models of the
              world that support explanation and understanding, rather than
              merely solving pattern recognition problems; (b) ground learning
              in intuitive theories of physics and psychology, to support and
              enrich the knowledge that is learned; and (c) harness
              compositionality and learning-to-learn to rapidly acquire and
              generalize knowledge to new tasks and situations. We suggest
              concrete challenges and promising routes towards these goals that
              can combine the strengths of recent neural network advances with
              more structured cognitive models.",
  month    =  nov,
  year     =  2016,
  keywords = "Computer Science - Artificial Intelligence,Computer Science -
              Computer Vision and Pattern Recognition,Computer Science -
              Machine Learning,Computer Science - Neural and Evolutionary
              Computing,Statistics - Machine Learning;comp-cog-sci"
}

@UNPUBLISHED{Lake2019-dt,
  title    = "Compositional Generalization through Meta {Sequence-to-Sequence}
              Learning",
  author   = "Lake, Brenden M",
  abstract = "People can learn a new concept and use it compositionally,
              understanding how to ``blicket twice'' after learning how to
              ``blicket.'' In contrast, powerful sequence-tosequence (seq2seq)
              neural networks fail such tests of compositionality, especially
              when composing new concepts together with existing concepts. In
              this paper, I show how memory-augmented neural networks can be
              trained to generalize compositionally through meta seq2seq
              learning. In this approach, models train on a series of seq2seq
              problems to acquire the compositional skills needed to solve new
              seq2seq problems. Meta se2seq learning solves several of the SCAN
              tests for compositional learning and can learn to apply implicit
              rules to variables.",
  month    =  oct,
  year     =  2019,
  keywords = "Computer Science - Artificial Intelligence,Computer Science -
              Computation and Language,Computer Science - Machine
              Learning;comp-cog-sci"
}

@UNPUBLISHED{Lake2019-ng,
  title    = "Human {Few-Shot} Learning of Compositional Instructions",
  author   = "Lake, Brenden M and Linzen, Tal and Baroni, Marco",
  abstract = "People learn in fast and flexible ways that have not been
              emulated by machines. Once a person learns a new verb ``dax,'' he
              or she can effortlessly understand how to ``dax twice,'' ``walk
              and dax,'' or ``dax vigorously.'' There have been striking recent
              improvements in machine learning for natural language processing,
              yet the best algorithms require vast amounts of experience and
              struggle to generalize new concepts in compositional ways. To
              better understand these distinctively human abilities, we study
              the compositional skills of people through languagelike
              instruction learning tasks. Our results show that people can
              learn and use novel functional concepts from very few examples
              (few-shot learning), successfully applying familiar functions to
              novel inputs. People can also compose concepts in complex ways
              that go beyond the provided demonstrations. Two additional
              experiments examined the assumptions and inductive biases that
              people make when solving these tasks, revealing three biases:
              mutual exclusivity, one-to-one mappings, and iconic
              concatenation. We discuss the implications for cognitive modeling
              and the potential for building machines with more human-like
              language learning capabilities.",
  month    =  may,
  year     =  2019,
  keywords = "Computer Science - Computation and Language;comp-cog-sci"
}

@UNPUBLISHED{Mao2019-ht,
  title    = "The {{{Neuro-Symbolic} Concept Learner}}: {{Interpreting
              Scenes}}, {{Words}}, and {{Sentences From Natural Supervision}}",
  author   = "Mao, Jiayuan and Gan, Chuang and Kohli, Pushmeet and Tenenbaum,
              Joshua B and Wu, Jiajun",
  abstract = "We propose the Neuro-Symbolic Concept Learner (NS-CL), a model
              that learns visual concepts, words, and semantic parsing of
              sentences without explicit supervision on any of them; instead,
              our model learns by simply looking at images and reading paired
              questions and answers. Our model builds an object-based scene
              representation and translates sentences into executable, symbolic
              programs. To bridge the learning of two modules, we use a
              neuro-symbolic reasoning module that executes these programs on
              the latent scene representation. Analogical to human concept
              learning, the perception module learns visual concepts based on
              the language description of the object being referred to.
              Meanwhile, the learned visual concepts facilitate learning new
              words and parsing new sentences. We use curriculum learning to
              guide the searching over the large compositional space of images
              and language. Extensive experiments demonstrate the accuracy and
              efficiency of our model on learning visual concepts, word
              representations, and semantic parsing of sentences. Further, our
              method allows easy generalization to new object attributes,
              compositions, language concepts, scenes and questions, and even
              new program domains. It also empowers applications including
              visual question answering and bidirectional image-text retrieval.",
  month    =  apr,
  year     =  2019,
  keywords = "Computer Science - Artificial Intelligence,Computer Science -
              Computation and Language,Computer Science - Computer Vision and
              Pattern Recognition,Computer Science - Machine
              Learning;skimmed;comp-cog-sci"
}

@UNPUBLISHED{Peterson2016-lj,
  title    = "Adapting {{Deep Network Features}} to {{Capture Psychological
              Representations}}",
  author   = "Peterson, Joshua C and Abbott, Joshua T and Griffiths, Thomas L",
  abstract = "Deep neural networks have become increasingly successful at
              solving classic perception problems such as object recognition,
              semantic segmentation, and scene understanding, often reaching or
              surpassing human-level accuracy. This success is due in part to
              the ability of DNNs to learn useful representations of
              high-dimensional inputs, a problem that humans must also solve.
              We examine the relationship between the representations learned
              by these networks and human psychological representations
              recovered from similarity judgments. We find that deep features
              learned in service of object classification account for a
              significant amount of the variance in human similarity judgments
              for a set of animal images. However, these features do not
              capture some qualitative distinctions that are a key part of
              human representations. To remedy this, we develop a method for
              adapting deep features to align with human similarity judgments,
              resulting in image representations that can potentially be used
              to extend the scope of psychological experiments.",
  month    =  aug,
  year     =  2016,
  keywords = "Computer Science - Artificial Intelligence,Computer Science -
              Computer Vision and Pattern Recognition,Computer Science - Neural
              and Evolutionary Computing;read;comp-cog-sci;ccm2023"
}

@UNPUBLISHED{Rezende2016-ge,
  title    = "{One-{{Shot} Generalization}} in {{Deep Generative Models}}",
  author   = "Rezende, Danilo Jimenez and Mohamed, Shakir and Danihelka, Ivo
              and Gregor, Karol and Wierstra, Daan",
  abstract = "Humans have an impressive ability to reason about new concepts
              and experiences from just a single example. In particular, humans
              have an ability for one-shot generalization: an ability to
              encounter a new concept, understand its structure, and then be
              able to generate compelling alternative variations of the
              concept. We develop machine learning systems with this important
              capacity by developing new deep generative models, models that
              combine the representational power of deep learning with the
              inferential power of Bayesian reasoning. We develop a class of
              sequential generative models that are built on the principles of
              feedback and attention. These two characteristics lead to
              generative models that are among the state-of-the art in density
              estimation and image generation. We demonstrate the one-shot
              generalization ability of our models using three tasks:
              unconditional sampling, generating new exemplars of a given
              concept, and generating new exemplars of a family of concepts. In
              all cases our models are able to generate compelling and diverse
              samples---having seen new examples just once---providing an
              important class of general-purpose models for one-shot machine
              learning.",
  month    =  may,
  year     =  2016,
  keywords = "Computer Science - Artificial Intelligence,Computer Science -
              Machine Learning,Statistics - Machine Learning;machine-learning"
}

@UNPUBLISHED{Shultz2021-hq,
  title    = "A {{Computational Model}} of {{Infant Learning}} and
              {{Reasoning}} with {{Probabilities}}",
  author   = "Shultz, Thomas R and Nobandegani, Ardavan S",
  abstract = "Recent experiments reveal that 6- to 12-month-old infants can
              learn probabilities and reason with them. In this work, we
              present a novel computational system called Neural Probability
              Learner and Sampler (NPLS) that learns and reasons with
              probabilities, providing a computationally sufficient mechanism
              to explain infant probabilistic learning and inference. In 24
              computer simulations, NPLS simulations show how probability
              distributions can emerge naturally from neural-network learning
              of event sequences, providing a novel explanation of infant
              probabilistic learning and reasoning. Three mathematical proofs
              show how and why NPLS simulates the infant results so accurately.
              The results are situated in relation to seven other active
              research lines. This work provides an effective way to integrate
              Bayesian and neural-network approaches to cognition.",
  month    =  jun,
  year     =  2021,
  keywords = "Quantitative Biology - Neurons and
              Cognition;comp-cog-sci;development"
}

@TECHREPORT{Smolensky2022-ts,
  title       = "Neurocompositional Computing in Human and Machine
                 Intelligence: {{A}} Tutorial",
  author      = "Smolensky, Paul and McCoy, R Thomas and Fernandez, Roland and
                 Goldrick, Matthew and Gao, Jianfeng",
  abstract    = "The past decade has produced a revolution in Artificial
                 Intelligence (AI), after a half-century of AI repeatedly
                 failing to meet expectations. What explains the dramatic
                 change from 20th-century to 21st-century AI, and how can
                 remaining limitations of current AI be overcome? Until now,
                 the widely accepted narrative has attributed the recent
                 progress in AI to technical engineering advances that have
                 yielded massive increases in the quantity of computational
                 resources and training data available to support statistical
                 learning in deep artificial neural networks. Although these
                 quantitative engineering innovations are important, here we
                 show that the latest advances in AI are not solely due to
                 quantitative increases in computing power but also qualitative
                 changes in how that computing power is deployed. These
                 qualitative changes have brought about a new type of computing
                 that we call neurocompositional computing. In
                 neurocompositional computing, neural networks exploit two
                 scientific principles that contemporary theory in cognitive
                 science maintains are simultaneously necessary to enable
                 human-level cognition. The Compositionality Principle asserts
                 that encodings of complex information are structures that are
                 systematically composed from simpler structured encodings. The
                 Continuity Principle states that the encoding and processing
                 of information is formalized with real numbers that vary
                 continuously. These principles have seemed irreconcilable
                 until the recent mathematical discovery that compositionality
                 can be realized not only through the traditional discrete
                 methods of symbolic computing, well developed in 20th-century
                 AI, but also through novel forms of continuous neural
                 computing---neurocompositional computing. The unprecedented
                 progress of 21st-century AI has resulted from the use of
                 limited---first-generation---forms of neurocompositional
                 computing. We show that the new techniques now being deployed
                 in second-generation neurocompositional computing create AI
                 systems that are not only more robust and accurate than
                 current systems, but also more comprehensible---making it
                 possible to diagnose errors in, and exert human control over,
                 artificial neural networks through interpretation of their
                 internal states and direct intervention upon those states.
                 Note: This tutorial is intended for those new to this topic,
                 and does not assume familiarity with cognitive science, AI, or
                 deep learning. Appendices provide more advanced material. Each
                 figure, and the associated box explaining it, provides an
                 exposition, illustration, or further details of a main point
                 of the paper; in order to make these figures relatively
                 self-contained, it has sometimes been necessary to repeat some
                 material from the text. For a brief introduction and
                 additional development of some of this material see
                 ``Neurocompositional computing: From the central paradox of
                 cognition to a new generation of ai systems''
                 (arXiv:2205.01128; to appear, AI Magazine)",
  institution = "Microsoft",
  month       =  may,
  year        =  2022,
  keywords    = "read;comp-cog-sci"
}

@ARTICLE{Wellman_undated-aj,
  title    = "Cognitive {{Development}}: {{Foundational Theories}} of {{Core
              Domains}}",
  author   = "Wellman, Henry M and Gelman, Susan A",
  pages    = "39",
  keywords = "development"
}

@ARTICLE{Mahowald1991-jj,
  title    = "The {{Silicon Retina}}",
  author   = "Mahowald, Misha A and Mead, Carver",
  journal  = "Sci. Am.",
  pages    = "9",
  year     =  1991,
  keywords = "comp-cog-sci",
  issn     = "0036-8733"
}

@BOOK{Minsky1988-bi,
  title     = "Perceptrons: Expanded Edition",
  author    = "Minsky, Marvin L and Papert, Seymour A",
  publisher = "MIT press",
  year      =  1988,
  keywords  = "comp-cog-sci",
  isbn      = "9780262631112"
}

@MISC{noauthor_undated-xy,
  title        = "Efficient Inverse Graphics in Biological Face Processing |
                  {{Science Advances}}",
  howpublished = "\url{https://advances.sciencemag.org/content/6/10/eaax5979/tab-pdf?__cf_chl_jschl_tk__=7edc4ca4dbf68389fcff61bcb4f9b2933065972f-1626234016-0-AUXGIGlyGqNMVHJhjRyQlw9DOb7_Nsxa5__OpC2K69M9D8q3ft1l8LC648BjbyZssjf1qXDRh9heKB23bAUqhMchMuBuTHxr1gBzgLl0YZz-fvX_BbIfEdkuGqgS2wIQwcCLXUhX7Vuu9lepXXTiDRdqgoBR_3HgolzgHQ6iOR88SOt_HkomiuuG19xpy9eHwbtkXyxVeuqVct2S5FKj2c_gF7JoxpOsDzMQ2ClPLRcttkLxGd5Y2NSg0hSEDqyY9X-MJK6yri2xtNvCQoUyFH2cOstnm8cMcp0PKaq91OAXSh_A3uCIJLJF8Dvy5m58BYllfEUROmN2Gs2l0Mvt-pdW5ClIo4ZFzQ_JlY8SX5yrdk3Nv7rREduZqg_ZKj_rSXsnQccxZkIUOnWnfk3HWWQJqVOfzh9HFpMYsr2jkFs-ljn7ZmKqdkoo5QRPi1XbSg}",
  note         = "Accessed: 2021-7-14",
  keywords     = "comp-cog-sci"
}

@ARTICLE{Carey1978-gm,
  title    = "Acquiring a {{Single New Word}}",
  author   = "Carey, Susan and Bartlett, Elsa",
  volume   =  15,
  pages    = "14",
  year     =  1978,
  keywords = "comp-cog-sci"
}

@MISC{noauthor_undated-by,
  title        = "Readings in Cognitive Science : A Perspective from Psychology
                  and Artificial Intelligence | {{{McGill} University Library}}",
  howpublished = "\url{https://mcgill.on.worldcat.org/v2/oclc/555237322}",
  note         = "Accessed: 2021-9-17",
  keywords     = "comp-cog-sci"
}

@BOOK{Rojas2013-pv,
  title     = "Neural Networks: A Systematic Introduction",
  author    = "Rojas, Ra{\'u}l",
  publisher = "Springer Science \& Business Media",
  year      =  2013,
  keywords  = "machine-learning",
  isbn      = "9783642610684"
}

@ARTICLE{Fontana2010-ie,
  title    = "Extending {{Healthy Life {Span--From} Yeast}} to {{Humans}}",
  author   = "Fontana, L and Partridge, L and Longo, V D",
  journal  = "Science",
  volume   =  328,
  number   =  5976,
  pages    = "321--326",
  month    =  apr,
  year     =  2010,
  keywords = "longevity",
  issn     = "0036-8075, 1095-9203",
  doi      = "10.1126/science.1172539"
}

@BOOK{noauthor_2015-uh,
  title    = "The Conceptual Mind : New Directions in the Study of Concepts",
  abstract = "``The study of concepts has advanced dramatically in recent
              years, with exciting new findings and theoretical developments.
              Core concepts have been investigated in greater depth and new
              lines of inquiry have blossomed, with researchers from an ever
              broader range of disciplines making important contributions. In
              this volume, leading philosophers and cognitive scientists offer
              original essays that present the state-of-the-art in the study of
              concepts. These essays, all commissioned for this book, do not
              merely present the usual surveys and overviews; rather, they
              offer the latest work on concepts by a diverse group of theorists
              as well as discussions of the ideas that should guide research
              over the next decade. The book is an essential companion volume
              to the earlier Concepts: Core Readings, the definitive source for
              classic texts on the nature of concepts. The essays cover
              concepts as they relate to animal cognition, the brain,
              evolution, perception, and language, concepts across cultures,
              concept acquisition and conceptual change, concepts and
              normativity, concepts in context, and conceptual
              individuation''--MIT CogNet.",
  year     =  2015,
  keywords = "Electronic books;comp-cog-sci",
  isbn     = "9780262326872",
  lccn     = "2014034214"
}

@ARTICLE{Carey2004-ya,
  title    = "Bootstrapping \& the Origin of Concepts",
  author   = "Carey, Susan",
  journal  = "Daedalus",
  volume   =  133,
  number   =  1,
  pages    = "59--68",
  month    =  jan,
  year     =  2004,
  keywords = "comp-cog-sci",
  issn     = "0011-5266, 1548-6192",
  doi      = "10.1162/001152604772746701"
}

@ARTICLE{Cassimatis_undated-lu,
  title    = "Artificial {{Intelligence}} and {{Cognitive Science Have}} the
              {{Same Problem}}",
  author   = "Cassimatis, Nicholas L",
  abstract = "Cognitive scientists attempting to explain human intelligence
              share a puzzle with artificial intelligence researchers aiming to
              create computers that exhibit humanlevel intelligence: how can a
              system composed of relatively unintelligent parts (such as
              neurons or transistors) behave intelligently? I argue that
              although cognitive science has made significant progress towards
              many of its goals, that solving the puzzle of intelligence
              requires special standards and methods in addition to those
              already employed in cognitive science. To promote such research,
              I suggest creating a subfield within cognitive science called
              intelligence science and propose some guidelines for research
              addressing the intelligence puzzle.",
  pages    = "6",
  keywords = "comp-cog-sci"
}

@ARTICLE{Choromanska_undated-tg,
  title    = "The {{Loss Surfaces}} of {{Multilayer Networks}}",
  author   = "Choromanska, Anna and Henaff, Mikael and Mathieu, Michael and
              Arous, Gerard Ben and LeCun, Yann",
  pages    = "13",
  keywords = "comp-cog-sci"
}

@UNPUBLISHED{Darwiche2017-sr,
  title    = "{Human-{{Level} Intelligence}} or {{{Animal-Like} Abilities}}?",
  author   = "Darwiche, Adnan",
  abstract = "The vision systems of the eagle and the snake outperform
              everything that we can make in the laboratory, but snakes and
              eagles cannot build an eyeglass or a telescope or a microscope.
              (Judea Pearl)",
  month    =  jul,
  year     =  2017,
  keywords = "Computer Science - Artificial Intelligence,Computer Science -
              Computers and Society,Computer Science - Machine
              Learning,Statistics - Machine Learning;comp-cog-sci"
}

@BOOK{Epstein2009-te,
  title     = "Parsing the {{Turing Test}}: {{Philosophical}} and
               {{Methodological Issues}} in the {{Quest}} for the {{Thinking
               Computer}}",
  editor    = "Epstein, Robert and Roberts, Gary and Beber, Grace",
  publisher = "Springer Netherlands",
  year      =  2009,
  address   = "Dordrecht",
  keywords  = "comp-cog-sci",
  isbn      = "9781402096242, 9781402067105",
  doi       = "10.1007/978-1-4020-6710-5"
}

@ARTICLE{Goodman2014-kq,
  title    = "Concepts in a {{Probabilistic Language}} of {{Thought}}",
  author   = "Goodman, Noah D and Tenenbaum, Joshua B and Gerstenberg, Tobias",
  pages    = "25",
  year     =  2014,
  keywords = "read;comp-cog-sci"
}

@ARTICLE{Griffiths2010-wc,
  title    = "Probabilistic Models of Cognition: Exploring Representations and
              Inductive Biases",
  author   = "Griffiths, Thomas L and Chater, Nick and Kemp, Charles and
              Perfors, Amy and Tenenbaum, Joshua B",
  journal  = "Trends Cogn. Sci.",
  volume   =  14,
  number   =  8,
  pages    = "357--364",
  month    =  aug,
  year     =  2010,
  keywords = "comp-cog-sci",
  issn     = "1364-6613",
  doi      = "10.1016/j.tics.2010.05.004"
}

@INCOLLECTION{Hauser2004-go,
  title     = "Evolutionary and Developmental Foundations of Human Knowledge",
  booktitle = "The {{Cognitive Neurosciences Iii}}",
  author    = "Hauser, Marc D and Spelke, Elizabeth",
  editor    = "Gazzaniga, Michael S",
  publisher = "MIT Press",
  year      =  2004,
  keywords  = "comp-cog-sci"
}

@ARTICLE{Hawkins2019-jn,
  title    = "A {{Framework}} for {{Intelligence}} and {{Cortical Function
              Based}} on {{Grid Cells}} in the {{Neocortex}}",
  author   = "Hawkins, Jeff and Lewis, Marcus and Klukas, Mirko and Purdy,
              Scott and Ahmad, Subutai",
  journal  = "Front. Neural Circuits",
  volume   =  12,
  pages    = "121",
  month    =  jan,
  year     =  2019,
  keywords = "comp-cog-sci",
  issn     = "1662-5110",
  doi      = "10.3389/fncir.2018.00121"
}

@ARTICLE{Lake2015-ap,
  title    = "{Human-Level} Concept Learning through Probabilistic Program
              Induction",
  author   = "Lake, B M and Salakhutdinov, R and Tenenbaum, J B",
  journal  = "Science",
  volume   =  350,
  number   =  6266,
  pages    = "1332--1338",
  month    =  dec,
  year     =  2015,
  keywords = "comp-cog-sci",
  issn     = "0036-8075, 1095-9203",
  doi      = "10.1126/science.aab3050"
}

@ARTICLE{Lake2019-zq,
  title    = "The {{Omniglot}} Challenge: A 3-Year Progress Report",
  author   = "Lake, Brenden M and Salakhutdinov, Ruslan and Tenenbaum, Joshua B",
  journal  = "Current Opinion in Behavioral Sciences",
  volume   =  29,
  pages    = "97--104",
  month    =  oct,
  year     =  2019,
  keywords = "comp-cog-sci",
  issn     = "2352-1546",
  doi      = "10.1016/j.cobeha.2019.04.007"
}

@ARTICLE{Lake2021-tz,
  title     = "Word Meaning in Minds and Machines",
  author    = "Lake, Brenden M and Murphy, Gregory L",
  journal   = "Psychol. Rev.",
  publisher = "US: American Psychological Association",
  year      =  2021,
  keywords  = "comp-cog-sci",
  issn      = "0033-295X, 1939-1471",
  doi       = "10.1037/rev0000297"
}

@ARTICLE{Landau1988-oy,
  title    = "The Importance of Shape in Early Lexical Learning",
  author   = "Landau, Barbara and Smith, Linda B and Jones, Susan S",
  journal  = "Cogn. Dev.",
  volume   =  3,
  number   =  3,
  pages    = "299--321",
  month    =  jul,
  year     =  1988,
  keywords = "development",
  issn     = "0885-2014",
  doi      = "10.1016/0885-2014(88)90014-7"
}

@INPROCEEDINGS{Lerer2016-kb,
  title      = "Learning {{Physical Intuition}} of {{Block Towers}} by
                {{Example}}",
  booktitle  = "International {{Conference}} on {{Machine Learning}}",
  author     = "Lerer, Adam and Gross, Sam and Fergus, Rob",
  publisher  = "PMLR",
  pages      = "430--438",
  month      =  jun,
  year       =  2016,
  keywords   = "comp-cog-sci",
  conference = "International Conference on Machine Learning"
}

@INCOLLECTION{Minsky2019-mb,
  title     = "A {{Framework For Representing Knowledge}}",
  booktitle = "A {{Framework For Representing Knowledge}}",
  author    = "Minsky, M",
  abstract  = "A Framework For Representing Knowledge was published in Frame
               Conceptions and Text Understanding on page 1.",
  publisher = "De Gruyter",
  pages     = "1--25",
  month     =  jul,
  year      =  2019,
  keywords  = "comp-cog-sci",
  isbn      = "9783110858778",
  doi       = "10.1515/9783110858778-003"
}

@INPROCEEDINGS{Krizhevsky2012-bm,
  title     = "{{ImageNet}} Classification with Deep Convolutional Neural
               Networks",
  booktitle = "Advances in Neural Information Processing Systems",
  author    = "Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E",
  editor    = "Pereira, F and Burges, C J and Bottou, L and Weinberger, K Q",
  publisher = "Curran Associates, Inc.",
  volume    =  25,
  year      =  2012,
  keywords  = "machine-learning"
}

@INBOOK{2021-fc,
  title     = "Perceptron",
  booktitle = "Wikipedia",
  author    = "{Wikipedia}",
  abstract  = "In machine learning, the perceptron is an algorithm for
               supervised learning of binary classifiers. A binary classifier
               is a function which can decide whether or not an input,
               represented by a vector of numbers, belongs to some specific
               class. It is a type of linear classifier, i.e. a classification
               algorithm that makes its predictions based on a linear predictor
               function combining a set of weights with the feature vector.",
  month     =  aug,
  year      =  2021,
  keywords  = "comp-cog-sci"
}

@ARTICLE{Piantadosi2016-na,
  title     = "The Logical Primitives of Thought: {{Empirical}} Foundations for
               Compositional Cognitive Models",
  author    = "Piantadosi, Steven T and Tenenbaum, Joshua B and Goodman, Noah D",
  journal   = "Psychol. Rev.",
  publisher = "US: American Psychological Association",
  volume    =  123,
  number    =  4,
  pages     = "392",
  year      =  2016,
  keywords  = "comp-cog-sci",
  issn      = "0033-295X, 1939-1471",
  doi       = "10.1037/a0039980"
}

@ARTICLE{Rosenblatt1958-kl,
  title    = "The Perceptron: {{A}} Probabilistic Model for Information Storage
              and Organization in the Brain",
  author   = "Rosenblatt, F",
  journal  = "Psychol. Rev.",
  volume   =  65,
  number   =  6,
  pages    = "386--408",
  year     =  1958,
  keywords = "read;comp-cog-sci",
  issn     = "0033-295X, 1939-1471",
  doi      = "10.1037/h0042519"
}

@ARTICLE{Rule2020-db,
  title    = "The {{Child}} as {{Hacker}}",
  author   = "Rule, Joshua S and Tenenbaum, Joshua B and Piantadosi, Steven T",
  journal  = "Trends Cogn. Sci.",
  volume   =  24,
  number   =  11,
  pages    = "900--915",
  month    =  nov,
  year     =  2020,
  keywords = "skimmed;development",
  issn     = "1364-6613",
  doi      = "10.1016/j.tics.2020.07.005"
}

@ARTICLE{Spelke2007-uu,
  title    = "Core Knowledge",
  author   = "Spelke, Elizabeth S and Kinzler, Katherine D",
  abstract = "Human cognition is founded, in part, on four systems for
              representing objects, actions, number, and space. It may be
              based, as well, on a fifth system for representing social
              partners. Each system has deep roots in human phylogeny and
              ontogeny, and it guides and shapes the mental lives of adults.
              Converging research on human infants, non-human primates,
              children and adults in diverse cultures can aid both
              understanding of these systems and attempts to overcome their
              limits.",
  journal  = "Dev. Sci.",
  volume   =  10,
  number   =  1,
  pages    = "89--96",
  year     =  2007,
  keywords = "development",
  issn     = "1363-755X, 1467-7687",
  doi      = "10.1111/j.1467-7687.2007.00569.x"
}

@INPROCEEDINGS{Stuhlmuller2010-ka,
  title     = "Learning Structured Generative Concepts",
  author    = "Stuhlmuller, Andreas and Tenenbaum, Joshua B and Goodman, Noah D",
  publisher = "Cognitive Science Society",
  year      =  2010,
  keywords  = "comp-cog-sci",
  isbn      = "9781617388903"
}

@MISC{Andreas2017-kq,
  title         = "Learning with {{Latent Language}}",
  author        = "Andreas, Jacob and Klein, Dan and Levine, Sergey",
  abstract      = "The named concepts and compositional operators present in
                   natural language provide a rich source of information about
                   the kinds of abstractions humans use to navigate the world.
                   Can this linguistic background knowledge improve the
                   generality and efficiency of learned classifiers and control
                   policies? This paper aims to show that using the space of
                   natural language strings as a parameter space is an
                   effective way to capture natural task structure. In a
                   pretraining phase, we learn a language interpretation model
                   that transforms inputs (e.g. images) into outputs (e.g.
                   labels) given natural language descriptions. To learn a new
                   concept (e.g. a classifier), we search directly in the space
                   of descriptions to minimize the interpreter's loss on
                   training examples. Crucially, our models do not require
                   language data to learn these concepts: language is used only
                   in pretraining to impose structure on subsequent learning.
                   Results on image classification, text editing, and
                   reinforcement learning show that, in all settings, models
                   with a linguistic parameterization outperform those without.",
  journal       = "arXiv [cs]",
  publisher     = "arXiv",
  number        = "arXiv:1711.00482",
  month         =  nov,
  year          =  2017,
  keywords      = "Computer Science - Computation and Language,Computer Science
                   - Neural and Evolutionary Computing;read;comp-cog-sci",
  archivePrefix = "arXiv",
  eprint        = "1711.00482",
  primaryClass  = "cs",
  arxivid       = "1711.00482"
}

@INCOLLECTION{Ashby2011-au,
  title     = "{{COVIS}}",
  booktitle = "Formal {{Approaches}} in {{Categorization}}",
  author    = "Ashby, F Gregory and Paul, Erick J and Maddox, W Todd",
  editor    = "Pothos, Emmanuel M and Wills, Andy J",
  abstract  = "The COVIS model of category learning assumes separate rule-based
               and procedural-learning categorization systems that compete for
               access to response production. The rule-based system selects and
               tests simple verbalizable hypotheses about category membership.
               The procedurallearning system gradually associates
               categorization responses with regions of perceptual space via
               reinforcement learning.",
  publisher = "Cambridge University Press",
  pages     = "65--87",
  year      =  2011,
  address   = "Cambridge",
  keywords  = "comp-cog-sci",
  isbn      = "9780511921322",
  doi       = "10.1017/CBO9780511921322.004"
}

@ARTICLE{Baars2007-hu,
  title    = "An Architectural Model of Conscious and Unconscious Brain
              Functions: {{Global Workspace Theory}} and {{IDA}}",
  author   = "Baars, Bernard J and Franklin, Stan",
  abstract = "While neural net models have been developed to a high degree of
              sophistication, they have some drawbacks at a more integrative,
              ``architectural'' level of analysis. We describe a ``hybrid''
              cognitive architecture that is implementable in neuronal nets,
              and which has uniform brainlike features, including
              activation-passing and highly distributed ``codelets,''
              implementable as small-scale neural nets. Empirically, this
              cognitive architecture accounts qualitatively for the data
              described by Baars' Global Workspace Theory (GWT), and Franklin's
              LIDA architecture, including state-of-the-art models of conscious
              contents in action-planning, Baddeley-style Working Memory, and
              working models of episodic and semantic longterm memory. These
              terms are defined both conceptually and empirically for the
              current theoretical domain. The resulting architecture meets four
              desirable goals for a unified theory of cognition: practical
              workability, autonomous agency, a plausible role for conscious
              cognition, and translatability into plausible neural terms. It
              also generates testable predictions, both empirical and
              computational.",
  journal  = "Neural Netw.",
  volume   =  20,
  number   =  9,
  pages    = "955--961",
  series   = "Brain and Consciousness",
  month    =  nov,
  year     =  2007,
  keywords = "Cognitive architecture,Conscious cognition,Global workspace
              theory,LIDA architecture;comp-cog-sci",
  issn     = "0893-6080",
  doi      = "10.1016/j.neunet.2007.09.013"
}

@ARTICLE{Bengio2013-nf,
  title    = "Representation {{Learning}}: {{A Review}} and {{New
              Perspectives}}",
  author   = "Bengio, Y and Courville, A and Vincent, P",
  abstract = "The success of machine learning algorithms generally depends on
              data representation, and we hypothesize that this is because
              different representations can entangle and hide more or less the
              different explanatory factors of variation behind the data.
              Although specific domain knowledge can be used to help design
              representations, learning with generic priors can also be used,
              and the quest for AI is motivating the design of more powerful
              representation-learning algorithms implementing such priors. This
              paper reviews recent work in the area of unsupervised feature
              learning and deep learning, covering advances in probabilistic
              models, autoencoders, manifold learning, and deep networks. This
              motivates longer term unanswered questions about the appropriate
              objectives for learning good representations, for computing
              representations (i.e., inference), and the geometrical
              connections between representation learning, density estimation,
              and manifold learning.",
  journal  = "IEEE Trans. Pattern Anal. Mach. Intell.",
  volume   =  35,
  number   =  8,
  pages    = "1798--1828",
  month    =  aug,
  year     =  2013,
  keywords = "Abstracts,autoencoder,Boltzmann machine,Deep learning,Feature
              extraction,feature learning,Learning systems,Machine
              learning,Manifolds,neural nets,Neural networks,representation
              learning,Speech recognition,unsupervised learning;comp-cog-sci",
  issn     = "0162-8828, 2160-9292",
  doi      = "10.1109/TPAMI.2013.50"
}

@ARTICLE{Bonner2018-ii,
  title    = "Computational Mechanisms Underlying Cortical Responses to the
              Affordance Properties of Visual Scenes",
  author   = "Bonner, Michael F and Epstein, Russell A",
  editor   = "Einh{\"a}user, Wolfgang",
  abstract = "Biologically inspired deep convolutional neural networks (CNNs),
              trained for computer vision tasks, have been found to predict
              cortical responses with remarkable accuracy. However, the
              internal operations of these models remain poorly understood, and
              the factors that account for their success are unknown. Here we
              develop a set of techniques for using CNNs to gain insights into
              the computational mechanisms underlying cortical responses. We
              focused on responses in the occipital place area (OPA), a
              scene-selective region of dorsal occipitoparietal cortex. In a
              previous study, we showed that fMRI activation patterns in the
              OPA contain information about the navigational affordances of
              scenes; that is, information about where one can and cannot move
              within the immediate environment. We hypothesized that this
              affordance information could be extracted using a set of purely
              feedforward computations. To test this idea, we examined a deep
              CNN with a feedforward architecture that had been previously
              trained for scene classification. We found that responses in the
              CNN to scene images were highly predictive of fMRI responses in
              the OPA. Moreover the CNN accounted for the portion of OPA
              variance relating to the navigational affordances of scenes. The
              CNN could thus serve as an image-computable candidate model of
              affordance-related responses in the OPA. We then ran a series of
              in silico experiments on this model to gain insights into its
              internal operations. These analyses showed that the computation
              of affordance-related features relied heavily on visual
              information at high-spatial frequencies and cardinal
              orientations, both of which have previously been identified as
              lowlevel stimulus preferences of scene-selective visual cortex.
              These computations also exhibited a strong preference for
              information in the lower visual field, which is consistent with
              known retinotopic biases in the OPA. Visualizations of feature
              selectivity within the CNN suggested that affordance-based
              responses encoded features that define the layout of the spatial
              environment, such as boundary-defining junctions and large
              extended surfaces. Together, these results map the sensory
              functions of the OPA onto a fully quantitative model that
              provides insights into its visual computations. More broadly,
              they advance integrative techniques for understanding visual
              cortex across multiple level of analysis: from the identification
              of cortical sensory functions to the modeling of their underlying
              algorithms.",
  journal  = "PLoS Comput. Biol.",
  volume   =  14,
  number   =  4,
  pages    = "e1006111",
  month    =  apr,
  year     =  2018,
  keywords = "comp-cog-sci",
  issn     = "1553-734X, 1553-7358",
  doi      = "10.1371/journal.pcbi.1006111"
}

@ARTICLE{Bonner2021-zd,
  title    = "Object Representations in the Human Brain Reflect the
              {Co-Occurrence} Statistics of Vision and Language",
  author   = "Bonner, Michael F and Epstein, Russell A",
  abstract = "Abstract A central regularity of visual perception is the
              co-occurrence of objects in the natural environment. Here we use
              machine learning and fMRI to test the hypothesis that object
              co-occurrence statistics are encoded in the human visual system
              and elicited by the perception of individual objects. We
              identified low-dimensional representations that capture the
              latent statistical structure of object co-occurrence in
              real-world scenes, and we mapped these statistical
              representations onto voxel-wise fMRI responses during object
              viewing. We found that cortical responses to single objects were
              predicted by the statistical ensembles in which they typically
              occur, and that this link between objects and their visual
              contexts was made most strongly in parahippocampal cortex,
              overlapping with the anterior portion of scene-selective
              parahippocampal place area. In contrast, a language-based
              statistical model of the co-occurrence of object names in written
              text predicted responses in neighboring regions of
              object-selective visual cortex. Together, these findings show
              that the sensory coding of objects in the human brain reflects
              the latent statistics of object context in visual and linguistic
              experience.",
  journal  = "Nat. Commun.",
  volume   =  12,
  number   =  1,
  pages    = "4081",
  month    =  dec,
  year     =  2021,
  keywords = "comp-cog-sci",
  issn     = "2041-1723",
  doi      = "10.1038/s41467-021-24368-2"
}

@ARTICLE{Botvinick2017-xr,
  title    = "Building Machines That Learn and Think for Themselves",
  author   = "Botvinick, Matthew and Barrett, David G T and Battaglia, Peter
              and de Freitas, Nando and Kumaran, Darshan and Leibo, Joel Z and
              Lillicrap, Timothy and Modayil, Joseph and Mohamed, Shakir and
              Rabinowitz, Neil C and Rezende, Danilo J and Santoro, Adam and
              Schaul, Tom and Summerfield, Christopher and Wayne, Greg and
              Weber, Theophane and Wierstra, Daan and Legg, Shane and Hassabis,
              Demis",
  abstract = "We agree with Lake and colleagues on their list of `key
              ingredients' for building humanlike intelligence, including the
              idea that model-based reasoning is essential. However, we favor
              an approach that centers on one additional ingredient: autonomy.
              In particular, we aim toward agents that can both build and
              exploit their own internal models, with minimal human
              hand-engineering. We believe an approach centered on autonomous
              learning has the greatest chance of success as we scale toward
              real-world complexity, tackling domains for which ready-made
              formal models are not available. Here we survey several important
              examples of the progress that has been made toward building
              autonomous agents with humanlike abilities, and highlight some
              outstanding challenges.",
  journal  = "Behav. Brain Sci.",
  volume   =  40,
  pages    = "e255",
  year     =  2017,
  keywords = "comp-cog-sci",
  issn     = "0140-525X, 1469-1825",
  doi      = "10.1017/S0140525X17000048"
}

@ARTICLE{Bourlard1988-if,
  title    = "{Auto-Association} by Multilayer Perceptrons and Singular Value
              Decomposition",
  author   = "Bourlard, H and Kamp, Y",
  abstract = "The multilayer perceptron, when working in auto-association mode,
              is sometimes considered as an interesting candidate to perform
              data compression or dimensionality reduction of the feature space
              in information processing applications. The present paper shows
              that, for auto-association, the nonlinearities of the hidden
              units are useless and that the optimal parameter values can be
              derived directly by purely linear techniques relying on singular
              value decomposition and low rank matrix approximation, similar in
              spirit to the well-known Karhunen-Lo6ve transform. This approach
              appears thus as an efficient alternative to the general error
              back-propagation algorithm commonly used for training multilayer
              perceptrons. Moreover, it also gives a clear interpretation of
              the r61e of the different parameters.",
  journal  = "Biol. Cybern.",
  volume   =  59,
  number   = "4-5",
  pages    = "291--294",
  month    =  sep,
  year     =  1988,
  keywords = "comp-cog-sci",
  issn     = "0340-1200, 1432-0770",
  doi      = "10.1007/BF00332918"
}

@MISC{Chollet2019-di,
  title         = "On the {{Measure}} of {{Intelligence}}",
  author        = "Chollet, Fran{\c c}ois",
  abstract      = "To make deliberate progress towards more intelligent and
                   more human-like artificial systems, we need to be following
                   an appropriate feedback signal: we need to be able to define
                   and evaluate intelligence in a way that enables comparisons
                   between two systems, as well as comparisons with humans.
                   Over the past hundred years, there has been an abundance of
                   attempts to define and measure intelligence, across both the
                   fields of psychology and AI. We summarize and critically
                   assess these definitions and evaluation approaches, while
                   making apparent the two historical conceptions of
                   intelligence that have implicitly guided them. We note that
                   in practice, the contemporary AI community still gravitates
                   towards benchmarking intelligence by comparing the skill
                   exhibited by AIs and humans at specific tasks, such as board
                   games and video games. We argue that solely measuring skill
                   at any given task falls short of measuring intelligence,
                   because skill is heavily modulated by prior knowledge and
                   experience: unlimited priors or unlimited training data
                   allow experimenters to ``buy'' arbitrary levels of skills
                   for a system, in a way that masks the system's own
                   generalization power. We then articulate a new formal
                   definition of intelligence based on Algorithmic Information
                   Theory, describing intelligence as skill-acquisition
                   efficiency and highlighting the concepts of scope,
                   generalization difficulty, priors, and experience, as
                   critical pieces to be accounted for in characterizing
                   intelligent systems. Using this definition, we propose a set
                   of guidelines for what a general AI benchmark should look
                   like. Finally, we present a new benchmark closely following
                   these guidelines, the Abstraction and Reasoning Corpus
                   (ARC), built upon an explicit set of priors designed to be
                   as close as possible to innate human priors. We argue that
                   ARC can be used to measure a human-like form of general
                   fluid intelligence and that it enables fair general
                   intelligence comparisons between AI systems and humans.",
  journal       = "arXiv [cs]",
  publisher     = "arXiv",
  number        = "arXiv:1911.01547",
  month         =  nov,
  year          =  2019,
  keywords      = "Computer Science - Artificial
                   Intelligence;read;comp-cog-sci;ARC Project",
  archivePrefix = "arXiv",
  eprint        = "1911.01547",
  primaryClass  = "cs",
  arxivid       = "1911.01547"
}

@ARTICLE{Chomsky1956-aj,
  title    = "Three Models for the Description of Language",
  author   = "Chomsky, N",
  abstract = "We investigate several conceptions of linguistic structure to
              determine whether or not they can provide simple and
              ``revealing'' grammars that generate all of the sentences of
              English and only these. We find that no finite-state Markov
              process that produces symbols with transition from state to state
              can serve as an English grammar. Furthermore, the particular
              subclass of such processes that producen-order statistical
              approximations to English do not come closer, with increasingn,
              to matching the output of an English grammar. We formalize-the
              notions of ``phrase structure'' and show that this gives us a
              method for describing language which is essentially more
              powerful, though still representable as a rather elementary type
              of finite-state process. Nevertheless, it is successful only when
              limited to a small subset of simple sentences. We study the
              formal properties of a set of grammatical transformations that
              carry sentences with phrase structure into new sentences with
              derived phrase structure, showing that transformational grammars
              are processes of the same elementary type as phrase-structure
              grammars; that the grammar of English is materially simplified if
              phrase structure description is limited to a kernel of simple
              sentences from which all other sentences are constructed by
              repeated transformations; and that this view of linguistic
              structure gives a certain insight into the use and understanding
              of language.",
  journal  = "IRE Transactions on Information Theory",
  volume   =  2,
  number   =  3,
  pages    = "113--124",
  month    =  sep,
  year     =  1956,
  keywords = "Impedance matching,Kernel,Laboratories,Markov processes,Natural
              languages,Research and development,Testing;comp-cog-sci",
  issn     = "2168-2712",
  doi      = "10.1109/TIT.1956.1056813"
}

@ARTICLE{Dekker2022-lm,
  title     = "Determinants of Human Compositional Generalization",
  author    = "Dekker, Ronald Boris and Otto, Fabian and Summerfield,
               Christopher",
  abstract  = "Generalisation (or transfer) is the ability to repurpose
               knowledge in novel settings. It is often asserted that
               generalisation is an important ingredient of human intelligence,
               but its extent, nature and determinants have proved
               controversial. Here, we re-examine this question with a new
               paradigm that formalises the transfer learning problem as one of
               recomposing existing functions to solve unseen problems. We find
               that people can generalise compositionally in ways that are
               elusive for standard neural networks, and that human
               generalisation benefits from training regimes in which items are
               axis-aligned and temporally correlated. We describe a neural
               network model based around a Hebbian gating process which can
               capture how human generalisation benefits from different
               training curricula. We additionally find that adult humans tend
               to learn composable functions asynchronously, exhibiting
               discontinuities in learning that resemble those seen in child
               development.",
  publisher = "PsyArXiv",
  month     =  mar,
  year      =  2022,
  keywords  = "Cognitive Psychology,Computational Neuroscience,Concepts and
               Categories,generalisation,Learning,neural
               network,Neuroscience,Social and Behavioral Sciences;comp-cog-sci",
  doi       = "10.31234/osf.io/qnpw6"
}

@ARTICLE{Dwivedi2021-zk,
  title     = "Unveiling Functions of the Visual Cortex Using {Task-Specific}
               Deep Neural Networks",
  author    = "Dwivedi, Kshitij and Bonner, Michael F and Cichy, Radoslaw
               Martin and Roig, Gemma",
  abstract  = "The human visual cortex enables visual perception through a
               cascade of hierarchical computations in cortical regions with
               distinct functionalities. Here, we introduce an AI-driven
               approach to discover the functional mapping of the visual
               cortex. We related human brain responses to scene images
               measured with functional MRI (fMRI) systematically to a diverse
               set of deep neural networks (DNNs) optimized to perform
               different scene perception tasks. We found a structured mapping
               between DNN tasks and brain regions along the ventral and dorsal
               visual streams. Low-level visual tasks mapped onto early brain
               regions, 3-dimensional scene perception tasks mapped onto the
               dorsal stream, and semantic tasks mapped onto the ventral
               stream. This mapping was of high fidelity, with more than 60\%
               of the explainable variance in nine key regions being explained.
               Together, our results provide a novel functional mapping of the
               human visual cortex and demonstrate the power of the
               computational approach.",
  journal   = "PLoS Comput. Biol.",
  publisher = "Public Library of Science",
  volume    =  17,
  number    =  8,
  pages     = "e1009267",
  month     =  aug,
  year      =  2021,
  keywords  = "Functional magnetic resonance imaging,Linear regression
               analysis,Neural networks,Permutation,Semantics,Sensory
               perception,Vision,Visual cortex;comp-cog-sci",
  issn      = "1553-734X, 1553-7358",
  doi       = "10.1371/journal.pcbi.1009267"
}

@UNPUBLISHED{Feinman2021-mh,
  title    = "Learning {{{Task-General} Representations}} with {{Generative
              {Neuro-Symbolic} Modeling}}",
  author   = "Feinman, Reuben and Lake, Brenden M",
  abstract = "People can learn rich, general-purpose conceptual representations
              from only raw perceptual inputs. Current machine learning
              approaches fall well short of these human standards, although
              different modeling traditions often have complementary strengths.
              Symbolic models can capture the compositional and causal
              knowledge that enables flexible generalization, but they struggle
              to learn from raw inputs, relying on strong abstractions and
              simplifying assumptions. Neural network models can learn directly
              from raw data, but they struggle to capture compositional and
              causal structure and typically must retrain to tackle new tasks.
              We bring together these two traditions to learn generative models
              of concepts that capture rich compositional and causal structure,
              while learning from raw data. We develop a generative
              neuro-symbolic (GNS) model of handwritten character concepts that
              uses the control flow of a probabilistic program, coupled with
              symbolic stroke primitives and a symbolic image renderer, to
              represent the causal and compositional processes by which
              characters are formed. The distributions of parts (strokes), and
              correlations between parts, are modeled with neural network
              subroutines, allowing the model to learn directly from raw data
              and express nonparametric statistical relationships. We apply our
              model to the Omniglot challenge of human-level concept learning,
              using a background set of alphabets to learn an expressive prior
              distribution over character drawings. In a subsequent evaluation,
              our GNS model uses probabilistic inference to learn rich
              conceptual representations from a single training image that
              generalize to 4 unique tasks, succeeding where previous work has
              fallen short.",
  month    =  jan,
  year     =  2021,
  keywords = "Computer Science - Artificial Intelligence,Computer Science -
              Machine Learning,Statistics - Machine Learning;comp-cog-sci"
}

@ARTICLE{Fodor1988-gq,
  title    = "Connectionism and Cognitive Architecture: {{A}} Critical Analysis",
  author   = "Fodor, Jerry A and Pylyshyn, Zenon W",
  abstract = "This paper explores differences between Connectionist proposals
              for cognitive architecture and the sorts of models that have
              traditionally been assumed in cognitive science. We claim that
              the major distinction is that, while both Connectionist and
              Classical architectures postulate representational mental states,
              the latter but not the former are committed to a symbol-level of
              representation, or to a `language of thought': i.e., to
              representational states that have combinatorial syntactic and
              semantic structure. Several arguments for combinatorial structure
              in mental representations are then reviewed. These include
              arguments based on the `systematicity' of mental representation:
              i.e., on the fact that cognitive capacities always exhibit
              certain symmetries, so that the ability to entertain a given
              thought implies the ability to entertain thoughts with
              semantically related contents. We claim that such arguments make
              a powerful case that mind/brain architecture is not Connectionist
              at the cognitive level. We then consider the possibility that
              Connectionism may provide an account of the neural (or `abstract
              neurological') structures in which Classical cognitive
              architecture is implemented. We survey a number of the standard
              arguments that have been offered in favor of Connectionism, and
              conclude that they are coherent only on this interpretation.
              R{\'e}sum{\'e} Cet article{\'e}tudie les diff{\'e}rences entre
              mod{\`e}les connectionistes et mod{\`e}les classiques de la
              structure cognitive. Nous pensons que, bien que les deux types de
              mod{\`e}les stipulent l'existence d'{\'e}tats mentaux
              repr{\'e}sentationnels, la diff{\'e}rence essentielle est que
              seuls les mod{\`e}les classiques requi{\`e}rent l'existence d'un
              niveau de repr{\'e}sentation symbolique---un ``langage de la
              pens{\'e}e''---, c'est-{\`a}-dire d'{\'e}tats
              repr{\'e}sentationnels poss{\'e}dant une structure syntaxique et
              s{\'e}mantique. Nous examinons ensuite diff{\'e}rents arguments
              qui militent en faveur de l'existence de repr{\'e}sentations
              mentales ayant ces propri{\'e}t{\'e}s. Certains de ces arguments
              reposent sur la ``syst{\'e}maticit{\'e}'' des repr{\'e}sentations
              mentales, c'est-{\`a}-dire sur le fait que les capacit{\'e}s
              cognitives exhibent toujours certaines sym{\'e}tries, de sorte
              que la capacit{\'e}d'entretenir certaines pens{\'e}es implique la
              capacit{\'e}d'entretenir d'autres pens{\'e}es apparent{\'e}es par
              leur contenu s{\'e}mantique. Nous pensons que ces arguments
              montrent de mani{\`e}re convainquante que l'architecture de
              l'esprit/du cerveau n'est pas connectioniste au niveau cognitif.
              Nous nous demandons ensuite s'il est possible d'interpr{\'e}ter
              le connectionisme comme une analyse des structures neuronales (ou
              des structures neurologiques ``abstraites'') dans lesquelles est
              r{\'e}alis{\'e}e l'architecture cognitive classique. Nous
              examinons plusieurs des arguments avanc{\'e}s habituellement en
              d{\'e}fense du connectionisme, et en concluons que ceux-ci n'ont
              de sens que dans cette interpr{\'e}tation.",
  journal  = "Cognition",
  volume   =  28,
  number   =  1,
  pages    = "3--71",
  year     =  1988,
  keywords = "comp-cog-sci",
  issn     = "0010-0277",
  doi      = "10.1016/0010-0277(88)90031-5"
}

@ARTICLE{Gershman2015-pa,
  title    = "Computational Rationality: {{A}} Converging Paradigm for
              Intelligence in Brains, Minds, and Machines",
  author   = "Gershman, Samuel J and Horvitz, Eric J and Tenenbaum, Joshua B",
  abstract = "After growing up together, and mostly growing apart in the second
              half of the 20th century, the fields of artificial intelligence
              (AI), cognitive science, and neuroscience are reconverging on a
              shared view of the computational foundations of intelligence that
              promotes valuable cross-disciplinary exchanges on questions,
              methods, and results. We chart advances over the past several
              decades that address challenges of perception and action under
              uncertainty through the lens of computation. Advances include the
              development of representations and inferential procedures for
              large-scale probabilistic inference and machinery for enabling
              reflection and decisions about tradeoffs in effort, precision,
              and timeliness of computations. These tools are deployed toward
              the goal of computational rationality: identifying decisions with
              highest expected utility, while taking into consideration the
              costs of computation in complex real-world problems in which most
              relevant calculations can only be approximated. We highlight key
              concepts with examples that show the potential for interchange
              between computer science, cognitive science, and neuroscience.",
  journal  = "Science",
  volume   =  349,
  number   =  6245,
  pages    = "273--278",
  month    =  jul,
  year     =  2015,
  keywords = "comp-cog-sci",
  issn     = "0036-8075, 1095-9203",
  doi      = "10.1126/science.aac6076"
}

@ARTICLE{Ghahramani2015-ko,
  title     = "Probabilistic Machine Learning and Artificial Intelligence",
  author    = "Ghahramani, Zoubin",
  abstract  = "How can a machine learn from experience? Probabilistic modelling
               provides a framework for understanding what learning is, and has
               therefore emerged as one of the principal theoretical and
               practical approaches for designing machines that learn from data
               acquired through experience. The probabilistic framework, which
               describes how to represent and manipulate uncertainty about
               models and predictions, has a central role in scientific data
               analysis, machine learning, robotics, cognitive science and
               artificial intelligence. This Review provides an introduction to
               this framework, and discusses some of the state-of-the-art
               advances in the field, namely, probabilistic programming,
               Bayesian optimization, data compression and automatic model
               discovery.",
  journal   = "Nature",
  publisher = "Nature Publishing Group",
  volume    =  521,
  number    =  7553,
  pages     = "452--459",
  month     =  may,
  year      =  2015,
  keywords  = "comp-cog-sci",
  issn      = "0028-0836, 1476-4687",
  doi       = "10.1038/nature14541"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Girshick_undated-ee,
  title    = "Rich {{Feature Hierarchies}} for {{Accurate Object Detection}}
              and {{Semantic Segmentation}}",
  author   = "Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik,
              Jitendra",
  abstract = "Object detection performance, as measured on the canonical PASCAL
              VOC dataset, has plateaued in the last few years. The
              best-performing methods are complex ensemble systems that
              typically combine multiple low-level image features with
              high-level context. In this paper, we propose a simple and
              scalable detection algorithm that improves mean average precision
              (mAP) by more than 30\% relative to the previous best result on
              VOC 2012---achieving a mAP of 53.3\%. Our approach combines two
              key insights: (1) one can apply high-capacity convolutional
              neural networks (CNNs) to bottom-up region proposals in order to
              localize and segment objects and (2) when labeled training data
              is scarce, supervised pre-training for an auxiliary task,
              followed by domain-specific fine-tuning, yields a significant
              performance boost. Since we combine region proposals with CNNs,
              we call our method R-CNN: Regions with CNN features. We also
              present experiments that provide insight into what the network
              learns, revealing a rich hierarchy of image features. Source code
              for the complete system is available at
              http://www.cs.berkeley.edu/ rbg/rcnn.",
  pages    = "8",
  keywords = "comp-cog-sci"
}

@ARTICLE{Goodman2008-ee,
  title    = "A {{Rational Analysis}} of {{{Rule-Based} Concept Learning}}",
  author   = "Goodman, Noah D and Tenenbaum, Joshua B and Feldman, Jacob and
              Griffiths, Thomas L",
  abstract = "This article proposes a new model of human concept learning that
              provides a rational analysis of learning feature-based concepts.
              This model is built upon Bayesian inference for a grammatically
              structured hypothesis space---a concept language of logical
              rules. This article compares the model predictions to human
              generalization judgments in several well-known category learning
              experiments, and finds good agreement for both average and
              individual participant generalizations. This article further
              investigates judgments for a broad set of 7-feature concepts---a
              more natural setting in several ways---and again finds that the
              model explains human performance.",
  journal  = "Cogn. Sci.",
  volume   =  32,
  number   =  1,
  pages    = "108--154",
  month    =  jan,
  year     =  2008,
  keywords = "comp-cog-sci",
  issn     = "0364-0213",
  doi      = "10.1080/03640210701802071"
}

@UNPUBLISHED{Goyal2020-od,
  title    = "Recurrent {{Independent Mechanisms}}",
  author   = "Goyal, Anirudh and Lamb, Alex and Hoffmann, Jordan and Sodhani,
              Shagun and Levine, Sergey and Bengio, Yoshua and Sch{\"o}lkopf,
              Bernhard",
  abstract = "Learning modular structures which reflect the dynamics of the
              environment can lead to better generalization and robustness to
              changes which only affect a few of the underlying causes. We
              propose Recurrent Independent Mechanisms (RIMs), a new recurrent
              architecture in which multiple groups of recurrent cells operate
              with nearly independent transition dynamics, communicate only
              sparingly through the bottleneck of attention, and are only
              updated at time steps where they are most relevant. We show that
              this leads to specialization amongst the RIMs, which in turn
              allows for dramatically improved generalization on tasks where
              some factors of variation differ systematically between training
              and evaluation.",
  month    =  nov,
  year     =  2020,
  keywords = "Computer Science - Artificial Intelligence,Computer Science -
              Machine Learning,Statistics - Machine Learning;comp-cog-sci"
}

@INPROCEEDINGS{He2016-if,
  title      = "Deep {{Residual Learning}} for {{Image Recognition}}",
  booktitle  = "2016 {{{IEEE} Conference}} on {{Computer Vision}} and {{Pattern
                Recognition}} ({{{CVPR}}})",
  author     = "He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian",
  abstract   = "Deeper neural networks are more difficult to train. We present
                a residual learning framework to ease the training of networks
                that are substantially deeper than those used previously. We
                explicitly reformulate the layers as learning residual
                functions with reference to the layer inputs, instead of
                learning unreferenced functions. We provide comprehensive
                empirical evidence showing that these residual networks are
                easier to optimize, and can gain accuracy from considerably
                increased depth. On the ImageNet dataset we evaluate residual
                nets with a depth of up to 152 layers---8$\times$ deeper than
                VGG nets [40] but still having lower complexity. An ensemble of
                these residual nets achieves 3.57\% error on the ImageNet test
                set. This result won the 1st place on the ILSVRC 2015
                classification task. We also present analysis on CIFAR-10 with
                100 and 1000 layers.",
  publisher  = "IEEE",
  pages      = "770--778",
  month      =  jun,
  year       =  2016,
  address    = "Las Vegas, NV, USA",
  keywords   = "machine-learning",
  conference = "2016 IEEE Conference on Computer Vision and Pattern Recognition
                (CVPR)",
  isbn       = "9781467388511",
  doi        = "10.1109/CVPR.2016.90"
}

@ARTICLE{Japkowicz2000-wi,
  title    = "Nonlinear {{Autoassociation Is Not Equivalent}} to {{PCA}}",
  author   = "Japkowicz, Nathalie and Hanson, Stephen Jos{\'e} and Gluck, Mark
              A",
  abstract = "A common misperception within the neural network community is
              that even with nonlinearities in their hidden layer,
              autoassociators trained with backpropagation are equivalent to
              linear methods such as principal component analysis (PCA). Our
              purpose is to demonstrate that nonlinear autoassociators actually
              behave differently from linear methods and that they can
              outperform these methods when used for latent extraction,
              projection, and classification. While linear autoassociators
              emulate PCA, and thus exhibit a flat or unimodal reconstruction
              error surface, autoassociators with nonlinearities in their
              hidden layer learn domains by building error reconstruction
              surfaces that, depending on the task, contain multiple local
              valleys. This interpolation bias allows nonlinear autoassociators
              to represent appropriate classifications of nonlinear multimodal
              domains, in contrast to linear autoassociators, which are
              inappropriate for such tasks. In fact, autoassociators with
              hidden unit nonlinearities can be shown to perform nonlinear
              classification and nonlinear recognition.",
  journal  = "Neural Comput.",
  volume   =  12,
  number   =  3,
  pages    = "531--545",
  month    =  mar,
  year     =  2000,
  keywords = "comp-cog-sci",
  issn     = "0899-7667",
  doi      = "10.1162/089976600300015691"
}

@ARTICLE{Kemp2009-oz,
  title    = "Structured Statistical Models of Inductive Reasoning",
  author   = "Kemp, Charles and Tenenbaum, Joshua B",
  abstract = "Everyday inductive inferences are often guided by rich background
              knowledge. Formal models of induction should aim to incorporate
              this knowledge and should explain how different kinds of
              knowledge lead to the distinctive patterns of reasoning found in
              different inductive contexts. This article presents a Bayesian
              framework that attempts to meet both goals and describe 4
              applications of the framework: a taxonomic model, a spatial
              model, a threshold model, and a causal model. Each model makes
              probabilistic inferences about the extensions of novel
              properties, but the priors for the 4 models are defined over
              different kinds of structures that capture different
              relationships between the categories in a domain. The framework
              therefore shows how statistical inference can operate over
              structured background knowledge, and the authors argue that this
              interaction between structure and statistics is critical for
              explaining the power and flexibility of human reasoning.",
  journal  = "Psychol. Rev.",
  volume   =  116,
  number   =  1,
  pages    = "20--58",
  year     =  2009,
  keywords = "comp-cog-sci",
  issn     = "0033-295X, 1939-1471",
  doi      = "10.1037/a0014282"
}

@ARTICLE{Kruschke1993-eg,
  title    = "Human {{Category Learning}}: {{Implications}} for
              {{Backpropagation Models}}",
  author   = "Kruschke, John K",
  abstract = "Backpropagation (Rumelhart et al., 1986a) was proposed as a
              general learning algorithm for multi-layer perceptrons. This a n
              d e demonstrates chat a standard version of backprop fails to
              attend selectively to input dimensions in the same way as humans,
              suffers catastrophic forgetting of previously learned
              associations when novel exemplars are [rained, and can be overly
              sensitive to linear categoy boundaries. Another connecrionist
              model, A L C O V E (Krwchke 1990, 1992), does nor suffer those
              failures. Previous researchers identified these problems; the
              present article repons quantitative fits of the models to new
              human learning data. A L C O V E can be functionally approximated
              by a network that uses linear-sigmoid hidden nodes, like standard
              backprop. Ir is argued that models of human category learning
              should incorporate quasi-local representations and dimensional
              artention learning, as well as error-driuen learning, to address
              simulraneously all three phenomena.",
  journal  = "Conn. Sci.",
  volume   =  5,
  number   =  1,
  pages    = "3--36",
  month    =  jan,
  year     =  1993,
  keywords = "comp-cog-sci",
  issn     = "0954-0091, 1360-0494",
  doi      = "10.1080/09540099308915683"
}

@ARTICLE{Lake_undated-bl,
  title    = "Concept Learning as Motor Program Induction: {{A}} {Large-Scale}
              Empirical Study",
  author   = "Lake, Brenden M and Salakhutdinov, Ruslan and Tenenbaum, Joshua B",
  abstract = "Human concept learning is particularly impressive in two
              respects: the internal structure of concepts can be
              representationally rich, and yet the very same concepts can also
              be learned from just a few examples. Several decades of research
              have dramatically advanced our understanding of these two aspects
              of concepts. While the richness and speed of concept learning are
              most often studied in isolation, the power of human concepts may
              be best explained through their synthesis. This paper presents a
              large-scale empirical study of one-shot concept learning,
              suggesting that rich generative knowledge in the form of a motor
              program can be induced from just a single example of a novel
              concept. Participants were asked to draw novel handwritten
              characters given a reference form, and we recorded the motor data
              used for production. Multiple drawers of the same character not
              only produced visually similar drawings, but they also showed a
              striking correspondence in their strokes, as measured by their
              number, shape, order, and direction. This suggests that
              participants can infer a rich motorbased concept from a single
              example. We also show that the motor programs induced by
              individual subjects provide a powerful basis for one-shot
              classification, yielding far higher accuracy than
              state-of-the-art pattern recognition methods based on just the
              visual form.",
  pages    = "6",
  keywords = "comp-cog-sci"
}

@ARTICLE{Lake2018-gk,
  title    = "The {{Emergence}} of {{Organizing Structure}} in {{Conceptual
              Representation}}",
  author   = "Lake, Brenden M and Lawrence, Neil D and Tenenbaum, Joshua B",
  abstract = "Both scientists and children make important structural
              discoveries, yet their computational underpinnings are not well
              understood. Structure discovery has previously been formalized as
              probabilistic inference about the right structural form---where
              form could be a tree, ring, chain, grid, etc. (Kemp \& Tenenbaum,
              2008). Although this approach can learn intuitive organizations,
              including a tree for animals and a ring for the color circle, it
              assumes a strong inductive bias that considers only these
              particular forms, and each form is explicitly provided as initial
              knowledge. Here we introduce a new computational model of how
              organizing structure can be discovered, utilizing a broad
              hypothesis space with a preference for sparse connectivity. Given
              that the inductive bias is more general, the model's initial
              knowledge shows little qualitative resemblance to some of the
              discoveries it supports. As a consequence, the model can also
              learn complex structures for domains that lack intuitive
              description, as well as predict human property induction
              judgments without explicit structural forms. By allowing form to
              emerge from sparsity, our approach clarifies how both the
              richness and flexibility of human conceptual organization can
              coexist.",
  journal  = "Cogn. Sci.",
  volume   =  42,
  number   = "S3",
  pages    = "809--832",
  year     =  2018,
  keywords = "Bayesian modeling,Sparsity,Structure discovery,Unsupervised
              learning;comp-cog-sci",
  issn     = "0364-0213, 1551-6709",
  doi      = "10.1111/cogs.12580"
}

@ARTICLE{Lake2020-wr,
  title    = "People {{Infer Recursive Visual Concepts}} from {{Just}} a {{Few
              Examples}}",
  author   = "Lake, Brenden M and Piantadosi, Steven T",
  abstract = "Machine learning has made major advances in categorizing objects
              in images, yet the best algorithms miss important aspects of how
              people learn and think about categories. People can learn richer
              concepts from fewer examples, including causal models that
              explain how members of a category are formed. Here, we explore
              the limits of this human ability to infer causal
              ``programs''---latent generating processes with nontrivial
              algorithmic properties---from one, two, or three visual examples.
              People were asked to extrapolate the programs in several ways,
              for both classifying and generating new examples. As a theory of
              these inductive abilities, we present a Bayesian program learning
              model that searches the space of programs for the best
              explanation of the observations. Although variable, people's
              judgments are broadly consistent with the model and inconsistent
              with several alternatives, including a pretrained deep neural
              network for object recognition, indicating that people can learn
              and reason with rich algorithmic abstractions from sparse input
              data.",
  journal  = "Computational Brain \& Behavior",
  volume   =  3,
  number   =  1,
  pages    = "54--65",
  month    =  mar,
  year     =  2020,
  keywords = "comp-cog-sci",
  issn     = "2522-0861, 2522-087X",
  doi      = "10.1007/s42113-019-00053-y"
}

@ARTICLE{Lloyd2014-ua,
  title    = "Automatic {{Construction}} and {{{Natural-Language} Description}}
              of {{Nonparametric Regression Models}}",
  author   = "Lloyd, James and Duvenaud, David and Grosse, Roger and Tenenbaum,
              Joshua and Ghahramani, Zoubin",
  abstract = "This paper presents the beginnings of an automatic statistician,
              focusing on regression problems. Our system explores an
              open-ended space of statistical models to discover a good
              explanation of a data set, and then produces a detailed report
              with figures and natural-language text. Our approach treats
              unknown regression functions nonparametrically using Gaussian
              processes, which has two important consequences. First, Gaussian
              processes can model functions in terms of high-level properties
              (e.g. smoothness, trends, periodicity, changepoints). Taken
              together with the compositional structure of our language of
              models this allows us to automatically describe functions in
              simple terms. Second, the use of flexible nonparametric models
              and a rich language for composing them in an open-ended manner
              also results in state-of-the-art extrapolation performance
              evaluated over 13 real time series data sets from various
              domains.",
  journal  = "Proc. Conf. AAAI Artif. Intell.",
  volume   =  28,
  number   =  1,
  month    =  jun,
  year     =  2014,
  keywords = "Regression;comp-cog-sci",
  issn     = "2159-5399, 2374-3468"
}

@INCOLLECTION{Lupyan2021-sj,
  title     = "Does {{Vocabulary Help Structure}} the {{Mind}}?",
  booktitle = "Minnesota {{Symposia}} on {{Child Psychology}}",
  author    = "Lupyan, Gary and Zettersten, Martin",
  abstract  = "The idea that language shapes thinking seemed plausible when
               scientists were in the dark about how thinking works. This
               chapter describes several mechanisms by which the words of a
               language can help structure knowledge and navigate cognitive
               problems. It is because thought and language seem so closely
               linked that language is so often used as a window to thought.
               The cognitive priority view faces two serious problems. The
               first is accounting for the cross-linguistic diversity of
               vocabularies. The second problem is the problem of origin. The
               chapter discusses new data aimed at both collecting verbal
               complexity measures independently from the original Bongard
               problems themselves, and collecting more objective measures of
               solution accuracy. It provides further evidence for the idea
               that easier-to-name visual features are more likely to be used
               by people when judging visual similarity.",
  publisher = "John Wiley \& Sons, Ltd",
  pages     = "160--199",
  year      =  2021,
  keywords  = "Bongard problems,cognitive priority,cross-linguistic
               diversity,name visual features,verbal complexity,visual
               similarity,vocabularies;comp-cog-sci",
  isbn      = "9781119684527",
  doi       = "10.1002/9781119684527.ch6"
}

@ARTICLE{Mnih2015-vd,
  title     = "{Human-Level} Control through Deep Reinforcement Learning",
  author    = "Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and
               Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and
               Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and
               Ostrovski, Georg and Petersen, Stig and Beattie, Charles and
               Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran,
               Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis",
  abstract  = "An artificial agent is developed that learns to play a diverse
               range of classic Atari 2600 computer games directly from sensory
               experience, achieving a performance comparable to that of an
               expert human player; this work paves the way to building
               general-purpose learning algorithms that bridge the divide
               between perception and action.",
  journal   = "Nature",
  publisher = "Nature Publishing Group",
  volume    =  518,
  number    =  7540,
  pages     = "529--533",
  month     =  feb,
  year      =  2015,
  keywords  = "comp-cog-sci",
  issn      = "0028-0836, 1476-4687",
  doi       = "10.1038/nature14236"
}

@ARTICLE{Newell1956-lm,
  title    = "The Logic Theory {Machine--{{A}}} Complex Information Processing
              System",
  author   = "Newell, A and Simon, H",
  abstract = "In this paper we describe a complex information processing
              system, which we call the logic theory machine, that is capable
              of discovering proofs for theorems in symbolic logic. This
              system, in contrast to the systematic algorithms that are
              ordinarily employed in computation, relies heavily on heuristic
              methods similar to those that have been observed in . human
              problem solving activity. The specification is written in a
              formal language, of the nature of a pseudo-code, that is suitable
              for coding for digital computers. However, the present paper is
              concerned exclusively with specification of the system, and not
              with its realization in a computer. The logic theory machine is
              part of a program of research to understand complex information
              processing systems by specifying and synthesizing a substantial
              variety of such systems for empirical study.",
  journal  = "IRE Transactions on Information Theory",
  volume   =  2,
  number   =  3,
  pages    = "61--79",
  month    =  sep,
  year     =  1956,
  keywords = "Automatic programming,Formal languages,Heuristic
              algorithms,Humans,Information analysis,Information
              processing,Logic,Pattern recognition,Problem-solving;comp-cog-sci",
  issn     = "2168-2712",
  doi      = "10.1109/TIT.1956.1056797"
}

@ARTICLE{Nobandegani_undated-cc,
  title    = "Example {{Generation Under Constraints Using Cascade Correlation
              Neural Nets}}",
  author   = "Nobandegani, Ardavan S and Shultz, Thomas R",
  abstract = "Humans not only can effortlessly imagine a wide range of novel
              instances and scenarios when prompted (e.g., a new shirt), but
              more remarkably, they can adequately generate examples which
              satisfy a given set of constraints (e.g., a new, dotted, pink
              shirt). Recently, Nobandegani and Shultz (2017) proposed a
              framework which permits converting deterministic, discriminative
              neural nets into probabilistic generative models. In this work,
              we formally show that an extension of this framework allows for
              generating examples under a wide range of constraints.
              Furthermore, we show that this framework is consistent with
              developmental findings on children's generative abilities, and
              can account for a developmental shift in infants' probabilistic
              learning and reasoning. We discuss the importance of integrating
              Bayesian and connectionist approaches to computational
              developmental psychology, and how our work contributes to that
              research.",
  pages    = "6",
  keywords = "comp-cog-sci"
}

@ARTICLE{Nye2020-np,
  title    = "Learning compositional rules via neural program synthesis",
  author   = "Nye, Maxwell and Solar-Lezama, Armando and Tenenbaum, Josh and
              Lake, Brenden M",
  abstract = "Many aspects of human reasoning, including language, require
              learning rules from very little data. Humans can do this, often
              learning systematic rules from very few examples, and combining
              these rules to form compositional rule-based systems. Current
              neural architectures, on the other hand, often fail to generalize
              in a compositional manner, especially when evaluated in ways that
              vary systematically from training. In this work, we present a
              neuro-symbolic model which learns entire rule systems from a
              small set of examples. Instead of directly predicting outputs
              from inputs, we train our model to induce the explicit system of
              rules governing a set of previously seen examples, drawing upon
              techniques from the neural program synthesis literature. Our
              rule-synthesis approach outperforms neural meta-learning
              techniques in three domains: an artificial instruction-learning
              domain used to evaluate human learning, the SCAN challenge
              datasets, and learning rule-based translations of number words
              into integers for a wide range of human languages.",
  journal  = "Adv. Neural Inf. Process. Syst.",
  volume   =  33,
  pages    = "10832--10842",
  year     =  2020,
  keywords = "read;comp-cog-sci",
  issn     = "1049-5258"
}

@ARTICLE{Piantadosi2016-fe,
  title    = "Four {{Problems Solved}} by the {{Probabilistic Language}} of
              {{Thought}}",
  author   = "Piantadosi, Steven T and Jacobs, Robert A",
  abstract = "We argue for the advantages of the probabilistic language of
              thought (pLOT), a recently emerging approach to modeling human
              cognition. Work using this framework demonstrates how the pLOT
              (a) refines the debate between symbols and statistics in
              cognitive modeling, (b) permits theories that draw on insights
              from both nativist and empiricist approaches, (c) explains the
              origins of novel and complex computational concepts, and (d)
              provides a framework for abstraction that can link sensation and
              conception. In each of these areas, the pLOT provides a
              productive middle ground between historical divides in cognitive
              psychology, pointing to a promising way forward for the field.",
  journal  = "Curr. Dir. Psychol. Sci.",
  volume   =  25,
  number   =  1,
  pages    = "54--59",
  month    =  feb,
  year     =  2016,
  keywords = "comp-cog-sci",
  issn     = "0963-7214, 1467-8721",
  doi      = "10.1177/0963721415609581"
}

@ARTICLE{Piloto2022-yi,
  title    = "Intuitive Physics Learning in a {Deep-Learning} Model Inspired by
              Developmental Psychology",
  author   = "Piloto, Luis S and Weinstein, Ari and Battaglia, Peter and
              Botvinick, Matthew",
  abstract = "Abstract `Intuitive physics' enables our pragmatic engagement
              with the physical world and forms a key component of `common
              sense' aspects of thought. Current artificial intelligence
              systems pale in their understanding of intuitive physics, in
              comparison to even very young children. Here we address this gap
              between humans and machines by drawing on the field of
              developmental psychology. First, we introduce and open-source a
              machine-learning dataset designed to evaluate conceptual
              understanding of intuitive physics, adopting the
              violation-of-expectation (VoE) paradigm from developmental
              psychology. Second, we build a deep-learning system that learns
              intuitive physics directly from visual data, inspired by studies
              of visual cognition in children. We demonstrate that our model
              can learn a diverse set of physical concepts, which depends
              critically on object-level representations, consistent with
              findings from developmental psychology. We consider the
              implications of these results both for AI and for research on
              human cognition.",
  journal  = "Nature Human Behaviour",
  month    =  jul,
  year     =  2022,
  keywords = "development",
  issn     = "2397-3374",
  doi      = "10.1038/s41562-022-01394-8"
}

@ARTICLE{Pitt_undated-sp,
  title    = "Exact {{Number Concepts Are Limited}} to the {{Verbal Count
              Range}}",
  author   = "Pitt, Benjamin and Gibson, Edward and Piantadosi, Steven T",
  abstract = "Previous findings suggest that mentally representing exact
              numbers larger than four depends on a verbal count routine (e.g.,
              ``one, two, three . . .''). However, these findings are
              controversial because they rely on comparisons across radically
              different languages and cultures. We tested the role of language
              in number concepts within a single population---the Tsimane' of
              Bolivia---in which knowledge of number words varies across
              individual adults. We used a novel data-analysis model to
              quantify the point at which participants (N = 30) switched from
              exact to approximate number representations during a simple
              numerical matching task. The results show that these behavioral
              switch points were bounded by participants' verbal count ranges;
              their representations of exact cardinalities were limited to the
              number words they knew. Beyond that range, they resorted to
              numerical approximation. These results resolve competing accounts
              of previous findings and provide unambiguous evidence that large
              exact number concepts are enabled by language.",
  pages    = "11",
  keywords = "comp-cog-sci"
}

@ARTICLE{Premack1997-aj,
  title    = "Infants {{Attribute {Value}}$\pm$} to the {{{Goal-Directed}
              Actions}} of {{Self-propelled Objects}}",
  author   = "Premack, David and Premack, Ann James",
  abstract = "Motion is a fundamental source of information for basic human
              interpretations; it is basic to the fundamental concept of
              causality and, the present model argues, equally basic to the
              fundamental concept of intentionality.The model is based on two
              main assumptions: When an infant perceives an object (1) moving
              spontaneously and (2) displaying goaldirected action, it will
              interpret the object as intentional and assign to it the unique
              properties of the psychological domain. The key property tested
              was: Do infants attribute value to interactions between
              intentional objects using criteria specified by the model?We
              showed infants (average age 52 weeks) computer-generated
              animations of spontaneously moving ``balls,'' using looking time
              in a standard habituation/dishabituation paradigm. In two
              positive interactions, one ball either ``caressed'' another, or
              ``helped'' it achieve its goal; whereas in two negative
              interactions, one ball either ``hit`` another, or ``prevented''
              it from achieving its goal. In keeping with predictions of the
              model, when transferred to a negative condition, infants who had
              been habituated on a positive condition showed greater
              dishabituation than those habituated on a negative condition. The
              results could not be easily explained by the similarity relations
              among the animations depicting the interactions.The results
              suggest that well before the age when the child can ascribe
              mental states or has a ``theory of mind,'' it recognizes the
              goals of self-propelled objects and attributes value to the
              interactions between them.",
  journal  = "J. Cogn. Neurosci.",
  volume   =  9,
  number   =  6,
  pages    = "848--856",
  month    =  nov,
  year     =  1997,
  keywords = "development",
  issn     = "0898-929X",
  doi      = "10.1162/jocn.1997.9.6.848"
}

@TECHREPORT{Rule2018-zm,
  title       = "Learning List Concepts through Program Induction",
  author      = "Rule, Joshua and Schulz, Eric and Piantadosi, Steven T and
                 Tenenbaum, Joshua B",
  abstract    = "Humans master complex systems of interrelated concepts like
                 mathematics and natural language. Previous work suggests
                 learning these systems relies on iteratively and directly
                 revising a language-like conceptual representation. We
                 introduce and assess a novel concept learning paradigm called
                 Martha's Magical Machines that captures complex relationships
                 between concepts. We model human concept learning in this
                 paradigm as a search in the space of term rewriting systems,
                 previously developed as an abstract model of computation. Our
                 model accurately predicts that participants learn some
                 transformations more easily than others and that they learn
                 harder concepts more easily using a bootstrapping curriculum
                 focused on their compositional parts. Our results suggest that
                 term rewriting systems may be a useful model of human
                 conceptual representations.",
  institution = "Animal Behavior and Cognition",
  month       =  may,
  year        =  2018,
  keywords    = "comp-cog-sci",
  doi         = "10.1101/321505"
}

@UNPUBLISHED{Scherrer2021-wg,
  title    = "Learning {{Neural Causal Models}} with {{Active Interventions}}",
  author   = "Scherrer, Nino and Bilaniuk, Olexa and Annadani, Yashas and
              Goyal, Anirudh and Schwab, Patrick and Sch{\"o}lkopf, Bernhard
              and Mozer, Michael C and Bengio, Yoshua and Bauer, Stefan and Ke,
              Nan Rosemary",
  abstract = "Discovering causal structures from data is a challenging
              inference problem of fundamental importance in all areas of
              science. The appealing scaling properties of neural networks have
              recently led to a surge of interest in differentiable neural
              network-based methods for learning causal structures from data.
              So far differentiable causal discovery has focused on static
              datasets of observational or interventional origin. In this work,
              we introduce an active intervention-targeting mechanism which
              enables a quick identification of the underlying causal structure
              of the data-generating process. Our method significantly reduces
              the required number of interactions compared with random
              intervention targeting and is applicable for both discrete and
              continuous optimization formulations of learning the underlying
              directed acyclic graph (DAG) from data. We examine the proposed
              method across a wide range of settings and demonstrate superior
              performance on multiple benchmarks from simulated to real-world
              data.",
  month    =  sep,
  year     =  2021,
  keywords = "Computer Science - Machine Learning,Statistics - Machine
              Learning;comp-cog-sci"
}

@ARTICLE{Shultz_undated-cv,
  title    = "Probability {{Without Counting}} and {{Dividing}}: {{A Fresh
              Computational Perspective}}",
  author   = "Shultz, Thomas R and Nobandegani, Ardavan S",
  abstract = "Recent experiments show that preverbal infants can reason
              probabilistically. This raises a deep puzzle because infants lack
              the counting and dividing abilities presumably required to
              compute probabilities. In the standard way of computing
              probabilities, they would have to count or accurately estimate
              large frequencies and divide those values by their total. Here,
              we present a novel neural-network model that learns and uses
              probability distributions without explicit counting or dividing.
              Probability distributions emerge naturally from neural-network
              learning of event sequences, providing a computationally
              sufficient explanation of how infants could succeed at
              probabilistic reasoning. Several alternative explanations are
              discussed and ruled out. Our work bears on several other active
              literatures, and it suggests an effective way to integrate
              Bayesian and neural-network approaches to cognition.",
  pages    = "7",
  keywords = "comp-cog-sci;development"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INCOLLECTION{Turing2009-sc,
  title     = "Computing {{Machinery}} and {{Intelligence}}",
  booktitle = "Parsing the {{Turing Test}}: {{Philosophical}} and
               {{Methodological Issues}} in the {{Quest}} for the {{Thinking
               Computer}}",
  author    = "Turing, Alan M",
  editor    = "Epstein, Robert and Roberts, Gary and Beber, Grace",
  abstract  = "I propose to consider the question, ``Can machines think?''
               This should begin with definitions of the meaning of the terms
               ``machine'' and ``think''. The definitions might be framed so as
               to reflect so far as possible the normal use of the words, but
               this attitude is dangerous. If the meaning of the words
               ``machine'' and ``think'' are to be found by examining how they
               are commonly used it is difficult to escape the conclusion that
               the meaning and the answer to the question, ``Can machines
               think?'' is to be sought in a statistical survey such as a
               Gallup poll.",
  publisher = "Springer Netherlands",
  pages     = "23--65",
  year      =  2009,
  address   = "Dordrecht",
  keywords  = "Computing Machinery,Digital Computer,Performance Capacity,Real
               Robot,Turing Machine;comp-cog-sci",
  isbn      = "9781402067105",
  doi       = "10.1007/978-1-4020-6710-5\_3"
}

@ARTICLE{Vaswani_undated-fb,
  title    = "Attention Is {{All}} You {{Need}}",
  author   = "Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit,
              Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz
              and Polosukhin, Illia",
  abstract = "The dominant sequence transduction models are based on complex
              recurrent or convolutional neural networks that include an
              encoder and a decoder. The best performing models also connect
              the encoder and decoder through an attention mechanism. We
              propose a new simple network architecture, the Transformer, based
              solely on attention mechanisms, dispensing with recurrence and
              convolutions entirely. Experiments on two machine translation
              tasks show these models to be superior in quality while being
              more parallelizable and requiring significantly less time to
              train. Our model achieves 28.4 BLEU on the WMT 2014
              Englishto-German translation task, improving over the existing
              best results, including ensembles, by over 2 BLEU. On the WMT
              2014 English-to-French translation task, our model establishes a
              new single-model state-of-the-art BLEU score of 41.0 after
              training for 3.5 days on eight GPUs, a small fraction of the
              training costs of the best models from the literature.",
  pages    = "11",
  keywords = "machine-learning"
}

@ARTICLE{Erickson2011-on,
  title    = "Exercise Training Increases Size of Hippocampus and Improves
              Memory",
  author   = "Erickson, K I and Voss, M W and Prakash, R S and Basak, C and
              Szabo, A and Chaddock, L and Kim, J S and Heo, S and Alves, H and
              White, S M and Wojcicki, T R and Mailey, E and Vieira, V J and
              Martin, S A and Pence, B D and Woods, J A and McAuley, E and
              Kramer, A F",
  journal  = "Proceedings of the National Academy of Sciences",
  volume   =  108,
  number   =  7,
  pages    = "3017--3022",
  month    =  feb,
  year     =  2011,
  keywords = "exercise-brain",
  issn     = "0027-8424, 1091-6490",
  doi      = "10.1073/pnas.1015950108"
}

@ARTICLE{Hill2019-uj,
  title    = "{{{BDNF}}}, Endurance Activity, and Mechanisms Underlying the
              Evolution of Hominin Brains",
  author   = "Hill, Tyler and Polk, John D",
  abstract = "Objectives As a complex, polygenic trait, brain size has likely
              been influenced by a range of direct and indirect selection
              pressures for both cognitive and non-cognitive functions and
              capabilities. It has been hypothesized that hominin brain
              expansion was, in part, a correlated response to selection acting
              on aerobic capacity (Raichlen \& Polk, 2013). According to this
              hypothesis, selection for aerobic capacity increased the activity
              of various signaling molecules, including those involved in brain
              growth. One key molecule is brain-derived neurotrophic factor
              (BDNF), a protein that regulates neuronal development, survival,
              and plasticity in mammals. This review updates, partially tests,
              and expands Raichlen and Polk's (2013) hypothesis by evaluating
              evidence for BDNF as a mediator of brain size. Discussion We
              contend that selection for endurance capabilities in a hot
              climate favored changes to muscle composition, mitochondrial
              dynamics and increased energy budget through pathways involving
              regulation of PGC-1$\alpha$ and MEF2 genes, both of which promote
              BDNF activity. In addition, the evolution of hairlessness and the
              skin's thermoregulatory response provide other molecular pathways
              that promote both BDNF activity and neurotransmitter synthesis.
              We discuss how these pathways contributed to the evolution of
              brain size and function in human evolution and propose avenues
              for future research. Our results support Raichlen and Polk's
              contention that selection for non-cognitive functions has direct
              mechanistic linkages to the evolution of brain size in hominins.",
  journal  = "Am. J. Phys. Anthropol.",
  volume   =  168,
  number   = "S67",
  pages    = "47--62",
  year     =  2019,
  keywords = "BDNF,brain
              growth,exercise,MEF2,neurotrophins,PGC-1$\alpha$,thermoregulation;exercise-brain",
  issn     = "0002-9483, 1096-8644",
  doi      = "10.1002/ajpa.23762"
}

@ARTICLE{Hung2018-fi,
  title     = "Effect of {{Acute Exercise Mode}} on {{Serum {Brain-Derived}
               Neurotrophic Factor}} ({{{BDNF}}}) and {{Task Switching
               Performance}}",
  author    = "Hung, Chiao-Ling and Tseng, Jun-Wei and Chao, Hsiao-Han and
               Hung, Tsung-Min and Wang, Ho-Seng",
  abstract  = "Previous studies have consistently reported a positive effect of
               acute exercise on cognition, particularly on executive function.
               However, most studies have focused on aerobic and resistant
               forms of exercise. The purpose of this study was to compare the
               effect of `open-skill' with `closed-skill' exercise (defined in
               terms of the predictability of the performing environment) on
               brain-derived neurotrophic factor (BDNF) production and task
               switching performance. Twenty young adult males participated in
               both closed (running) and open (badminton) skill exercise
               sessions in a counterbalanced order on separate days. The
               exercise sessions consisted of 5 min of warm up exercises
               followed by 30 min of running or badminton. The exercise
               intensity was set at 60\% ($\pm$5\%) of the heart rate reserve
               level (HRR) with HR being monitored by a wireless heart rate
               monitor. Blood samples were taken and participation in a
               task-switching paradigm occurred before and after each exercise
               session. Results showed no differences in serum BDNF or
               task-switching performance at the pre-test stage, however,
               badminton exercise resulted in significantly higher serum BDNF
               levels (a proxy for levels of BDNF in the brain) and near
               significant smaller global switching costs relative to running.
               This study has provided preliminary evidence in support the
               relative benefits of open-skills exercises on BDNF and executive
               function.",
  journal   = "J. Clin. Med. Res.",
  publisher = "Multidisciplinary Digital Publishing Institute",
  volume    =  7,
  number    =  10,
  pages     = "301",
  month     =  oct,
  year      =  2018,
  keywords  = "closed-skill,executive function,open-skill,switch
               cost;exercise-brain",
  issn      = "1918-3003",
  doi       = "10.3390/jcm7100301"
}

@ARTICLE{Ruegsegger2017-yh,
  title     = "Running from {{Disease}}: {{Molecular Mechanisms Associating
               Dopamine}} and {{Leptin Signaling}} in the {{Brain}} with
               {{Physical Inactivity}}, {{Obesity}}, and {{Type}} 2
               {{Diabetes}}",
  author    = "Ruegsegger, Gregory N and Booth, Frank W",
  abstract  = "Physical inactivity is a primary contributor to diseases such as
               obesity, cardiovascular disease, and Type 2 diabetes.
               Accelerometry data suggest that a majority of U.S. adults fail
               to perform substantial levels of physical activity needed to
               improve health. Thus, understanding the molecular factors that
               stimulate physical activity, and physical inactivity, is
               imperative for the development of strategies to reduce sedentary
               behavior and in turn prevent chronic disease. Despite many of
               the well-known health benefits of physical activity being
               described, little is known about genetic and biological factors
               that may influence this complex behavior. The mesolimbic
               dopamine system regulates motivating and rewarding behavior as
               well as motor movement. Here, we present data supporting the
               hypothesis that obesity may mechanistically lower voluntary
               physical activity levels via dopamine dysregulation. In doing
               so, we review data that suggests mesolimbic dopamine activity is
               a strong contributor to voluntary physical activity behavior. We
               also summarize findings suggesting that obesity leads to central
               dopaminergic dysfunction, which in turn contributes to
               reductions in physical activity that often accompany obesity.
               Additionally, we highlight examples in which central leptin
               activity influences physical activity levels in a
               dopamine-dependent manner. Future elucidation of these
               mechanisms will help support strategies to increase physical
               activity levels in obese patients and prevent diseases caused by
               physical inactivity.",
  journal   = "Front. Endocrinol.",
  publisher = "Frontiers",
  volume    =  0,
  year      =  2017,
  keywords  = "Dopamine,Leptin,Motivation,Nucleus Accumbens,physical
               activity,physical inactivity;exercise-brain",
  issn      = "1664-2392",
  doi       = "10.3389/fendo.2017.00109"
}

@ARTICLE{Levine2014-bg,
  title    = "Low {{Protein Intake Is Associated}} with a {{Major Reduction}}
              in {{{IGF-1}}}, {{Cancer}}, and {{Overall Mortality}} in the 65
              and {{Younger}} but {{Not Older Population}}",
  author   = "Levine, Morgan E and Suarez, Jorge A and Brandhorst, Sebastian
              and Balasubramanian, Priya and Cheng, Chia-Wei and Madia,
              Federica and Fontana, Luigi and Mirisola, Mario G and
              Guevara-Aguirre, Jaime and Wan, Junxiang and Passarino, Giuseppe
              and Kennedy, Brian K and Wei, Min and Cohen, Pinchas and
              Crimmins, Eileen M and Longo, Valter D",
  abstract = "Mice and humans with growth hormone receptor/ IGF-1 deficiencies
              display major reductions in agerelated diseases. Because protein
              restriction reduces GHR-IGF-1 activity, we examined links between
              protein intake and mortality. Respondents aged 50--65 reporting
              high protein intake had a 75\% increase in overall mortality and
              a 4-fold increase in cancer death risk during the following 18
              years. These associations were either abolished or attenuated if
              the proteins were plant derived. Conversely, high protein intake
              was associated with reduced cancer and overall mortality in
              respondents over 65, but a 5-fold increase in diabetes mortality
              across all ages. Mouse studies confirmed the effect of high
              protein intake and GHR-IGF-1 signaling on the incidence and
              progression of breast and melanoma tumors, but also the
              detrimental effects of a low protein diet in the very old. These
              results suggest that low protein intake during middle age
              followed by moderate to high protein consumption in old adults
              may optimize healthspan and longevity.",
  journal  = "Cell Metab.",
  volume   =  19,
  number   =  3,
  pages    = "407--417",
  month    =  mar,
  year     =  2014,
  keywords = "longevity",
  issn     = "1550-4131",
  doi      = "10.1016/j.cmet.2014.02.006"
}

@INPROCEEDINGS{Gal2016-il,
  title     = "Dropout as a {{Bayesian Approximation}}: {{Representing Model
               Uncertainty}} in {{Deep Learning}}",
  booktitle = "Proceedings of The 33rd International Conference on Machine
               Learning",
  author    = "Gal, Yarin and Ghahramani, Zoubin",
  editor    = "Balcan, Maria Florina and Weinberger, Kilian Q",
  abstract  = "Deep learning tools have gained tremendous attention in applied
               machine learning. However such tools for regression and
               classification do not capture model uncertainty. In comparison,
               Bayesian models offer a mathematically grounded framework to
               reason about model uncertainty, but usually come with a
               prohibitive computational cost. In this paper we develop a new
               theoretical framework casting dropout training in deep neural
               networks (NNs) as approximate Bayesian inference in deep
               Gaussian processes. A direct result of this theory gives us
               tools to model uncertainty with dropout NNs -- extracting
               information from existing models that has been thrown away so
               far. This mitigates the problem of representing uncertainty in
               deep learning without sacrificing either computational
               complexity or test accuracy. We perform an extensive study of
               the properties of dropout's uncertainty. Various network
               architectures and non-linearities are assessed on tasks of
               regression and classification, using MNIST as an example. We
               show a considerable improvement in predictive log-likelihood and
               RMSE compared to existing state-of-the-art methods, and finish
               by using dropout's uncertainty in deep reinforcement learning.",
  publisher = "PMLR",
  volume    =  48,
  pages     = "1050--1059",
  series    = "Proceedings of Machine Learning Research",
  year      =  2016,
  address   = "New York, New York, USA",
  keywords  = "machine-learning"
}

@ARTICLE{Brooks1991-sg,
  title    = "Intelligence without representation",
  author   = "Brooks, Rodney A",
  abstract = "Artificial intelligence research has foundered on the issue of
              representation. When intelligence is approached in an incremental
              manner, with strict reliance on interfacing to the real world
              through perception and action, reliance on representation
              disappears. In this paper we outline our approach to
              incrementally building complete intelligent Creatures. The
              fundamental decomposition of the intelligent system is not into
              independent information processing units which must interface
              with each other via representations. Instead, the intelligent
              system is decomposed into independent and parallel activity
              producers which all interface directly to the world through
              perception and action, rather than interface to each other
              particularly much. The notions of central and peripheral systems
              evaporate---everything is both central and peripheral. Based on
              these principles we have built a very successful series of mobile
              robots which operate without supervision as Creatures in standard
              office environments.",
  journal  = "Artif. Intell.",
  volume   =  47,
  number   =  1,
  pages    = "139--159",
  month    =  jan,
  year     =  1991,
  keywords = "project 2",
  issn     = "0004-3702",
  doi      = "10.1016/0004-3702(91)90053-M"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Chevalier2022-ot,
  title     = "Special issue on development of self-regulation, cognitive
               control, and executive function, Part {II}: Editorial note",
  author    = "Chevalier, Nicolas and Lipina, Sebasti{\'a}n and Scerif, Gaia
               and Segretin, M Soledad",
  abstract  = "Special issue on development of self-regulation, cognitive
               control, and executive function, Part II: Editorial note ---
               University of Edinburgh Research Explorer Skip to main
               navigation Skip to ",
  journal   = "Dev. Sci.",
  publisher = "research.ed.ac.uk",
  volume    =  25,
  number    =  6,
  pages     = "e13326",
  month     =  nov,
  year      =  2022,
  keywords  = "development",
  language  = "en",
  issn      = "1363-755X, 1467-7687",
  pmid      = "36112772",
  doi       = "10.1111/desc.13326"
}

@ARTICLE{Sharma2021-xf,
  title         = "Skill Induction and Planning with Latent Language",
  author        = "Sharma, Pratyusha and Torralba, Antonio and Andreas, Jacob",
  abstract      = "We present a framework for learning hierarchical policies
                   from demonstrations, using sparse natural language
                   annotations to guide the discovery of reusable skills for
                   autonomous decision-making. We formulate a generative model
                   of action sequences in which goals generate sequences of
                   high-level subtask descriptions, and these descriptions
                   generate sequences of low-level actions. We describe how to
                   train this model using primarily unannotated demonstrations
                   by parsing demonstrations into sequences of named high-level
                   subtasks, using only a small number of seed annotations to
                   ground language in action. In trained models, natural
                   language commands index a combinatorial library of skills;
                   agents can use these skills to plan by generating high-level
                   instruction sequences tailored to novel goals. We evaluate
                   this approach in the ALFRED household simulation
                   environment, providing natural language annotations for only
                   10\% of demonstrations. It achieves task completion rates
                   comparable to state-of-the-art models (outperforming several
                   recent methods with access to ground-truth plans during
                   training and evaluation) while providing structured and
                   human-readable high-level plans.",
  month         =  oct,
  year          =  2021,
  keywords      = "read;comp-cog-sci;ARC Project",
  archivePrefix = "arXiv",
  eprint        = "2110.01517",
  primaryClass  = "cs.LG",
  arxivid       = "2110.01517"
}

@INPROCEEDINGS{Mueller2022-pc,
  title     = "Coloring the Blank Slate: Pre-training Imparts a Hierarchical
               Inductive Bias to Sequence-to-sequence Models",
  booktitle = "Findings of the Association for Computational Linguistics: {ACL}
               2022",
  author    = "Mueller, Aaron and Frank, Robert and Linzen, Tal and Wang,
               Luheng and Schuster, Sebastian",
  abstract  = "Relations between words are governed by hierarchical structure
               rather than linear ordering. Sequence-to-sequence (seq2seq)
               models, despite their success in downstream NLP applications,
               often fail to generalize in a hierarchy-sensitive manner when
               performing syntactic transformations---for example, transforming
               declarative sentences into questions. However, syntactic
               evaluations of seq2seq models have only observed models that
               were not pre-trained on natural language data before being
               trained to perform syntactic transformations, in spite of the
               fact that pre-training has been found to induce hierarchical
               linguistic generalizations in language models; in other words,
               the syntactic capabilities of seq2seq models may have been
               greatly understated. We address this gap using the pre-trained
               seq2seq models T5 and BART, as well as their multilingual
               variants mT5 and mBART. We evaluate whether they generalize
               hierarchically on two transformations in two languages: question
               formation and passivization in English and German. We find that
               pre-trained seq2seq models generalize hierarchically when
               performing syntactic transformations, whereas models trained
               from scratch on syntactic transformations do not. This result
               presents evidence for the learnability of hierarchical syntactic
               information from non-annotated natural language text while also
               demonstrating that seq2seq models are capable of syntactic
               generalization, though only after exposure to much more language
               data than human learners receive.",
  publisher = "Association for Computational Linguistics",
  pages     = "1352--1368",
  month     =  may,
  year      =  2022,
  address   = "Dublin, Ireland",
  keywords  = "skimmed;compling-cogsci2023",
  doi       = "10.18653/v1/2022.findings-acl.106"
}

@ARTICLE{Ambridge2008-jt,
  title    = "Is Structure Dependence an Innate Constraint? New Experimental
              Evidence From Children's {Complex-Question} Production",
  author   = "Ambridge, Ben and Rowland, Caroline F and Pine, Julian M",
  abstract = "According to Crain and Nakayama (1987), when forming complex
              yes/no questions, children do not make errors such as Is the boy
              who smoking is crazy? because they have innate knowledge of
              structure dependence and so will not move the auxiliary from the
              relative clause. However, simple recurrent networks are also able
              to avoid such errors, on the basis of surface distributional
              properties of the input (Lewis \& Elman, 2001; Reali \&
              Christiansen, 2005). Two new elicited production studies revealed
              that (a) children occasionally produce structure-dependence
              errors and (b) the pattern of children's auxiliary-doubling
              errors (Is the boy who is smoking is crazy?) suggests a
              sensitivity to surface co-occurrence patterns in the input. This
              article concludes that current data do not provide any support
              for the claim that structure dependence is an innate constraint,
              and that it is possible that children form a structure-dependent
              grammar on the basis of exposure to input that exhibits this
              property.",
  journal  = "Cogn. Sci.",
  volume   =  32,
  number   =  1,
  pages    = "222--255",
  month    =  jan,
  year     =  2008,
  keywords = "skimmed;compling-cogsci2023",
  language = "en",
  issn     = "0364-0213",
  pmid     = "21635337",
  doi      = "10.1080/03640210701703766"
}

@ARTICLE{Lynch2020-tf,
  title         = "Language Conditioned Imitation Learning over Unstructured
                   Data",
  author        = "Lynch, Corey and Sermanet, Pierre",
  abstract      = "Natural language is perhaps the most flexible and intuitive
                   way for humans to communicate tasks to a robot. Prior work
                   in imitation learning typically requires each task be
                   specified with a task id or goal image -- something that is
                   often impractical in open-world environments. On the other
                   hand, previous approaches in instruction following allow
                   agent behavior to be guided by language, but typically
                   assume structure in the observations, actuators, or language
                   that limit their applicability to complex settings like
                   robotics. In this work, we present a method for
                   incorporating free-form natural language conditioning into
                   imitation learning. Our approach learns perception from
                   pixels, natural language understanding, and multitask
                   continuous control end-to-end as a single neural network.
                   Unlike prior work in imitation learning, our method is able
                   to incorporate unlabeled and unstructured demonstration data
                   (i.e. no task or language labels). We show this dramatically
                   improves language conditioned performance, while reducing
                   the cost of language annotation to less than 1\% of total
                   data. At test time, a single language conditioned visuomotor
                   policy trained with our method can perform a wide variety of
                   robotic manipulation skills in a 3D environment, specified
                   only with natural language descriptions of each task (e.g.
                   ``open the drawer...now pick up the block...now press the
                   green button...''). To scale up the number of instructions
                   an agent can follow, we propose combining text conditioned
                   policies with large pretrained neural language models. We
                   find this allows a policy to be robust to many
                   out-of-distribution synonym instructions, without requiring
                   new demonstrations. See videos of a human typing live text
                   commands to our agent at language-play.github.io",
  month         =  may,
  year          =  2020,
  keywords      = "ARC Project;comp-cog-sci",
  archivePrefix = "arXiv",
  eprint        = "2005.07648",
  primaryClass  = "cs.RO",
  arxivid       = "2005.07648"
}

@ARTICLE{Lynch2022-su,
  title         = "Interactive Language: Talking to Robots in Real Time",
  author        = "Lynch, Corey and Wahid, Ayzaan and Tompson, Jonathan and
                   Ding, Tianli and Betker, James and Baruch, Robert and
                   Armstrong, Travis and Florence, Pete",
  abstract      = "We present a framework for building interactive, real-time,
                   natural language-instructable robots in the real world, and
                   we open source related assets (dataset, environment,
                   benchmark, and policies). Trained with behavioral cloning on
                   a dataset of hundreds of thousands of language-annotated
                   trajectories, a produced policy can proficiently execute an
                   order of magnitude more commands than previous works:
                   specifically we estimate a 93.5\% success rate on a set of
                   87,000 unique natural language strings specifying raw
                   end-to-end visuo-linguo-motor skills in the real world. We
                   find that the same policy is capable of being guided by a
                   human via real-time language to address a wide range of
                   precise long-horizon rearrangement goals, e.g. ``make a
                   smiley face out of blocks''. The dataset we release
                   comprises nearly 600,000 language-labeled trajectories, an
                   order of magnitude larger than prior available datasets. We
                   hope the demonstrated results and associated assets enable
                   further advancement of helpful, capable,
                   natural-language-interactable robots. See videos at
                   https://interactive-language.github.io.",
  month         =  oct,
  year          =  2022,
  archivePrefix = "arXiv",
  eprint        = "2210.06407",
  primaryClass  = "cs.RO",
  arxivid       = "2210.06407"
}

@INBOOK{Lombrozo2019-my,
  title     = "``Learning by Thinking'' in Science and in Everyday Life",
  author    = "Lombrozo, Tania",
  abstract  = "AbstractThis chapter introduces ``learning by thinking'' (LbT)
               as a form of learning distinct from familiar forms of learning
               through observation. When learning b",
  publisher = "Oxford University Press",
  month     =  dec,
  year      =  2019,
  keywords  = "project 1",
  language  = "en",
  doi       = "10.1093/oso/9780190212308.003.0010"
}

@UNPUBLISHED{Patel2022-fg,
  title    = "Mapping Language Models to Grounded Conceptual Spaces",
  author   = "Patel, Roma and Pavlick, Ellie",
  abstract = "A fundamental criticism of text-only language models (LMs) is
              their lack of grounding---that is, the ability to tie a word for
              which they have learned a representation, to its actual use in
              the world. However, despite this limitation, large pre-trained
              LMs have been shown to have a remarkable grasp of the conceptual
              structure of language, as demonstrated by their ability to answer
              questions, generate fluent text, or make inferences about
              entities, objects, and properties that they have never physically
              observed. In this work we investigate the extent to which the
              rich conceptual structure that LMs learn indeed reflects the
              conceptual structure of the non-linguistic world---which is
              something that LMs have never observed. We do this by testing
              whether the LMs can learn to map an entire conceptual domain
              (e.g., direction or colour) onto a grounded world representation
              given only a small number of examples. For example, we show a
              model what the word ``left`` means using a textual depiction of a
              grid world, and assess how well it can generalise to related
              concepts, for example, the word ``right'', in a similar grid
              world. We investigate a range of generative language models of
              varying sizes (including GPT-2 and GPT-3), and see that although
              the smaller models struggle to perform this mapping, the largest
              model can not only learn to ground the concepts that it is
              explicitly taught, but appears to generalise to several instances
              of unseen concepts as well. Our results suggest an alternative
              means of building grounded language models: rather than learning
              grounded representations ``from scratch'', it is possible that
              large text-only models learn a sufficiently rich conceptual
              structure that could allow them to be grounded in a
              data-efficient way.",
  month    =  may,
  year     =  2022,
  keywords = "ARC Project;comp-cog-sci"
}

@ARTICLE{Das2023-ho,
  title     = "Combining Functional and Automata Synthesis to Discover Causal
               Reactive Programs",
  author    = "Das, Ria and Tenenbaum, Joshua B and Solar-Lezama, Armando and
               Tavares, Zenna",
  abstract  = "We present a new algorithm that synthesizes functional reactive
               programs from observation data. The key novelty is to iterate
               between a functional synthesis step, which attempts to generate
               a transition function over observed states, and an automata
               synthesis step, which adds any additional latent state necessary
               to fully account for the observations. We develop a functional
               reactive DSL called Autumn that can express a rich variety of
               causal dynamics in time-varying, Atari-style grid worlds, and
               apply our method to synthesize Autumn programs from data. We
               evaluate our algorithm on a benchmark suite of 30 Autumn
               programs as well as a third-party corpus of grid-world-style
               video games. We find that our algorithm synthesizes 27 out of 30
               programs in our benchmark suite and 21 out of 27 programs from
               the third-party corpus, including several programs describing
               complex latent state transformations, and from input traces
               containing hundreds of observations. We expect that our approach
               will provide a template for how to integrate functional and
               automata synthesis in other induction domains.",
  journal   = "Proc. ACM Program. Lang.",
  publisher = "Association for Computing Machinery",
  volume    =  7,
  number    = "POPL",
  pages     = "1628--1658",
  month     =  jan,
  year      =  2023,
  address   = "New York, NY, USA",
  keywords  = "causal, synthesis, automata, reactive;ARC Project;comp-cog-sci",
  doi       = "10.1145/3571249"
}

@ARTICLE{Acquaviva2021-wf,
  title         = "Communicating Natural Programs to Humans and Machines",
  author        = "Acquaviva, Samuel and Pu, Yewen and Kryven, Marta and
                   Sechopoulos, Theodoros and Wong, Catherine and Ecanow,
                   Gabrielle E and Nye, Maxwell and Tessler, Michael Henry and
                   Tenenbaum, Joshua B",
  abstract      = "The Abstraction and Reasoning Corpus (ARC) is a set of
                   procedural tasks that tests an agent's ability to flexibly
                   solve novel problems. While most ARC tasks are easy for
                   humans, they are challenging for state-of-the-art AI. What
                   makes building intelligent systems that can generalize to
                   novel situations such as ARC difficult? We posit that the
                   answer might be found by studying the difference of
                   \textbackslashemph\{language\}: While humans readily
                   generate and interpret instructions in a general language,
                   computer systems are shackled to a narrow domain-specific
                   language that they can precisely execute. We present LARC,
                   the \textbackslashtextit\{Language-complete ARC\}: a
                   collection of natural language descriptions by a group of
                   human participants who instruct each other on how to solve
                   ARC tasks using language alone, which contains successful
                   instructions for 88\% of the ARC tasks. We analyze the
                   collected instructions as `natural programs', finding that
                   while they resemble computer programs, they are distinct in
                   two ways: First, they contain a wide range of primitives;
                   Second, they frequently leverage communicative strategies
                   beyond directly executable codes. We demonstrate that these
                   two distinctions prevent current program synthesis
                   techniques from leveraging LARC to its full potential, and
                   give concrete suggestions on how to build the
                   next-generation program synthesizers.",
  month         =  jun,
  year          =  2021,
  keywords      = "ARC Project;comp-cog-sci",
  archivePrefix = "arXiv",
  eprint        = "2106.07824",
  primaryClass  = "cs.AI",
  arxivid       = "2106.07824"
}

@UNPUBLISHED{Bigelow2022-sr,
  title    = "{Non-Commitment} in Mental Imagery",
  author   = "Bigelow, Eric J and McCoy, John and Ullman, Tomer D",
  abstract = "We examine non-commitment in the imagination. Across 5 studies (N
              > 1, 800), we find that most people are non-committal about basic
              aspects of their mental images, including features that would be
              readily apparent in real images. While previous work on the
              imagination has discussed the possibility of non-commitment, this
              paper is the first, to our knowledge, to examine this
              systematically and empirically. We find that people do not commit
              to basic properties of specified mental scenes (Studies 1 and 2),
              and that people report non-commitment rather than uncertainty or
              forgetfulness (Study 3). Such non-commitment is present even for
              people with generally vivid imaginations, and those who report
              imagining the specified scene very vividly (Studies 4a, 4b).
              People readily confabulate properties of their mental images when
              non-commitment is not offered as an explicit option (Study 5).
              Taken together, these results establish non-commitment as a
              pervasive component of mental imagery.",
  month    =  oct,
  year     =  2022,
  keywords = "Imagination; mental imagery; non-commitment; vividness;ARC
              Project;comp-cog-sci",
  doi      = "10.31234/osf.io/pn4zd"
}

@ARTICLE{Gordon2020-qy,
  title         = "Compressing {BERT}: Studying the Effects of Weight Pruning
                   on Transfer Learning",
  author        = "Gordon, Mitchell A and Duh, Kevin and Andrews, Nicholas",
  abstract      = "Pre-trained universal feature extractors, such as BERT for
                   natural language processing and VGG for computer vision,
                   have become effective methods for improving deep learning
                   models without requiring more labeled data. While effective,
                   feature extractors like BERT may be prohibitively large for
                   some deployment scenarios. We explore weight pruning for
                   BERT and ask: how does compression during pre-training
                   affect transfer learning? We find that pruning affects
                   transfer learning in three broad regimes. Low levels of
                   pruning (30-40\%) do not affect pre-training loss or
                   transfer to downstream tasks at all. Medium levels of
                   pruning increase the pre-training loss and prevent useful
                   pre-training information from being transferred to
                   downstream tasks. High levels of pruning additionally
                   prevent models from fitting downstream datasets, leading to
                   further degradation. Finally, we observe that fine-tuning
                   BERT on a specific task does not improve its prunability. We
                   conclude that BERT can be pruned once during pre-training
                   rather than separately for each task without affecting
                   performance.",
  month         =  feb,
  year          =  2020,
  keywords      = "read;nlp",
  archivePrefix = "arXiv",
  eprint        = "2002.08307",
  primaryClass  = "cs.CL",
  arxivid       = "2002.08307"
}

@ARTICLE{Yang2022-ho,
  title         = "{TextPruner}: A Model Pruning Toolkit for {Pre-Trained}
                   Language Models",
  author        = "Yang, Ziqing and Cui, Yiming and Chen, Zhigang",
  abstract      = "Pre-trained language models have been prevailed in natural
                   language processing and become the backbones of many NLP
                   tasks, but the demands for computational resources have
                   limited their applications. In this paper, we introduce
                   TextPruner, an open-source model pruning toolkit designed
                   for pre-trained language models, targeting fast and easy
                   model compression. TextPruner offers structured
                   post-training pruning methods, including vocabulary pruning
                   and transformer pruning, and can be applied to various
                   models and tasks. We also propose a self-supervised pruning
                   method that can be applied without the labeled data. Our
                   experiments with several NLP tasks demonstrate the ability
                   of TextPruner to reduce the model size without re-training
                   the model.",
  month         =  mar,
  year          =  2022,
  keywords      = "skimmed;nlp",
  archivePrefix = "arXiv",
  eprint        = "2203.15996",
  primaryClass  = "cs.CL",
  arxivid       = "2203.15996"
}

@ARTICLE{Zafrir2021-pm,
  title         = "Prune Once for All: Sparse {Pre-Trained} Language Models",
  author        = "Zafrir, Ofir and Larey, Ariel and Boudoukh, Guy and Shen,
                   Haihao and Wasserblat, Moshe",
  abstract      = "Transformer-based language models are applied to a wide
                   range of applications in natural language processing.
                   However, they are inefficient and difficult to deploy. In
                   recent years, many compression algorithms have been proposed
                   to increase the implementation efficiency of large
                   Transformer-based models on target hardware. In this work we
                   present a new method for training sparse pre-trained
                   Transformer language models by integrating weight pruning
                   and model distillation. These sparse pre-trained models can
                   be used to transfer learning for a wide range of tasks while
                   maintaining their sparsity pattern. We demonstrate our
                   method with three known architectures to create sparse
                   pre-trained BERT-Base, BERT-Large and DistilBERT. We show
                   how the compressed sparse pre-trained models we trained
                   transfer their knowledge to five different downstream
                   natural language tasks with minimal accuracy loss. Moreover,
                   we show how to further compress the sparse models' weights
                   to 8bit precision using quantization-aware training. For
                   example, with our sparse pre-trained BERT-Large fine-tuned
                   on SQuADv1.1 and quantized to 8bit we achieve a compression
                   ratio of $40$X for the encoder with less than $1\%$ accuracy
                   loss. To the best of our knowledge, our results show the
                   best compression-to-accuracy ratio for BERT-Base,
                   BERT-Large, and DistilBERT.",
  month         =  nov,
  year          =  2021,
  keywords      = "read;nlp",
  archivePrefix = "arXiv",
  eprint        = "2111.05754",
  primaryClass  = "cs.CL",
  arxivid       = "2111.05754"
}

@ARTICLE{Squire1992-cp,
  title    = "Declarative and nondeclarative memory: multiple brain systems
              supporting learning and memory",
  author   = "Squire, L R",
  abstract = "Abstract The topic of multiple forms of memory is considered from
              a biological point of view. Fact-and-event (declarative,
              explicit) memory is contrasted with a collection of non conscious
              (non-declarative, implicit) memory abilities including skills and
              habits, priming, and simple conditioning. Recent evidence is
              reviewed indicating that declarative and non declarative forms of
              memory have different operating characteristics and depend on
              separate brain systems. A brain-systems framework for
              understanding memory phenomena is developed in light of lesion
              studies involving rats, monkeys, and humans, as well as recent
              studies with normal humans using the divided visual field
              technique, event-related potentials, and positron emission
              tomography (PET).",
  journal  = "J. Cogn. Neurosci.",
  volume   =  4,
  number   =  3,
  pages    = "232--243",
  year     =  1992,
  keywords = "read;cog-neuro;learning\&memory2023",
  language = "en",
  issn     = "0898-929X",
  pmid     = "23964880",
  doi      = "10.1162/jocn.1992.4.3.232"
}

@ARTICLE{Weir2022-cv,
  title         = "{One-Shot} Learning from a Demonstration with Hierarchical
                   Latent Language",
  author        = "Weir, Nathaniel and Yuan, Xingdi and C{\^o}t{\'e},
                   Marc-Alexandre and Hausknecht, Matthew and Laroche, Romain
                   and Momennejad, Ida and Van Seijen, Harm and Van Durme,
                   Benjamin",
  abstract      = "Humans have the capability, aided by the expressive
                   compositionality of their language, to learn quickly by
                   demonstration. They are able to describe unseen
                   task-performing procedures and generalize their execution to
                   other contexts. In this work, we introduce DescribeWorld, an
                   environment designed to test this sort of generalization
                   skill in grounded agents, where tasks are linguistically and
                   procedurally composed of elementary concepts. The agent
                   observes a single task demonstration in a Minecraft-like
                   grid world, and is then asked to carry out the same task in
                   a new map. To enable such a level of generalization, we
                   propose a neural agent infused with hierarchical latent
                   language--both at the level of task inference and subtask
                   planning. Our agent first generates a textual description of
                   the demonstrated unseen task, then leverages this
                   description to replicate it. Through multiple evaluation
                   scenarios and a suite of generalization tests, we find that
                   agents that perform text-based inference are better equipped
                   for the challenge under a random split of tasks.",
  month         =  mar,
  year          =  2022,
  keywords      = "ARC Project;comp-cog-sci",
  archivePrefix = "arXiv",
  eprint        = "2203.04806",
  primaryClass  = "cs.CL",
  arxivid       = "2203.04806"
}

@ARTICLE{Kumar2022-lq,
  title         = "Using Natural Language and Program Abstractions to Instill
                   Human Inductive Biases in Machines",
  author        = "Kumar, Sreejan and Correa, Carlos G and Dasgupta, Ishita and
                   Marjieh, Raja and Hu, Michael Y and Hawkins, Robert D and
                   Daw, Nathaniel D and Cohen, Jonathan D and Narasimhan,
                   Karthik and Griffiths, Thomas L",
  abstract      = "Strong inductive biases give humans the ability to quickly
                   learn to perform a variety of tasks. Although meta-learning
                   is a method to endow neural networks with useful inductive
                   biases, agents trained by meta-learning may sometimes
                   acquire very different strategies from humans. We show that
                   co-training these agents on predicting representations from
                   natural language task descriptions and programs induced to
                   generate such tasks guides them toward more human-like
                   inductive biases. Human-generated language descriptions and
                   program induction models that add new learned primitives
                   both contain abstract concepts that can compress description
                   length. Co-training on these representations result in more
                   human-like behavior in downstream meta-reinforcement
                   learning agents than less abstract controls (synthetic
                   language descriptions, program induction without learned
                   primitives), suggesting that the abstraction supported by
                   these representations is key.",
  month         =  may,
  year          =  2022,
  keywords      = "ARC Project;comp-cog-sci",
  archivePrefix = "arXiv",
  eprint        = "2205.11558",
  primaryClass  = "cs.AI",
  arxivid       = "2205.11558"
}

@ARTICLE{Glenberg2000-dv,
  title    = "Symbol Grounding and Meaning: A Comparison of {High-Dimensional}
              and Embodied Theories of Meaning",
  author   = "Glenberg, Arthur M and Robertson, David A",
  abstract = "Latent Semantic Analysis (Landauer \& Dumais, 1997) and
              Hyperspace Analogue to Language (Burgess \& Lund, 1997) model
              meaning as the relations among abstract symbols that are
              arbitrarily related to what they signify. These symbols are
              ungrounded in that they are not tied to perceptual experience or
              action. Because the symbols are ungrounded, they cannot, in
              principle, capture the meaning of novel situations. In contrast,
              participants in three experiments found it trivially easy to
              discriminate between descriptions of sensible novel situations
              (e.g., using a newspaper to protect one's face from the wind) and
              nonsense novel situations (e.g., using a matchbook to protect
              one's face from the wind). These results support the Indexical
              Hypothesis that the meaning of a sentence is constructed by (a)
              indexing words and phrases to real objects or perceptual, analog
              symbols; (b) deriving affordances from the objects and symbols;
              and (c) meshing the affordances under the guidance of syntax.",
  journal  = "J. Mem. Lang.",
  volume   =  43,
  number   =  3,
  pages    = "379--401",
  month    =  oct,
  year     =  2000,
  keywords = "meaning; language; embodiment; computational models; Latent
              Semantic Analysis; Hyperspace Analogue to
              Language;compling-cogsci2023",
  issn     = "0749-596X",
  doi      = "10.1006/jmla.2000.2714"
}

@ARTICLE{Peterson2021-nw,
  title    = "Using large-scale experiments and machine learning to discover
              theories of human decision-making",
  author   = "Peterson, Joshua C and Bourgin, David D and Agrawal, Mayank and
              Reichman, Daniel and Griffiths, Thomas L",
  abstract = "Predicting and understanding how people make decisions has been a
              long-standing goal in many fields, with quantitative models of
              human decision-making informing research in both the social
              sciences and engineering. We show how progress toward this goal
              can be accelerated by using large datasets to power
              machine-learning algorithms that are constrained to produce
              interpretable psychological theories. Conducting the largest
              experiment on risky choice to date and analyzing the results
              using gradient-based optimization of differentiable decision
              theories implemented through artificial neural networks, we were
              able to recapitulate historical discoveries, establish that there
              is room to improve on existing theories, and discover a new, more
              accurate model of human decision-making in a form that preserves
              the insights from centuries of research.",
  journal  = "Science",
  volume   =  372,
  number   =  6547,
  pages    = "1209--1214",
  month    =  jun,
  year     =  2021,
  language = "en",
  issn     = "0036-8075, 1095-9203",
  pmid     = "34112693",
  doi      = "10.1126/science.abe2629"
}

@ARTICLE{Merrill2022-sv,
  title         = "Entailment Semantics Can Be Extracted from an Ideal Language
                   Model",
  author        = "Merrill, William and Warstadt, Alex and Linzen, Tal",
  abstract      = "Language models are often trained on text alone, without
                   additional grounding. There is debate as to how much of
                   natural language semantics can be inferred from such a
                   procedure. We prove that entailment judgments between
                   sentences can be extracted from an ideal language model that
                   has perfectly learned its target distribution, assuming the
                   training sentences are generated by Gricean agents, i.e.,
                   agents who follow fundamental principles of communication
                   from the linguistic theory of pragmatics. We also show
                   entailment judgments can be decoded from the predictions of
                   a language model trained on such Gricean data. Our results
                   reveal a pathway for understanding the semantic information
                   encoded in unlabeled linguistic data and a potential
                   framework for extracting semantics from language models.",
  month         =  sep,
  year          =  2022,
  keywords      = "compling-cogsci2023",
  archivePrefix = "arXiv",
  eprint        = "2209.12407",
  primaryClass  = "cs.CL",
  arxivid       = "2209.12407"
}

@ARTICLE{Hu2019-wh,
  title    = "Hierarchical decision making by generating and following natural
              language instructions",
  author   = "Hu, Hengyuan and Yarats, Denis and Gong, Qucheng and Tian,
              Yuandong and Lewis, Mike",
  journal  = "Adv. Neural Inf. Process. Syst.",
  volume   =  32,
  year     =  2019,
  keywords = "ARC Project;comp-cog-sci",
  issn     = "1049-5258"
}

@ARTICLE{Odouard2022-dv,
  title         = "Evaluating Understanding on Conceptual Abstraction
                   Benchmarks",
  author        = "Odouard, Victor Vikram and Mitchell, Melanie",
  abstract      = "A long-held objective in AI is to build systems that
                   understand concepts in a humanlike way. Setting aside the
                   difficulty of building such a system, even trying to
                   evaluate one is a challenge, due to present-day AI's
                   relative opacity and its proclivity for finding shortcut
                   solutions. This is exacerbated by humans' tendency to
                   anthropomorphize, assuming that a system that can recognize
                   one instance of a concept must also understand other
                   instances, as a human would. In this paper, we argue that
                   understanding a concept requires the ability to use it in
                   varied contexts. Accordingly, we propose systematic
                   evaluations centered around concepts, by probing a system's
                   ability to use a given concept in many different
                   instantiations. We present case studies of such an
                   evaluations on two domains -- RAVEN (inspired by Raven's
                   Progressive Matrices) and the Abstraction and Reasoning
                   Corpus (ARC) -- that have been used to develop and assess
                   abstraction abilities in AI systems. Our concept-based
                   approach to evaluation reveals information about AI systems
                   that conventional test sets would have left hidden.",
  month         =  jun,
  year          =  2022,
  keywords      = "ARC Project;comp-cog-sci",
  archivePrefix = "arXiv",
  eprint        = "2206.14187",
  primaryClass  = "cs.AI",
  arxivid       = "2206.14187"
}

@UNPUBLISHED{Assouel2022-er,
  title    = "Object-centric Compositional Imagination for Visual Abstract
              Reasoning",
  author   = "Assouel, Rim and Rodriguez, Pau and Taslakian, Perouz and
              Vazquez, David and Bengio, Yoshua",
  abstract = "Like humans devoid of imagination, current machine learning
              systems lack the ability to adapt to new, unexpected situations
              by foreseeing them, which makes them unable to solve new tasks by
              analogical reasoning. In this work, we introduce a new
              compositional imagination framework that improves a model's
              ability to generalize. One of the key components of our framework
              is object-centric inductive biases that enables models to
              perceive the environment as a series of objects, properties, and
              transformations. By composing these key ingredients, it is
              possible to generate new unseen tasks that, when used to train
              the model, improve generalization. Experiments on a simplified
              version of the Abstraction and Reasoning Corpus (ARC) demonstrate
              the effectiveness of our framework.",
  month    =  jun,
  year     =  2022,
  keywords = "ARC Project;comp-cog-sci"
}

@INCOLLECTION{Weisberg2020-zy,
  title     = "Insight in {Problem-Solving} and Creative Thinking",
  booktitle = "Rethinking Creativity: {Inside-the-Box} Thinking as the Basis
               for Innovation",
  author    = "Weisberg, Robert W",
  abstract  = "Rethinking Creativity - September 2020",
  publisher = "Cambridge University Press",
  pages     = "215--248",
  month     =  sep,
  year      =  2020,
  keywords  = "Insight in problem-solving; insight in creativity; Aha!
               experiences; analytic thinking in insight;project 1",
  doi       = "10.1017/9781108785259.007"
}

@ARTICLE{Vysogorets2021-wi,
  title         = "Connectivity Matters: Neural Network Pruning Through the
                   Lens of Effective Sparsity",
  author        = "Vysogorets, Artem and Kempe, Julia",
  abstract      = "Neural network pruning is a fruitful area of research with
                   surging interest in high sparsity regimes. Benchmarking in
                   this domain heavily relies on faithful representation of the
                   sparsity of subnetworks, which has been traditionally
                   computed as the fraction of removed connections (direct
                   sparsity). This definition, however, fails to recognize
                   unpruned parameters that detached from input or output
                   layers of underlying subnetworks, potentially
                   underestimating actual effective sparsity: the fraction of
                   inactivated connections. While this effect might be
                   negligible for moderately pruned networks (up to 10-100
                   compression rates), we find that it plays an increasing role
                   for thinner subnetworks, greatly distorting comparison
                   between different pruning algorithms. For example, we show
                   that effective compression of a randomly pruned
                   LeNet-300-100 can be orders of magnitude larger than its
                   direct counterpart, while no discrepancy is ever observed
                   when using SynFlow for pruning [Tanaka et al., 2020]. In
                   this work, we adopt the lens of effective sparsity to
                   reevaluate several recent pruning algorithms on common
                   benchmark architectures (e.g., LeNet-300-100, VGG-19,
                   ResNet-18) and discover that their absolute and relative
                   performance changes dramatically in this new and more
                   appropriate framework. To aim for effective, rather than
                   direct, sparsity, we develop a low-cost extension to most
                   pruning algorithms. Further, equipped with effective
                   sparsity as a reference frame, we partially reconfirm that
                   random pruning with appropriate sparsity allocation across
                   layers performs as well or better than more sophisticated
                   algorithms for pruning at initialization [Su et al., 2020].
                   In response to this observation, using a simple analogy of
                   pressure distribution in coupled cylinders from physics, we
                   design novel layerwise sparsity quotas that outperform all
                   existing baselines in the context of random pruning.",
  month         =  jul,
  year          =  2021,
  keywords      = "nlp",
  archivePrefix = "arXiv",
  eprint        = "2107.02306",
  primaryClass  = "cs.LG",
  arxivid       = "2107.02306"
}

@ARTICLE{Brown2020-gd,
  title         = "Language Models are {Few-Shot} Learners",
  author        = "Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah,
                   Melanie and Kaplan, Jared and Dhariwal, Prafulla and
                   Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and
                   Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel
                   and Krueger, Gretchen and Henighan, Tom and Child, Rewon and
                   Ramesh, Aditya and Ziegler, Daniel M and Wu, Jeffrey and
                   Winter, Clemens and Hesse, Christopher and Chen, Mark and
                   Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess,
                   Benjamin and Clark, Jack and Berner, Christopher and
                   McCandlish, Sam and Radford, Alec and Sutskever, Ilya and
                   Amodei, Dario",
  abstract      = "Recent work has demonstrated substantial gains on many NLP
                   tasks and benchmarks by pre-training on a large corpus of
                   text followed by fine-tuning on a specific task. While
                   typically task-agnostic in architecture, this method still
                   requires task-specific fine-tuning datasets of thousands or
                   tens of thousands of examples. By contrast, humans can
                   generally perform a new language task from only a few
                   examples or from simple instructions - something which
                   current NLP systems still largely struggle to do. Here we
                   show that scaling up language models greatly improves
                   task-agnostic, few-shot performance, sometimes even reaching
                   competitiveness with prior state-of-the-art fine-tuning
                   approaches. Specifically, we train GPT-3, an autoregressive
                   language model with 175 billion parameters, 10x more than
                   any previous non-sparse language model, and test its
                   performance in the few-shot setting. For all tasks, GPT-3 is
                   applied without any gradient updates or fine-tuning, with
                   tasks and few-shot demonstrations specified purely via text
                   interaction with the model. GPT-3 achieves strong
                   performance on many NLP datasets, including translation,
                   question-answering, and cloze tasks, as well as several
                   tasks that require on-the-fly reasoning or domain
                   adaptation, such as unscrambling words, using a novel word
                   in a sentence, or performing 3-digit arithmetic. At the same
                   time, we also identify some datasets where GPT-3's few-shot
                   learning still struggles, as well as some datasets where
                   GPT-3 faces methodological issues related to training on
                   large web corpora. Finally, we find that GPT-3 can generate
                   samples of news articles which human evaluators have
                   difficulty distinguishing from articles written by humans.
                   We discuss broader societal impacts of this finding and of
                   GPT-3 in general.",
  month         =  may,
  year          =  2020,
  keywords      = "nlp",
  archivePrefix = "arXiv",
  eprint        = "2005.14165",
  primaryClass  = "cs.CL",
  arxivid       = "2005.14165"
}

@MISC{Wang_undated-gn,
  title        = "Glue: A multi-task benchmark and analysis platform for
                  natural language {understand-ING}",
  author       = "Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill,
                  Felix and Levy, Omer and Bowman, Samuel R",
  abstract     = "For natural language understanding (NLU) technology to be
                  maximally useful, it must be able to process language in a
                  way that is not exclusive to a single task, genre, or
                  dataset. In pursuit of this objective, we introduce the
                  General Language Understanding Evaluation (GLUE) benchmark, a
                  collection of tools for evaluating the performance of models
                  across a diverse set of existing NLU tasks. By including
                  tasks with limited training data, GLUE is designed to favor
                  and encourage models that share general linguistic knowledge
                  across tasks. GLUE also includes a hand-crafted diagnostic
                  test suite that enables detailed linguistic analysis of
                  models. We evaluate baselines based on current methods for
                  transfer and representation learning and find that multi-task
                  training on all tasks performs better than training a
                  separate model per task. However, the low absolute
                  performance of our best model indicates the need for improved
                  general NLU systems.",
  howpublished = "\url{https://openreview.net/pdf?id=rJ4km2R5t7}",
  note         = "Accessed: 2022-10-21",
  keywords     = "nlp"
}

@ARTICLE{Watkins1992-pk,
  title     = "{Q-Learning}",
  author    = "Watkins, Christopher Jch and Dayan, Peter",
  journal   = "Mach. Learn.",
  publisher = "Springer",
  volume    =  8,
  number    = "3-4",
  pages     = "279--292",
  year      =  1992,
  keywords  = "machine-learning",
  issn      = "0885-6125"
}

@UNPUBLISHED{Andrychowicz2016-uq,
  title    = "Learning to Learn by Gradient Descent by Gradient Descent",
  author   = "Andrychowicz, Marcin and Denil, Misha and Gomez, Sergio and
              Hoffman, Matthew W and Pfau, David and Schaul, Tom and
              Shillingford, Brendan and de Freitas, Nando",
  abstract = "The move from hand-designed features to learned features in
              machine learning has been wildly successful. In spite of this,
              optimization algorithms are still designed by hand. In this paper
              we show how the design of an optimization algorithm can be cast
              as a learning problem, allowing the algorithm to learn to exploit
              structure in the problems of interest in an automatic way. Our
              learned algorithms, implemented by LSTMs, outperform generic,
              hand-designed competitors on the tasks for which they are
              trained, and also generalize well to new tasks with similar
              structure. We demonstrate this on a number of tasks, including
              simple convex problems, training neural networks, and styling
              images with neural art.",
  month    =  nov,
  year     =  2016,
  keywords = "Computer Science - Machine Learning,Computer Science - Neural and
              Evolutionary Computing;comp-cog-sci;machine-learning"
}

@MISC{De_Raedt2020-hk,
  title         = "From {{Statistical Relational}} to {{{Neuro-Symbolic}
                   Artificial Intelligence}}",
  author        = "De Raedt, Luc and Duman{\v c}i{\'c}, Sebastijan and
                   Manhaeve, Robin and Marra, Giuseppe",
  abstract      = "Neuro-symbolic and statistical relational artificial
                   intelligence both integrate frameworks for learning with
                   logical reasoning. This survey identifies several parallels
                   across seven different dimensions between these two fields.
                   These cannot only be used to characterize and position
                   neuro-symbolic artificial intelligence approaches but also
                   to identify a number of directions for further research.",
  journal       = "arXiv [cs]",
  publisher     = "arXiv",
  number        = "arXiv:2003.08316",
  month         =  mar,
  year          =  2020,
  keywords      = "Computer Science - Artificial Intelligence;comp-cog-sci",
  archivePrefix = "arXiv",
  eprint        = "2003.08316",
  primaryClass  = "cs",
  arxivid       = "2003.08316",
  doi           = "10.48550/arXiv.2003.08316"
}

@MISC{Ellis2020-xn,
  title         = "{{{DreamCoder}}}: {{Growing}} Generalizable, Interpretable
                   Knowledge with {Wake-Sleep} {{Bayesian}} Program Learning",
  author        = "Ellis, Kevin and Wong, Catherine and Nye, Maxwell and
                   Sable-Meyer, Mathias and Cary, Luc and Morales, Lucas and
                   Hewitt, Luke and Solar-Lezama, Armando and Tenenbaum, Joshua
                   B",
  abstract      = "Expert problem-solving is driven by powerful languages for
                   thinking about problems and their solutions. Acquiring
                   expertise means learning these languages -- systems of
                   concepts, alongside the skills to use them. We present
                   DreamCoder, a system that learns to solve problems by
                   writing programs. It builds expertise by creating
                   programming languages for expressing domain concepts,
                   together with neural networks to guide the search for
                   programs within these languages. A ``wake-sleep'' learning
                   algorithm alternately extends the language with new symbolic
                   abstractions and trains the neural network on imagined and
                   replayed problems. DreamCoder solves both classic inductive
                   programming tasks and creative tasks such as drawing
                   pictures and building scenes. It rediscovers the basics of
                   modern functional programming, vector algebra and classical
                   physics, including Newton's and Coulomb's laws. Concepts are
                   built compositionally from those learned earlier, yielding
                   multi-layered symbolic representations that are
                   interpretable and transferrable to new tasks, while still
                   growing scalably and flexibly with experience.",
  journal       = "arXiv [cs]",
  publisher     = "arXiv",
  number        = "arXiv:2006.08381",
  month         =  jun,
  year          =  2020,
  keywords      = "Computer Science - Artificial Intelligence,Computer Science
                   - Machine Learning;read;comp-cog-sci",
  archivePrefix = "arXiv",
  eprint        = "2006.08381",
  primaryClass  = "cs",
  arxivid       = "2006.08381"
}

@UNPUBLISHED{Greff2020-gr,
  title    = "On the {{Binding Problem}} in {{Artificial Neural Networks}}",
  author   = "Greff, Klaus and van Steenkiste, Sjoerd and Schmidhuber,
              J{\"u}rgen",
  abstract = "Contemporary neural networks still fall short of human-level
              generalization, which extends far beyond our direct experiences.
              In this paper, we argue that the underlying cause for this
              shortcoming is their inability to dynamically and flexibly bind
              information that is distributed throughout the network. This
              binding problem affects their capacity to acquire a compositional
              understanding of the world in terms of symbol-like entities (like
              objects), which is crucial for generalizing in predictable and
              systematic ways. To address this issue, we propose a unifying
              framework that revolves around forming meaningful entities from
              unstructured sensory inputs (segregation), maintaining this
              separation of information at a representational level
              (representation), and using these entities to construct new
              inferences, predictions, and behaviors (composition). Our
              analysis draws inspiration from a wealth of research in
              neuroscience and cognitive psychology, and surveys relevant
              mechanisms from the machine learning literature, to help identify
              a combination of inductive biases that allow symbolic information
              processing to emerge naturally in neural networks. We believe
              that a compositional approach to AI, in terms of grounded
              symbol-like representations, is of fundamental importance for
              realizing human-level generalization, and we hope that this paper
              may contribute towards that goal as a reference and inspiration.",
  month    =  dec,
  year     =  2020,
  keywords = "Computer Science - Artificial Intelligence,Computer Science -
              Machine Learning,Computer Science - Neural and Evolutionary
              Computing,I.2.6;comp-cog-sci"
}

@ARTICLE{Gureckis2012-xz,
  title    = "{Self-{{Directed} Learning}}: {{A Cognitive}} and {{Computational
              Perspective}}",
  author   = "Gureckis, Todd M and Markant, Douglas B",
  abstract = "A widely advocated idea in education is that people learn better
              when the flow of experience is under their control (i.e.,
              learning is self-directed). However, the reasons why volitional
              control might result in superior acquisition and the limits to
              such advantages remain poorly understood. In this article, we
              review the issue from both a cognitive and computational
              perspective. On the cognitive side, self-directed learning allows
              individuals to focus effort on useful information they do not yet
              possess, can expose information that is inaccessible via passive
              observation, and may enhance the encoding and retention of
              materials. On the computational side, the development of
              efficient ``active learning'' algorithms that can select their
              own training data is an emerging research topic in machine
              learning. This review argues that recent advances in these
              related fields may offer a fresh theoretical perspective on how
              people gather information to support their own learning.",
  journal  = "Perspect. Psychol. Sci.",
  volume   =  7,
  number   =  5,
  pages    = "464--481",
  month    =  sep,
  year     =  2012,
  keywords = "active learning,intervention-based causal learning,machine
              learning,self-directed learning,self-regulated
              study;comp-cog-sci;project 1",
  issn     = "1745-6916, 1745-6924",
  doi      = "10.1177/1745691612454304"
}

@ARTICLE{LeCun2015-hm,
  title     = "Deep Learning",
  author    = "LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey",
  abstract  = "Deep learning allows computational models that are composed of
               multiple processing layers to learn representations of data with
               multiple levels of abstraction. These methods have dramatically
               improved the state-of-the-art in speech recognition, visual
               object recognition, object detection and many other domains such
               as drug discovery and genomics. Deep learning discovers
               intricate structure in large data sets by using the
               backpropagation algorithm to indicate how a machine should
               change its internal parameters that are used to compute the
               representation in each layer from the representation in the
               previous layer. Deep convolutional nets have brought about
               breakthroughs in processing images, video, speech and audio,
               whereas recurrent nets have shone light on sequential data such
               as text and speech.",
  journal   = "Nature",
  publisher = "Nature Publishing Group",
  volume    =  521,
  number    =  7553,
  pages     = "436--444",
  month     =  may,
  year      =  2015,
  keywords  = "read;machine-learning;ccm2023",
  issn      = "0028-0836, 1476-4687",
  doi       = "10.1038/nature14539"
}

@ARTICLE{Piantadosi2021-ie,
  title    = "The {{Computational Origin}} of {{Representation}}",
  author   = "Piantadosi, Steven T",
  abstract = "Each of our theories of mental representation provides some
              insight into how the mind works. However, these insights often
              seem incompatible, as the debates between symbolic, dynamical,
              emergentist, sub-symbolic, and grounded approaches to cognition
              attest. Mental representations---whatever they are---must share
              many features with each of our theories of representation, and
              yet there are few hypotheses about how a synthesis could be
              possible. Here, I develop a theory of the underpinnings of
              symbolic cognition that shows how sub-symbolic dynamics may give
              rise to higher-level cognitive representations of structures,
              systems of knowledge, and algorithmic processes. This theory
              implements a version of conceptual role semantics by positing an
              internal universal representation language in which learners may
              create mental models to capture dynamics they observe in the
              world. The theory formalizes one account of how truly novel
              conceptual content may arise, allowing us to explain how even
              elementary logical and computational operations may be learned
              from a more primitive basis. I provide an implementation that
              learns to represent a variety of structures, including logic,
              number, kinship trees, regular languages, context-free languages,
              domains of theories like magnetism, dominance hierarchies, list
              structures, quantification, and computational primitives like
              repetition, reversal, and recursion. This account is based on
              simple discrete dynamical processes that could be implemented in
              a variety of different physical or biological systems. In
              particular, I describe how the required dynamics can be directly
              implemented in a connectionist framework. The resulting theory
              provides an ``assembly language'' for cognition, where high-level
              theories of symbolic computation can be implemented in simple
              dynamics that themselves could be encoded in biologically
              plausible systems.",
  journal  = "Minds Mach.",
  volume   =  31,
  number   =  1,
  pages    = "1--58",
  month    =  mar,
  year     =  2021,
  keywords = "comp-cog-sci",
  issn     = "0924-6495, 1572-8641",
  doi      = "10.1007/s11023-020-09540-9"
}

@ARTICLE{Rich2018-zj,
  title     = "The Limits of Learning: {{Exploration}}, Generalization, and the
               Development of Learning Traps",
  author    = "Rich, Alexander S and Gureckis, Todd M",
  abstract  = "Learning usually improves the accuracy of beliefs through the
               accumulation of experience. But are there limits to learning
               that prevent us from accurately understanding our world? In this
               article we investigate the concept of a ``learning trap''---the
               formation of a stable false belief even with extensive
               experience. Our review highlights how these traps develop
               through the interaction of learning and decision making in
               unknown environments. We further document a particularly
               pernicious learning trap driven by selective attention, a
               mechanism often assumed to facilitate learning in complex
               environments. Using computer simulation, we demonstrate the key
               attributes of the agent and environment that lead to this new
               type of learning trap. Then, in a series of experiments we
               present evidence that people robustly fall into this trap, even
               in the presence of various interventions predicted to meliorate
               it. These results highlight a fundamental limit to learning and
               adaptive behavior that impacts individuals, organizations,
               animals, and machines. (PsycInfo Database Record (c) 2020 APA,
               all rights reserved)",
  journal   = "J. Exp. Psychol. Gen.",
  publisher = "American Psychological Association",
  volume    =  147,
  number    =  11,
  pages     = "1553--1570",
  year      =  2018,
  address   = "US",
  keywords  = "Decision Making,Development,Environment,False
               Beliefs,Generalization (Learning),Learning,Learning
               Environment,Selective Attention;comp-cog-sci",
  issn      = "0096-3445, 1939-2222",
  doi       = "10.1037/xge0000466"
}

@ARTICLE{Tenenbaum2011-ud,
  title    = "How to grow a mind: statistics, structure, and abstraction",
  author   = "Tenenbaum, Joshua B and Kemp, Charles and Griffiths, Thomas L and
              Goodman, Noah D",
  abstract = "In coming to understand the world-in learning concepts, acquiring
              language, and grasping causal relations-our minds make inferences
              that appear to go far beyond the data available. How do we do it?
              This review describes recent approaches to reverse-engineering
              human learning and cognitive development and, in parallel,
              engineering more humanlike machine learning systems.
              Computational models that perform probabilistic inference over
              hierarchies of flexibly structured representations can address
              some of the deepest questions about the nature and origins of
              human thought: How does abstract knowledge guide learning and
              reasoning from sparse data? What forms does our knowledge take,
              across different domains and tasks? And how is that abstract
              knowledge itself acquired?",
  journal  = "Science",
  volume   =  331,
  number   =  6022,
  pages    = "1279--1285",
  month    =  mar,
  year     =  2011,
  keywords = "read;comp-cog-sci;project 2",
  language = "en",
  issn     = "0036-8075, 1095-9203",
  pmid     = "21393536",
  doi      = "10.1126/science.1192788"
}

@ARTICLE{Thomas_McCoy2020-zy,
  title         = "Universal linguistic inductive biases via meta-learning",
  author        = "Thomas McCoy, R and Grant, Erin and Smolensky, Paul and
                   Griffiths, Thomas L and Linzen, Tal",
  abstract      = "How do learners acquire languages from the limited data
                   available to them? This process must involve some inductive
                   biases - factors that affect how a learner generalizes - but
                   it is unclear which inductive biases can explain observed
                   patterns in language acquisition. To facilitate
                   computational modeling aimed at addressing this question, we
                   introduce a framework for giving particular linguistic
                   inductive biases to a neural network model; such a model can
                   then be used to empirically explore the effects of those
                   inductive biases. This framework disentangles universal
                   inductive biases, which are encoded in the initial values of
                   a neural network's parameters, from non-universal factors,
                   which the neural network must learn from data in a given
                   language. The initial state that encodes the inductive
                   biases is found with meta-learning, a technique through
                   which a model discovers how to acquire new languages more
                   easily via exposure to many possible languages. By
                   controlling the properties of the languages that are used
                   during meta-learning, we can control the inductive biases
                   that meta-learning imparts. We demonstrate this framework
                   with a case study based on syllable structure. First, we
                   specify the inductive biases that we intend to give our
                   model, and then we translate those inductive biases into a
                   space of languages from which a model can meta-learn.
                   Finally, using existing analysis techniques, we verify that
                   our approach has imparted the linguistic inductive biases
                   that it was intended to impart.",
  month         =  jun,
  year          =  2020,
  keywords      = "read;comp-cog-sci",
  archivePrefix = "arXiv",
  eprint        = "2006.16324",
  primaryClass  = "cs.CL",
  arxivid       = "2006.16324"
}

@INBOOK{Bassok2012-sg,
  title     = "Problem Solving",
  author    = "Bassok, Miriam and Novick, Laura R",
  abstract  = "Abstract. This chapter follows the historical development of
               research on problem solving. It begins with a description of two
               research traditions that addressed",
  publisher = "Oxford University Press",
  month     =  mar,
  year      =  2012,
  language  = "en",
  doi       = "10.1093/oxfordhb/9780199734689.013.0021"
}

@ARTICLE{Ellis2022-je,
  title    = "Synthesizing theories of human language with Bayesian program
              induction",
  author   = "Ellis, Kevin and Albright, Adam and Solar-Lezama, Armando and
              Tenenbaum, Joshua B and O'Donnell, Timothy J",
  abstract = "Automated, data-driven construction and evaluation of scientific
              models and theories is a long-standing challenge in artificial
              intelligence. We present a framework for algorithmically
              synthesizing models of a basic part of human language:
              morpho-phonology, the system that builds word forms from sounds.
              We integrate Bayesian inference with program synthesis and
              representations inspired by linguistic theory and cognitive
              models of learning and discovery. Across 70 datasets from 58
              diverse languages, our system synthesizes human-interpretable
              models for core aspects of each language's morpho-phonology,
              sometimes approaching models posited by human linguists. Joint
              inference across all 70 data sets automatically synthesizes a
              meta-model encoding interpretable cross-language typological
              tendencies. Finally, the same algorithm captures few-shot
              learning dynamics, acquiring new morphophonological rules from
              just one or a few examples. These results suggest routes to more
              powerful machine-enabled discovery of interpretable models in
              linguistics and other scientific domains.",
  journal  = "Nat. Commun.",
  volume   =  13,
  number   =  1,
  pages    = "5024",
  month    =  aug,
  year     =  2022,
  keywords = "skimmed;comp-cog-sci",
  language = "en",
  issn     = "2041-1723",
  pmid     = "36042196",
  doi      = "10.1038/s41467-022-32012-w",
  pmc      = "PMC9427767"
}

@ARTICLE{Valkov2018-sq,
  title         = "{HOUDINI}: Lifelong Learning as Program Synthesis",
  author        = "Valkov, Lazar and Chaudhari, Dipak and Srivastava, Akash and
                   Sutton, Charles and Chaudhuri, Swarat",
  abstract      = "We present a neurosymbolic framework for the lifelong
                   learning of algorithmic tasks that mix perception and
                   procedural reasoning. Reusing high-level concepts across
                   domains and learning complex procedures are key challenges
                   in lifelong learning. We show that a program synthesis
                   approach that combines gradient descent with combinatorial
                   search over programs can be a more effective response to
                   these challenges than purely neural methods. Our framework,
                   called HOUDINI, represents neural networks as strongly
                   typed, differentiable functional programs that use symbolic
                   higher-order combinators to compose a library of neural
                   functions. Our learning algorithm consists of: (1) a
                   symbolic program synthesizer that performs a type-directed
                   search over parameterized programs, and decides on the
                   library functions to reuse, and the architectures to combine
                   them, while learning a sequence of tasks; and (2) a neural
                   module that trains these programs using stochastic gradient
                   descent. We evaluate HOUDINI on three benchmarks that
                   combine perception with the algorithmic tasks of counting,
                   summing, and shortest-path computation. Our experiments show
                   that HOUDINI transfers high-level concepts more effectively
                   than traditional transfer learning and progressive neural
                   networks, and that the typed representation of networks
                   significantly accelerates the search.",
  month         =  mar,
  year          =  2018,
  archivePrefix = "arXiv",
  eprint        = "1804.00218",
  primaryClass  = "cs.LG",
  arxivid       = "1804.00218"
}

@ARTICLE{Raffel2019-jw,
  title         = "Exploring the Limits of Transfer Learning with a Unified
                   {Text-to-Text} Transformer",
  author        = "Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee,
                   Katherine and Narang, Sharan and Matena, Michael and Zhou,
                   Yanqi and Li, Wei and Liu, Peter J",
  abstract      = "Transfer learning, where a model is first pre-trained on a
                   data-rich task before being fine-tuned on a downstream task,
                   has emerged as a powerful technique in natural language
                   processing (NLP). The effectiveness of transfer learning has
                   given rise to a diversity of approaches, methodology, and
                   practice. In this paper, we explore the landscape of
                   transfer learning techniques for NLP by introducing a
                   unified framework that converts all text-based language
                   problems into a text-to-text format. Our systematic study
                   compares pre-training objectives, architectures, unlabeled
                   data sets, transfer approaches, and other factors on dozens
                   of language understanding tasks. By combining the insights
                   from our exploration with scale and our new ``Colossal Clean
                   Crawled Corpus'', we achieve state-of-the-art results on
                   many benchmarks covering summarization, question answering,
                   text classification, and more. To facilitate future work on
                   transfer learning for NLP, we release our data set,
                   pre-trained models, and code.",
  month         =  oct,
  year          =  2019,
  keywords      = "nlp",
  archivePrefix = "arXiv",
  eprint        = "1910.10683",
  primaryClass  = "cs.LG",
  arxivid       = "1910.10683"
}

@MISC{Bramley_undated-rs,
  title        = "Grounding compositional hypothesis generation in specific
                  instances",
  author       = "Bramley, Neil R and Tenenbaum, Joshua B",
  abstract     = "A number of recent computational models treat concept
                  learning as a form of probabilistic rule induction in a space
                  of language-like, compositional concepts. Inference in such
                  models frequently requires repeatedly sampling from a
                  (infinite) distribution over possible concept rules and
                  comparing their relative likelihood in light of current data
                  or evidence. However, we argue that most existing algorithms
                  for top-down sampling are inefficient and cognitively
                  implausible accounts of human hypothesis generation. As a
                  result, we propose an alternative, Instance Driven Generator
                  (IDG), that constructs bottom-up hypotheses directly out of
                  encountered positive instances of a concept. Using a novel
                  rule induction task based on the children's game Zendo, we
                  compare these ``bottomup'' and ``top-down'' approaches to
                  inference. We find that the bottom-up IDG model accounts
                  better for human inferences and results in a computationally
                  more tractable inference mechanism for concept learning
                  models based on a probabilistic language of thought.",
  howpublished = "\url{https://www.bramleylab.ppls.ed.ac.uk/pdfs/bramley2018zendo.pdf}",
  note         = "Accessed: 2022-10-16",
  keywords     = "project 1;comp-cog-sci"
}

@ARTICLE{Nisbett1977-oz,
  title    = "Telling more than we can know: Verbal reports on mental processes",
  author   = "Nisbett, Richard E and Wilson, Timothy D",
  abstract = "Reviews evidence which suggests that there may be little or no
              direct introspective access to higher order cognitive processes.
              Ss are sometimes (a) unaware of the existence of a stimulus that
              importantly influenced a response, (b) unaware of the existence
              of the response, and (c) unaware that the stimulus has affected
              the response. It is proposed that when people attempt to report
              on their cognitive processes, that is, on the processes mediating
              the effects of a stimulus on a response, they do not do so on the
              basis of any true introspection. Instead, their reports are based
              on a priori, implicit causal theories, or judgments about the
              extent to which a particular stimulus is a plausible cause of a
              given response. This suggests that though people may not be able
              to observe directly their cognitive processes, they will
              sometimes be able to report accurately about them. Accurate
              reports will occur when influential stimuli are salient and are
              plausible causes of the responses they produce, and will not
              occur when stimuli are not salient or are not plausible causes.
              (86 ref) (PsycINFO Database Record (c) 2018 APA, all rights
              reserved)",
  journal  = "Psychol. Rev.",
  volume   =  84,
  number   =  3,
  pages    = "231--259",
  month    =  may,
  year     =  1977,
  keywords = "project 1",
  issn     = "0033-295X, 1939-1471",
  doi      = "10.1037/0033-295X.84.3.231"
}

@ARTICLE{Griffiths2019-hj,
  title    = "Doing more with less: Meta-reasoning and meta-learning in humans
              and machines",
  author   = "Griffiths, Thomas L and Callaway, Frederick and Chang, Michael B
              and Grant, Erin and Krueger, Paul M and Lieder, Falk",
  abstract = "Artificial intelligence systems use an increasing amount of
              computation and data to solve very specific problems. By
              contrast, human minds solve a wide range of problems using a
              fixed amount of computation and limited experience. We identify
              two abilities that we see as crucial to this kind of general
              intelligence: meta-reasoning (deciding how to allocate
              computational resources) and meta-learning (modeling the learning
              environment to make better use of limited data). We summarize the
              relevant AI literature and relate the resulting ideas to recent
              work in psychology. (PsycINFO Database Record (c) 2019 APA, all
              rights reserved)",
  journal  = "Current Opinion in Behavioral Sciences",
  volume   =  29,
  pages    = "24--30",
  month    =  oct,
  year     =  2019,
  issn     = "2352-1546, 2352-1554",
  doi      = "10.1016/j.cobeha.2019.01.005"
}

@ARTICLE{De_Jong1998-ci,
  title     = "Scientific Discovery Learning with Computer Simulations of
               Conceptual Domains",
  author    = "De Jong, Ton and Van Joolingen, Wouter R",
  abstract  = "Scientific discovery learning is a highly self-directed and
               constructivistic form of learning. A computer simulation is a
               type of computer-based environment that is well suited for
               discovery learning, the main task of the learner being to infer,
               through experimentation, characteristics of the model underlying
               the simulation. In this article we give a review of the observed
               effectiveness and efficiency of discovery learning in simulation
               environments together with problems that learners may encounter
               in discovery learning, and we discuss how simulations may be
               combined with instructional support in order to overcome these
               problems.",
  journal   = "Rev. Educ. Res.",
  publisher = "American Educational Research Association",
  volume    =  68,
  number    =  2,
  pages     = "179--201",
  month     =  jun,
  year      =  1998,
  keywords  = "project 1",
  issn      = "0034-6543",
  doi       = "10.3102/00346543068002179"
}

@ARTICLE{Gopnik2012-iu,
  title    = "Scientific thinking in young children: theoretical advances,
              empirical research, and policy implications",
  author   = "Gopnik, Alison",
  abstract = "New theoretical ideas and empirical research show that very young
              children's learning and thinking are strikingly similar to much
              learning and thinking in science. Preschoolers test hypotheses
              against data and make causal inferences; they learn from
              statistics and informal experimentation, and from watching and
              listening to others. The mathematical framework of probabilistic
              models and Bayesian inference can describe this learning in
              precise ways. These discoveries have implications for early
              childhood education and policy. In particular, they suggest both
              that early childhood experience is extremely important and that
              the trend toward more structured and academic early childhood
              programs is misguided.",
  journal  = "Science",
  volume   =  337,
  number   =  6102,
  pages    = "1623--1627",
  month    =  sep,
  year     =  2012,
  keywords = "project 1",
  language = "en",
  issn     = "0036-8075, 1095-9203",
  pmid     = "23019643",
  doi      = "10.1126/science.1223416"
}

@ARTICLE{Xu2022-eq,
  title         = "{EST}: Evaluating Scientific Thinking in Artificial Agents",
  author        = "Xu, Manjie and Jiang, Guangyuan and Zhang, Chi and Zhu,
                   Song-Chun and Zhu, Yixin",
  abstract      = "Theoretical ideas and empirical research have shown us a
                   seemingly surprising result: children, even very young
                   toddlers, demonstrate learning and thinking in a strikingly
                   similar manner to scientific reasoning in formal research.
                   Encountering a novel phenomenon, children make hypotheses
                   against data, conduct causal inference from observation,
                   test their theory via experimentation, and correct the
                   proposition if inconsistency arises. Rounds of such
                   processes continue until the underlying mechanism is found.
                   Towards building machines that can learn and think like
                   people, one natural question for us to ask is: whether the
                   intelligence we achieve today manages to perform such a
                   scientific thinking process, and if any, at what level. In
                   this work, we devise the EST environment for evaluating the
                   scientific thinking ability in artificial agents. Motivated
                   by the stream of research on causal discovery, we build our
                   interactive EST environment based on Blicket detection.
                   Specifically, in each episode of EST, an agent is presented
                   with novel observations and asked to figure out all objects'
                   Blicketness. At each time step, the agent proposes new
                   experiments to validate its hypothesis and updates its
                   current belief. By evaluating Reinforcement Learning (RL)
                   agents on both a symbolic and visual version of this task,
                   we notice clear failure of today's learning methods in
                   reaching a level of intelligence comparable to humans. Such
                   inefficacy of learning in scientific thinking calls for
                   future research in building humanlike intelligence.",
  month         =  jun,
  year          =  2022,
  keywords      = "skimmed;project 1;machine-learning",
  archivePrefix = "arXiv",
  eprint        = "2206.09203",
  primaryClass  = "cs.AI",
  arxivid       = "2206.09203"
}

@ARTICLE{Lohse2022-nm,
  title    = "Hypotheses in adult-child interactions stimulate children's
              reasoning and verbalizations",
  author   = "Lohse, Karoline and Hildebrandt, Andrea and Hildebrandt, Frauke",
  abstract = "Adult-child interactions can support children's development and
              are established as predictors of program quality in early
              childhood settings. However, the linguistic components that
              constitute positive interactions have not yet been studied in
              detail. This study investigates the effects of hypotheses
              proposed by adults on children's responses in a dyadic
              picture-book viewing situation. In 2 experiments, adults' use of
              hypotheses (e.g., ``Maybe this is a dwarf's door'') was tested
              against the use of instructive statements (``This is a dwarf's
              door'') and in combination with open questions (``What do you
              think, why is the door so small?''). In Experiment 1, hypotheses
              differed from instructions only by the modal marker ``maybe''.
              Children's responses to hypotheses were longer and contained more
              self-generated explanations as compared to responses to
              instructions. The use of hypotheses also seemed to encourage
              children to attach more importance to their own explanations. In
              Experiment 2, combining hypotheses with open-ended why questions
              elicited longer responses but no more self-generated explanations
              in children than open-ended questions alone. Results indicate
              that subtle differences in adults' utterances can directly
              influence children's reasoning and children's contributions to
              dialogues.",
  journal  = "Early Child. Res. Q.",
  volume   =  58,
  pages    = "254--263",
  month    =  jan,
  year     =  2022,
  keywords = "Adult-child interactions; sustained shared thinking; hypotheses;
              open questions;development",
  issn     = "0885-2006",
  doi      = "10.1016/j.ecresq.2021.09.014"
}

@ARTICLE{Bramley2018-zb,
  title    = "Intuitive experimentation in the physical world",
  author   = "Bramley, Neil R and Gerstenberg, Tobias and Tenenbaum, Joshua B
              and Gureckis, Todd M",
  abstract = "Many aspects of our physical environment are hidden. For example,
              it is hard to estimate how heavy an object is from visual
              observation alone. In this paper we examine how people actively
              ``experiment'' within the physical world to discover such latent
              properties. In the first part of the paper, we develop a novel
              framework for the quantitative analysis of the information
              produced by physical interactions. We then describe two
              experiments that present participants with moving objects in
              ``microworlds'' that operate according to continuous
              spatiotemporal dynamics similar to everyday physics (i.e., forces
              of gravity, friction, etc.). Participants were asked to interact
              with objects in the microworlds in order to identify their
              masses, or the forces of attraction/repulsion that governed their
              movement. Using our modeling framework, we find that learners who
              freely interacted with the physical system selectively produced
              evidence that revealed the physical property consistent with
              their inquiry goal. As a result, their inferences were more
              accurate than for passive observers and, in some contexts, for
              yoked participants who watched video replays of an active
              learner's interactions. We characterize active learners' actions
              into a range of micro-experiment strategies and discuss how these
              might be learned or generalized from past experience. The
              technical contribution of this work is the development of a novel
              analytic framework and methodology for the study of interactively
              learning about the physical world. Its empirical contribution is
              the demonstration of sophisticated goal directed human active
              learning in a naturalistic context.",
  journal  = "Cogn. Psychol.",
  volume   =  105,
  pages    = "9--38",
  month    =  sep,
  year     =  2018,
  keywords = "Active learning; Experimental design; Mental simulation; Physical
              understanding;read;project 1;comp-cog-sci",
  language = "en",
  issn     = "0010-0285, 1095-5623",
  pmid     = "29885534",
  doi      = "10.1016/j.cogpsych.2018.05.001"
}

@ARTICLE{Coenen2015-wp,
  title    = "Strategies to intervene on causal systems are adaptively selected",
  author   = "Coenen, Anna and Rehder, Bob and Gureckis, Todd M",
  abstract = "How do people choose interventions to learn about causal systems?
              Here, we considered two possibilities. First, we test an
              information sampling model, information gain, which values
              interventions that can discriminate between a learner's
              hypotheses (i.e. possible causal structures). We compare this
              discriminatory model to a positive testing strategy that instead
              aims to confirm individual hypotheses. Experiment 1 shows that
              individual behavior is described best by a mixture of these two
              alternatives. In Experiment 2 we find that people are able to
              adaptively alter their behavior and adopt the discriminatory
              model more often after experiencing that the confirmatory
              strategy leads to a subjective performance decrement. In
              Experiment 3, time pressure leads to the opposite effect of
              inducing a change towards the simpler positive testing strategy.
              These findings suggest that there is no single strategy that
              describes how intervention decisions are made. Instead, people
              select strategies in an adaptive fashion that trades off their
              expected performance and cognitive effort.",
  journal  = "Cogn. Psychol.",
  volume   =  79,
  pages    = "102--133",
  month    =  jun,
  year     =  2015,
  keywords = "Causal learning; Hypothesis testing; Information gain;
              Interventions; Self-directed learning;project 1",
  language = "en",
  issn     = "0010-0285, 1095-5623",
  pmid     = "25935867",
  doi      = "10.1016/j.cogpsych.2015.02.004"
}

@ARTICLE{Allen2020-tf,
  title    = "Rapid trial-and-error learning with simulation supports flexible
              tool use and physical reasoning",
  author   = "Allen, Kelsey R and Smith, Kevin A and Tenenbaum, Joshua B",
  abstract = "Many animals, and an increasing number of artificial agents,
              display sophisticated capabilities to perceive and manipulate
              objects. But human beings remain distinctive in their capacity
              for flexible, creative tool use-using objects in new ways to act
              on the world, achieve a goal, or solve a problem. To study this
              type of general physical problem solving, we introduce the
              Virtual Tools game. In this game, people solve a large range of
              challenging physical puzzles in just a handful of attempts. We
              propose that the flexibility of human physical problem solving
              rests on an ability to imagine the effects of hypothesized
              actions, while the efficiency of human search arises from rich
              action priors which are updated via observations of the world. We
              instantiate these components in the ``sample, simulate, update''
              (SSUP) model and show that it captures human performance across
              30 levels of the Virtual Tools game. More broadly, this model
              provides a mechanism for explaining how people condense general
              physical knowledge into actionable, task-specific plans to
              achieve flexible and efficient physical problem solving.",
  journal  = "Proc. Natl. Acad. Sci. U. S. A.",
  volume   =  117,
  number   =  47,
  pages    = "29302--29310",
  month    =  nov,
  year     =  2020,
  keywords = "intuitive physics; physical problem solving; tool
              use;read;comp-cog-sci;project 2",
  language = "en",
  issn     = "0027-8424, 1091-6490",
  pmid     = "33229515",
  doi      = "10.1073/pnas.1912341117",
  pmc      = "PMC7703630"
}

@ARTICLE{Bonawitz2011-pi,
  title    = "The double-edged sword of pedagogy: Instruction limits
              spontaneous exploration and discovery",
  author   = "Bonawitz, Elizabeth and Shafto, Patrick and Gweon, Hyowon and
              Goodman, Noah D and Spelke, Elizabeth and Schulz, Laura",
  abstract = "Motivated by computational analyses, we look at how teaching
              affects exploration and discovery. In Experiment 1, we
              investigated children's exploratory play after an adult
              pedagogically demonstrated a function of a toy, after an
              interrupted pedagogical demonstration, after a na{\"\i}ve adult
              demonstrated the function, and at baseline. Preschoolers in the
              pedagogical condition focused almost exclusively on the target
              function; by contrast, children in the other conditions explored
              broadly. In Experiment 2, we show that children restrict their
              exploration both after direct instruction to themselves and after
              overhearing direct instruction given to another child; they do
              not show this constraint after observing direct instruction given
              to an adult or after observing a non-pedagogical intentional
              action. We discuss these findings as the result of rational
              inductive biases. In pedagogical contexts, a teacher's failure to
              provide evidence for additional functions provides evidence for
              their absence; such contexts generalize from child to child
              (because children are likely to have comparable states of
              knowledge) but not from adult to child. Thus, pedagogy promotes
              efficient learning but at a cost: children are less likely to
              perform potentially irrelevant actions but also less likely to
              discover novel information.",
  journal  = "Cognition",
  volume   =  120,
  number   =  3,
  pages    = "322--330",
  month    =  sep,
  year     =  2011,
  keywords = "development",
  language = "en",
  issn     = "0010-0277, 1873-7838",
  pmid     = "21216395",
  doi      = "10.1016/j.cognition.2010.10.001",
  pmc      = "PMC3369499"
}

@ARTICLE{Dumont2022-am,
  title    = "Transactional longitudinal relations between accuracy and
              reaction time on a measure of cognitive flexibility at 5, 6, and
              7 years of age",
  author   = "Dumont, {\'E}milie and Castellanos-Ryan, Natalie and Parent,
              Sophie and Jacques, Sophie and S{\'e}guin, Jean R and Zelazo,
              Philip David",
  abstract = "Whereas accuracy is used as an indicator of cognitive flexibility
              in preschool-age children, reaction time (RT), or a combination
              of accuracy and RT, provide better indices of performance as
              children transition to school. Theoretical models and
              cross-sectional studies suggest that a speed-accuracy tradeoff
              may be operating across this transition, but the lack of
              longitudinal studies makes this transition difficult to
              understand. The current study explored the longitudinal and
              bidirectional associations between accuracy and RT on the DCCS
              (mixed block) at 5, 6, and 7 years of age using cross-lagged
              panel analyses. The study also examined the roles of working
              memory and language, as potential longitudinal mediators between
              RT at Time X and accuracy at Time X + 1, and explored the role of
              inhibitory control. The sample consisted of 425 children from the
              Quebec Longitudinal Study of Child Development. Results show
              lagged associations from slower RT to greater improvements in
              accuracy between 5 and 6 years and between 6 and 7 years.
              Further, higher accuracy at 6 years predicted faster RT at 7
              years. Only working memory acted as a partial mediator between RT
              at 5 years and accuracy at 6 years. These results provide needed
              longitudinal evidence to support theoretical claims that slower
              RT precedes improved accuracy in the development of cognitive
              flexibility, that working memory may be involved in the early
              stage of this process, and that accuracy and reaction time become
              more efficient in later stages of this process.",
  journal  = "Dev. Sci.",
  volume   =  25,
  number   =  5,
  pages    = "e13254",
  month    =  sep,
  year     =  2022,
  keywords = "DCCS; cognitive flexibility; cross-lagged panel; longitudinal;
              school transition; working memory;development",
  language = "en",
  issn     = "1363-755X, 1467-7687",
  pmid     = "35195319",
  doi      = "10.1111/desc.13254"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Chowdhery2022-un,
  title    = "{PaLM}: Scaling Language Modeling with Pathways",
  author   = "Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and
              Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, P
              and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian
              and Schuh, Parker and Shi, Kensen and Tsvyashchenko, Sasha and
              Maynez, Joshua and Rao, Abhishek B and Barnes, Parker and Tay, Yi
              and Shazeer, Noam M and Prabhakaran, Vinodkumar and Reif, Emily
              and Du, Nan and Hutchinson, B and Pope, Reiner and Bradbury,
              James and Austin, Jacob and Isard, M and Gur-Ari, Guy and Yin,
              Pengcheng and Duke, Toju and Levskaya, Anselm and Ghemawat, S and
              Dev, Sunipa and Michalewski, H and Garc{\'\i}a, Xavier and Misra,
              Vedant and Robinson, Kevin and Fedus, L and Zhou, Denny and
              Ippolito, Daphne and Luan, D and Lim, Hyeontaek and Zoph, Barret
              and Spiridonov, A and Sepassi, Ryan and Dohan, David and Agrawal,
              Shivani and Omernick, Mark and Dai, Andrew M and Pillai, T S and
              Pellat, Marie and Lewkowycz, Aitor and Moreira, Erica and Child,
              Rewon and Polozov, Oleksandr and Lee, Katherine and Zhou, Zongwei
              and Wang, Xuezhi and Saeta, Brennan and D{\'\i}az, Mark and
              Firat, Orhan and Catasta, Michele and Wei, Jason and
              Meier-Hellstern, K and Eck, D and Dean, J and Petrov, Slav and
              Fiedel, Noah",
  abstract = "A 540-billion parameter, densely activated, Transformer language
              model, which is called PaLM achieves breakthrough performance,
              outperforming the state-of-the-art on a suite of multi-step
              reasoning tasks, and outperforming average human performance on
              the recently released BIG-bench benchmark. Large language models
              have been shown to achieve remarkable performance across a
              variety of natural language tasks using few-shot learning , which
              drastically reduces the number of task-specic training examples
              needed to adapt the model to a particular application. To further
              our understanding of the impact of scale on few-shot learning, we
              trained a 540-billion parameter, densely activated, Transformer
              language model, which we call Pathways Language Model (PaLM). We
              trained PaLM on 6144 TPU v4 chips using Pathways, a new ML system
              which enables highly ecient training across multiple TPU Pods.
              We demonstrate continued benets of scaling by achieving
              state-of-the-art few-shot learning results on hundreds of
              language understanding and generation benchmarks. On a number of
              these tasks, PaLM 540B achieves breakthrough performance,
              outperforming the netuned state-of-the-art on a suite of
              multi-step reasoning tasks, and outperforming average human
              performance on the recently released BIG-bench benchmark. A
              signicant number of BIG-bench tasks showed discontinuous
              improvements from model scale, meaning that performance steeply
              increased as we scaled to our largest model. PaLM also has strong
              capabilities in multilingual tasks and source code generation,
              which we demonstrate on a wide array of benchmarks. We
              additionally provide a comprehensive analysis on bias and
              toxicity, and study the extent of training data memorization with
              respect to model scale. Finally, we discuss the ethical
              considerations related to large language models and discuss
              potential mitigation strategies.",
  journal  = "ArXiv",
  year     =  2022,
  keywords = "nlp",
  language = "en",
  arxivid  = "2204.02311"
}

@ARTICLE{Xu2013-bw,
  title     = "Infants Are Rational Constructivist Learners",
  author    = "Xu, Fei and Kushnir, Tamar",
  abstract  = "What is the nature of human learning, and what insights can be
               gained from understanding early learning in infants and young
               children? This is an important question for understanding the
               human mind, the origins of knowledge, scientific reasoning, and
               how to best structure our educational environment. In this
               article, we argue for a new approach to cognitive development:
               rational constructivism. This view characterizes the child as a
               rational constructive learner, and it sees early learning as
               rational, statistical, and inferential. Empirical evidence for
               this approach has been accumulating rapidly, and a set of
               domain-general statistical and inferential mechanisms have been
               uncovered to explain why infants and young children learn so
               fast and so well.",
  journal   = "Curr. Dir. Psychol. Sci.",
  publisher = "SAGE Publications Inc",
  volume    =  22,
  number    =  1,
  pages     = "28--32",
  month     =  feb,
  year      =  2013,
  keywords  = "development",
  issn      = "0963-7214",
  doi       = "10.1177/0963721412469396"
}

@INPROCEEDINGS{McCoy2019-zo,
  title     = "Right for the Wrong Reasons: Diagnosing Syntactic Heuristics in
               Natural Language Inference",
  booktitle = "Proceedings of the 57th Annual Meeting of the Association for
               Computational Linguistics",
  author    = "McCoy, Tom and Pavlick, Ellie and Linzen, Tal",
  abstract  = "A machine learning system can score well on a given test set by
               relying on heuristics that are effective for frequent example
               types but break down in more challenging cases. We study this
               issue within natural language inference (NLI), the task of
               determining whether one sentence entails another. We hypothesize
               that statistical NLI models may adopt three fallible syntactic
               heuristics: the lexical overlap heuristic, the subsequence
               heuristic, and the constituent heuristic. To determine whether
               models have adopted these heuristics, we introduce a controlled
               evaluation set called HANS (Heuristic Analysis for NLI Systems),
               which contains many examples where the heuristics fail. We find
               that models trained on MNLI, including BERT, a state-of-the-art
               model, perform very poorly on HANS, suggesting that they have
               indeed adopted these heuristics. We conclude that there is
               substantial room for improvement in NLI systems, and that the
               HANS dataset can motivate and measure progress in this area.",
  publisher = "Association for Computational Linguistics",
  pages     = "3428--3448",
  month     =  jul,
  year      =  2019,
  address   = "Florence, Italy",
  keywords  = "nlp",
  doi       = "10.18653/v1/P19-1334"
}

@ARTICLE{Ribeiro2020-xl,
  title         = "Beyond Accuracy: Behavioral Testing of {NLP} models with
                   {CheckList}",
  author        = "Ribeiro, Marco Tulio and Wu, Tongshuang and Guestrin, Carlos
                   and Singh, Sameer",
  abstract      = "Although measuring held-out accuracy has been the primary
                   approach to evaluate generalization, it often overestimates
                   the performance of NLP models, while alternative approaches
                   for evaluating models either focus on individual tasks or on
                   specific behaviors. Inspired by principles of behavioral
                   testing in software engineering, we introduce CheckList, a
                   task-agnostic methodology for testing NLP models. CheckList
                   includes a matrix of general linguistic capabilities and
                   test types that facilitate comprehensive test ideation, as
                   well as a software tool to generate a large and diverse
                   number of test cases quickly. We illustrate the utility of
                   CheckList with tests for three tasks, identifying critical
                   failures in both commercial and state-of-art models. In a
                   user study, a team responsible for a commercial sentiment
                   analysis model found new and actionable bugs in an
                   extensively tested model. In another user study, NLP
                   practitioners with CheckList created twice as many tests,
                   and found almost three times as many bugs as users without
                   it.",
  month         =  may,
  year          =  2020,
  keywords      = "nlp",
  archivePrefix = "arXiv",
  eprint        = "2005.04118",
  primaryClass  = "cs.CL",
  arxivid       = "2005.04118"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@UNPUBLISHED{Tenney2022-km,
  title    = "What do you learn from context? Probing for sentence structure in
              contextualized word representations",
  author   = "Tenney, Ian and Xia, Patrick and Chen, Berlin and Wang, Alex and
              Poliak, Adam and Thomas McCoy, R and Kim, Najoung and Van Durme,
              Benjamin and Bowman, Samuel R and Das, Dipanjan and Pavlick,
              Ellie",
  abstract = "Contextualized representation models such as ELMo (Peters et al.,
              2018a) and BERT (Devlin et al., 2018) have recently achieved
              state-of-the-art results on a diverse array of downstream NLP
              tasks. Building on recent token-level probing work, we introduce
              a novel edge probing task design and construct a broad suite of
              sub-sentence tasks derived from the traditional structured NLP
              pipeline. We probe word-level contextual representations from
              four recent models and investigate how they encode sentence
              structure across a range of syntactic, semantic, local, and
              long-range phenomena. We find that existing models trained on
              language modeling and translation produce strong representations
              for syntactic phenomena, but only offer comparably small
              improvements on semantic tasks over a non-contextual baseline.",
  journal  = "https://openreview.net  forum 
              id=SJzSgnRcKXhttps://openreview.net  forum  id=SJzSgnRcKX",
  month    =  feb,
  year     =  2022,
  keywords = "nlp"
}

@ARTICLE{Yi2019-lo,
  title         = "{CLEVRER}: {CoLlision} Events for Video {REpresentation} and
                   Reasoning",
  author        = "Yi, Kexin and Gan, Chuang and Li, Yunzhu and Kohli, Pushmeet
                   and Wu, Jiajun and Torralba, Antonio and Tenenbaum, Joshua B",
  abstract      = "The ability to reason about temporal and causal events from
                   videos lies at the core of human intelligence. Most video
                   reasoning benchmarks, however, focus on pattern recognition
                   from complex visual and language input, instead of on causal
                   structure. We study the complementary problem, exploring the
                   temporal and causal structures behind videos of objects with
                   simple visual appearance. To this end, we introduce the
                   CoLlision Events for Video REpresentation and Reasoning
                   (CLEVRER), a diagnostic video dataset for systematic
                   evaluation of computational models on a wide range of
                   reasoning tasks. Motivated by the theory of human casual
                   judgment, CLEVRER includes four types of questions:
                   descriptive (e.g., ``what color''), explanatory (``what is
                   responsible for''), predictive (``what will happen next''),
                   and counterfactual (``what if''). We evaluate various
                   state-of-the-art models for visual reasoning on our
                   benchmark. While these models thrive on the perception-based
                   task (descriptive), they perform poorly on the causal tasks
                   (explanatory, predictive and counterfactual), suggesting
                   that a principled approach for causal reasoning should
                   incorporate the capability of both perceiving complex visual
                   and language inputs, and understanding the underlying
                   dynamics and causal relations. We also study an oracle model
                   that explicitly combines these components via symbolic
                   representations.",
  month         =  oct,
  year          =  2019,
  keywords      = "project 2",
  archivePrefix = "arXiv",
  eprint        = "1910.01442",
  primaryClass  = "cs.CV",
  arxivid       = "1910.01442"
}

@ARTICLE{Merullo2022-zx,
  title         = "Linearly Mapping from Image to Text Space",
  author        = "Merullo, Jack and Castricato, Louis and Eickhoff, Carsten
                   and Pavlick, Ellie",
  abstract      = "The extent to which text-only language models (LMs) learn to
                   represent the physical, non-linguistic world is an open
                   question. Prior work has shown that pretrained LMs can be
                   taught to ``understand'' visual inputs when the models'
                   parameters are updated on image captioning tasks. We test a
                   stronger hypothesis: that the conceptual representations
                   learned by text-only models are functionally equivalent (up
                   to a linear transformation) to those learned by models
                   trained on vision tasks. Specifically, we show that the
                   image representations from vision models can be transferred
                   as continuous prompts to frozen LMs by training only a
                   single linear projection. Using these to prompt the LM
                   achieves competitive performance on captioning and visual
                   question answering tasks compared to models that tune both
                   the image encoder and text decoder (such as the MAGMA
                   model). We compare three image encoders with increasing
                   amounts of linguistic supervision seen during pretraining:
                   BEIT (no linguistic information), NF-ResNET (lexical
                   category information), and CLIP (full natural language
                   descriptions). We find that all three encoders perform
                   equally well at transferring visual property information to
                   the language model (e.g., whether an animal is large or
                   small), but that image encoders pretrained with linguistic
                   supervision more saliently encode category information
                   (e.g., distinguishing hippo vs.\textbackslash elephant) and
                   thus perform significantly better on benchmark
                   language-and-vision tasks. Our results indicate that LMs
                   encode conceptual information structurally similarly to
                   vision-based models, even those that are solely trained on
                   images.",
  month         =  sep,
  year          =  2022,
  keywords      = "read;compling-cogsci2023",
  archivePrefix = "arXiv",
  eprint        = "2209.15162",
  primaryClass  = "cs.CL",
  arxivid       = "2209.15162"
}

@UNPUBLISHED{Dubey2021-zq,
  title    = "Aha! moments correspond to metacognitive prediction errors",
  author   = "Dubey, Rachit and Ho, Mark K and Mehta, Hermish and Griffiths,
              Tom",
  abstract = "Psychologists have long been fascinated with understanding the
              nature of Aha! moments, moments when we transition from not
              knowing to suddenly realizing the solution to a problem. In this
              work, we present a theoretical framework that explains why we
              experience Aha! moments. Our theory posits that during
              problem-solving, in addition to solving the problem, people also
              maintain a metacognitive model of their ability to solve the
              problem as well as a prediction about the time it would take them
              to solve that problem. Aha! moments arise when we experience a
              positive error in this metacognitive prediction, i.e. when we
              solve a problem much faster than we expected to solve it. We
              posit that this metacognitive error is analogous to a positive
              reward prediction error thereby explaining why we feel so good
              after an Aha! moment. We provide support to our theory across
              three large-scale pre-registered experiments on problem solving,
              demonstrating a link between metacognitive prediction errors and
              Aha! moments. These results highlight the importance of
              metacognitive prediction errors and deepen our understanding of
              human metareasoning.",
  month    =  jun,
  year     =  2021,
  keywords = "Aha! moment; Insight; metacognition; monitoring and control;
              prediction errors; problem solving; reinforcement
              learning;project 1",
  doi      = "10.31234/osf.io/c5v42"
}

@INPROCEEDINGS{Gerstenberg2015-lf,
  title     = "How, whether, why: Causal judgments as counterfactual contrasts",
  booktitle = "{CogSci}",
  author    = "Gerstenberg, Tobias and Goodman, Noah D and Lagnado, David A and
               Tenenbaum, Joshua B",
  year      =  2015,
  keywords  = "comp-cog-sci;project 2"
}

@ARTICLE{Bakhtin2019-hv,
  title         = "{PHYRE}: A New Benchmark for Physical Reasoning",
  author        = "Bakhtin, Anton and van der Maaten, Laurens and Johnson,
                   Justin and Gustafson, Laura and Girshick, Ross",
  abstract      = "Understanding and reasoning about physics is an important
                   ability of intelligent agents. We develop the PHYRE
                   benchmark for physical reasoning that contains a set of
                   simple classical mechanics puzzles in a 2D physical
                   environment. The benchmark is designed to encourage the
                   development of learning algorithms that are sample-efficient
                   and generalize well across puzzles. We test several modern
                   learning algorithms on PHYRE and find that these algorithms
                   fall short in solving the puzzles efficiently. We expect
                   that PHYRE will encourage the development of novel
                   sample-efficient agents that learn efficient but useful
                   models of physics. For code and to play PHYRE for yourself,
                   please visit https://player.phyre.ai.",
  month         =  aug,
  year          =  2019,
  keywords      = "read;project 2",
  copyright     = "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
  archivePrefix = "arXiv",
  eprint        = "1908.05656",
  primaryClass  = "cs.LG",
  arxivid       = "1908.05656"
}

@UNPUBLISHED{Ludwin-Peery2021-pr,
  title    = "Limits on Simulation Approaches in Intuitive Physics",
  author   = "Ludwin-Peery, Ethan and Bramley, Neil R and Davis, Ernest and
              Gureckis, Todd M",
  abstract = "A popular explanation of the human ability for physical reasoning
              is that it depends on a sophisticated ability to perform mental
              simulations. According to this perspective, physical reasoning
              problems are approached by repeatedly simulating relevant aspects
              of a scenario, with noise, and making judgments based on
              aggregation over these simulations. In this paper, we describe
              three core tenets of simulation approaches, theoretical
              commitments that must be present in order for a simulation
              approach to be viable. The identification of these tenets
              threatens the plausibility of simulation as a theory of physical
              reasoning, because they appear to be incompatible with what we
              know about cognition more generally. To investigate this apparent
              contradiction, we describe three experiments involving simple
              physical judgments and predictions, and argue their results
              challenge these core predictions of theories of mental
              simulation.",
  month    =  jan,
  year     =  2021,
  keywords = "project 2",
  doi      = "10.31234/osf.io/xhzuc"
}

@ARTICLE{Fabricius2021-zg,
  title    = "Perceptual Access Reasoning ({PAR}) in Developing a
              Representational Theory of Mind",
  author   = "Fabricius, William V and Gonzales, Christopher R and Pesch,
              Annelise and Weimer, Amy A and Pugliese, John and Carroll,
              Kathleen and Bolnick, Rebecca R and Kupfer, Anne S and Eisenberg,
              Nancy and Spinrad, Tracy L",
  abstract = "An important part of children's social and cognitive development
              is their understanding that people are psychological beings with
              internal, mental states including desire, intention, perception,
              and belief. A full understanding of people as psychological
              beings requires a representational theory of mind (ToM), which is
              an understanding that mental states can faithfully represent
              reality, or misrepresent reality. For the last 35 years,
              researchers have relied on false-belief tasks as the gold
              standard to test children's understanding that beliefs can
              misrepresent reality. In false-belief tasks, children are asked
              to reason about the behavior of agents who have false beliefs
              about situations. Although a large body of evidence indicates
              that most children pass false-belief tasks by the end of the
              preschool years, the evidence we present in this monograph
              suggests that most children do not understand false beliefs or,
              surprisingly, even true beliefs until middle childhood. We argue
              that young children pass false-belief tasks without understanding
              false beliefs by using perceptual access reasoning (PAR). With
              PAR, children understand that seeing leads to knowing in the
              moment, but not that knowing also arises from thinking or
              persists as memory and belief after the situation changes. By the
              same token, PAR leads children to fail true-belief tasks. PAR
              theory can account for performance on other traditional tests of
              representational ToM and related tasks, and can account for the
              factors that have been found to correlate with or affect both
              true- and false-belief performance. The theory provides a new
              laboratory measure which we label the belief understanding scale
              (BUS). This scale can distinguish between a child who is
              operating with PAR versus a child who is understanding beliefs.
              This scale provides a method needed to allow the study of the
              development of representational ToM. In this monograph, we report
              the outcome of the tests that we have conducted of predictions
              generated by PAR theory. The findings demonstrated signature PAR
              limitations in reasoning about the mind during the ages when
              children are hypothesized to be using PAR. In Chapter II,
              secondary analyses of the published true-belief literature
              revealed that children failed several types of true-belief tasks.
              Chapters III through IX describe new empirical data collected
              across multiple studies between 2003 and 2014 from 580 children
              aged 4-7 years, as well as from a small sample of 14 adults.
              Participants were recruited from the Phoenix, Arizona
              metropolitan area. All participants were native English-speakers.
              Children were recruited from university-sponsored and community
              preschools and daycare centers, and from hospital maternity
              wards. Adults were university students who participated to
              partially fulfill course requirements for research participation.
              Sociometric data were collected only in Chapter IX, and are fully
              reported there. In Chapter III, minor alterations in task
              procedures produced wide variations in children's performance in
              3-option false-belief tasks. In Chapter IV, we report findings
              which show that the developmental lag between children's
              understanding ignorance and understanding false belief is longer
              than the lag reported in previous studies. In Chapter V, children
              did not distinguish between agents who have false beliefs versus
              agents who have no beliefs. In Chapter VI, findings showed that
              children found it no easier to reason about true beliefs than to
              reason about false beliefs. In Chapter VII, when children were
              asked to justify their correct answers in false-belief tasks,
              they did not reference agents' false beliefs. Similarly, in
              Chapter VIII, when children were asked to explain agents' actions
              in false-belief tasks, they did not reference agents' false
              beliefs. In Chapter IX, children who were identified as using PAR
              differed from children who understood beliefs along three
              dimensions-in levels of social development, inhibitory control,
              and kindergarten adjustment. Although the findings need
              replication and additional studies of alternative
              interpretations, the collection of results reported in this
              monograph challenges the prevailing view that representational
              ToM is in place by the end of the preschool years. Furthermore,
              the pattern of findings is consistent with the proposal that PAR
              is the developmental precursor of representational ToM. The
              current findings also raise questions about claims that infants
              and toddlers demonstrate ToM-related abilities, and that
              representational ToM is innate.",
  journal  = "Monogr. Soc. Res. Child Dev.",
  volume   =  86,
  number   =  3,
  pages    = "7--154",
  month    =  sep,
  year     =  2021,
  language = "en",
  issn     = "0037-976X, 1540-5834",
  pmid     = "34580875",
  doi      = "10.1111/mono.12432",
  pmc      = "PMC9292623"
}

@ARTICLE{Allen2022-as,
  title    = "Physical Design using Differentiable Learned Simulators",
  author   = "Allen, Kelsey R and Lopez-Guevara, Tatiana and Stachenfeld, K and
              Sanchez-Gonzalez, Alvaro and Battaglia, P and Hamrick, Jessica B
              and Pfaff, T",
  abstract = "This work explores a simple, fast, and robust approach to inverse
              design which combines learned forward simulators based on graph
              neural networks with gradient-based design optimization, and
              suggests that despite some remaining challenges, machine
              learning-based simulators are maturing to the point where they
              can support general-purpose design optimization across a variety
              of domains. Designing physical artifacts that serve a purpose---
              such as tools and other functional structures---is central to
              engineering as well as everyday human behavior. Though automating
              design has tremendous promise, general-purpose methods do not yet
              exist. Here we explore a simple, fast, and robust approach to
              inverse design which combines learned forward simulators based on
              graph neural networks with gradient-based design optimization.
              Our approach solves high-dimensional problems with complex
              physical dynamics, including designing surfaces and tools to
              manipulate fluid flows and optimizing the shape of an airfoil to
              minimize drag. This framework produces highquality designs by
              propagating gradients through trajectories of hundreds of steps,
              even when using models that were pre-trained for single-step
              predictions on data substantially different from the design
              tasks. In our fluid manipulation tasks, the resulting designs
              outperformed those found by sampling-based optimization
              techniques. In airfoil design, they matched the quality of those
              obtained with a specialized solver. Our results suggest that
              despite some remaining challenges, machine learning-based
              simulators are maturing to the point where they can support
              general-purpose design optimization across a variety of domains.",
  journal  = "ArXiv",
  year     =  2022,
  keywords = "comp-cog-sci;project 2",
  language = "en",
  arxivid  = "2202.00728"
}

@ARTICLE{Balestriero2021-hw,
  title         = "Learning in High Dimension Always Amounts to Extrapolation",
  author        = "Balestriero, Randall and Pesenti, Jerome and LeCun, Yann",
  abstract      = "The notion of interpolation and extrapolation is fundamental
                   in various fields from deep learning to function
                   approximation. Interpolation occurs for a sample $x$
                   whenever this sample falls inside or on the boundary of the
                   given dataset's convex hull. Extrapolation occurs when $x$
                   falls outside of that convex hull. One fundamental
                   (mis)conception is that state-of-the-art algorithms work so
                   well because of their ability to correctly interpolate
                   training data. A second (mis)conception is that
                   interpolation happens throughout tasks and datasets, in
                   fact, many intuitions and theories rely on that assumption.
                   We empirically and theoretically argue against those two
                   points and demonstrate that on any high-dimensional ($>$100)
                   dataset, interpolation almost surely never happens. Those
                   results challenge the validity of our current
                   interpolation/extrapolation definition as an indicator of
                   generalization performances.",
  month         =  oct,
  year          =  2021,
  keywords      = "machine-learning",
  archivePrefix = "arXiv",
  eprint        = "2110.09485",
  primaryClass  = "cs.LG",
  arxivid       = "2110.09485"
}

@ARTICLE{Ullman2017-fo,
  title    = "Mind Games: Game Engines as an Architecture for Intuitive Physics",
  author   = "Ullman, Tomer D and Spelke, Elizabeth and Battaglia, Peter and
              Tenenbaum, Joshua B",
  abstract = "We explore the hypothesis that many intuitive physical inferences
              are based on a mental physics engine that is analogous in many
              ways to the machine physics engines used in building interactive
              video games. We describe the key features of game physics engines
              and their parallels in human mental representation, focusing
              especially on the intuitive physics of young infants where the
              hypothesis helps to unify many classic and otherwise puzzling
              phenomena, and may provide the basis for a computational account
              of how the physical knowledge of infants develops. This
              hypothesis also explains several 'physics illusions', and helps
              to inform the development of artificial intelligence (AI) systems
              with more human-like common sense.",
  journal  = "Trends Cogn. Sci.",
  volume   =  21,
  number   =  9,
  pages    = "649--665",
  month    =  sep,
  year     =  2017,
  keywords = "project 2",
  language = "en",
  issn     = "1364-6613, 1879-307X",
  pmid     = "28655498",
  doi      = "10.1016/j.tics.2017.05.012"
}

@ARTICLE{Johnson-Laird2010-yq,
  title    = "Mental models and human reasoning",
  author   = "Johnson-Laird, Philip N",
  abstract = "To be rational is to be able to reason. Thirty years ago
              psychologists believed that human reasoning depended on formal
              rules of inference akin to those of a logical calculus. This
              hypothesis ran into difficulties, which led to an alternative
              view: reasoning depends on envisaging the possibilities
              consistent with the starting point---a perception of the world, a
              set of assertions, a memory, or some mixture of them. We
              construct mental models of each distinct possibility and derive a
              conclusion from them. The theory predicts systematic errors in
              our reasoning, and the evidence corroborates this prediction.
              Yet, our ability to use counterexamples to refute invalid
              inferences provides a foundation for rationality. On this
              account, reasoning is a simulation of the world fleshed out with
              our knowledge, not a formal rearrangement of the logical
              skeletons of sentences.",
  journal  = "Proceedings of the National Academy of Sciences",
  volume   =  107,
  number   =  43,
  pages    = "18243--18250",
  year     =  2010,
  keywords = "project 1",
  eprint   = "https://www.pnas.org/doi/pdf/10.1073/pnas.1012933107",
  doi      = "10.1073/pnas.1012933107"
}

@INCOLLECTION{Forbus1988-zh,
  title     = "Chapter 7 - Qualitative Physics: Past, Present, and Future",
  booktitle = "Exploring Artificial Intelligence",
  author    = "Forbus, Kenneth D",
  editor    = "Shrobe, Howard E and {the American Association for Artificial
               Intelligence}",
  abstract  = "Publisher Summary Qualitative physics is concerned with
               representing and reasoning about the physical world. The goal of
               qualitative physics is to capture both the commonsense knowledge
               of the person on the street and the tacit knowledge underlying
               the quantitative knowledge used by engineers and scientists. The
               key to qualitative physics is to find ways to represent
               continuous properties of the world by discrete systems of
               symbols. One can always quantize something continuous, but not
               all quantizations are equally useful. One way to state the idea
               is the relevance principle: The distinctions made by a
               quantization must be relevant to the kind of reasoning
               performed. This chapter describes what qualitative physics is,
               why one should be doing it, and where it came from. It discusses
               some open problems in qualitative physics.",
  publisher = "Morgan Kaufmann",
  pages     = "239--296",
  month     =  jan,
  year      =  1988,
  keywords  = "skimmed;project 2",
  isbn      = "9780934613675",
  doi       = "10.1016/B978-0-934613-67-5.50011-3"
}

@ARTICLE{Lupyan2016-mq,
  title     = "The centrality of language in human cognition",
  author    = "Lupyan, Gary",
  abstract  = "The emergence of language---a productive and combinatorial
               system of communication---has been hailed as one of the major
               transitions in evolution. By enabling symbolic culture, language
               allows humans to draw on and expand on the knowledge of their
               ancestors and peers. A common assumption among linguists and
               psychologists is that although language is critical to our
               ability to share our thoughts, it plays a minor, if any, role in
               generating, controlling, and structuring them. I examine some
               assumptions that led to this view of language and discuss an
               alternative according to which normal human cognition is
               language-augmented cognition. I focus on one of the fundamental
               design features of language---the use of words as symbolic
               cues---and argue that language acts as a high-level control
               system for the mind, allowing individuals to sculpt mental
               representations of others as well as their own.",
  journal   = "Lang. Learn.",
  publisher = "Wiley",
  volume    =  66,
  number    =  3,
  pages     = "516--553",
  month     =  sep,
  year      =  2016,
  keywords  = "comp-cog-sci;language",
  copyright = "http://onlinelibrary.wiley.com/termsAndConditions\#vor",
  language  = "en",
  issn      = "0023-8333, 1467-9922",
  doi       = "10.1111/lang.12155"
}

@ARTICLE{Rosedahl2022-py,
  title    = "Linear separability, irrelevant variability, and categorization
              difficulty",
  author   = "Rosedahl, Luke A and Ashby, F Gregory",
  abstract = "In rule-based (RB) category-learning tasks, the optimal strategy
              is a simple explicit rule, whereas in information-integration
              (II) tasks, the optimal strategy is impossible to describe
              verbally. This study investigates the effects of two different
              category properties on learning difficulty in category learning
              tasks-namely, linear separability and variability on stimulus
              dimensions that are irrelevant to the categorization decision.
              Previous research had reported that linearly separable II
              categories are easier to learn than nonlinearly separable
              categories, but Experiment 1, which compared performance on
              linearly and nonlinearly separable categories that were equated
              as closely as possible on all other factors that might affect
              difficulty, found that linear separability had no effect on
              learning. Experiments 1 and 2 together also established a novel
              dissociation between RB and II category learning: increasing
              variability on irrelevant stimulus dimensions impaired II
              learning but not RB learning. These results are all predicted by
              the best available measures of difficulty in RB and II tasks.
              (PsycInfo Database Record (c) 2022 APA, all rights reserved).",
  journal  = "J. Exp. Psychol. Learn. Mem. Cogn.",
  volume   =  48,
  number   =  2,
  pages    = "159--172",
  month    =  feb,
  year     =  2022,
  language = "en",
  issn     = "0278-7393, 1939-1285",
  pmid     = "33871263",
  doi      = "10.1037/xlm0001000",
  pmc      = "PMC8523591"
}

@ARTICLE{Chronicle2004-bv,
  title    = "What makes an insight problem? The roles of heuristics, goal
              conception, and solution recoding in knowledge-lean problems",
  author   = "Chronicle, Edward P and MacGregor, James N and Ormerod, Thomas C",
  abstract = "Four experiments investigated transformation problems with
              insight characteristics. In Experiment 1, performance on a
              version of the 6-coin problem that had a concrete and
              visualizable solution followed a hill-climbing heuristic.
              Experiment 2 demonstrated that the difficulty of a version of the
              problem that potentially required insight for solution stems from
              the same hill-climbing heuristic, which creates an implicit
              conceptual block. Experiment 3 confirmed that the difficulty of
              the potential insight solution is conceptual, not procedural.
              Experiment 4 demonstrated the same principles of move selection
              on the 6-coin problem and the 10-coin (triangle) problem. It is
              argued that hill-climbing heuristics provide a common framework
              for understanding transformation and insight problem solving.
              Postsolution receding may account for part of the phenomenology
              of insight.",
  journal  = "J. Exp. Psychol. Learn. Mem. Cogn.",
  volume   =  30,
  number   =  1,
  pages    = "14--27",
  month    =  jan,
  year     =  2004,
  keywords = "cog-sci;project 1",
  language = "en",
  issn     = "0278-7393",
  pmid     = "14736293",
  doi      = "10.1037/0278-7393.30.1.14"
}

@MISC{Gershman_undated-tc,
  title        = "Perceptual multistability as Markov chain Monte Carlo
                  inference",
  author       = "Gershman, Samuel J and Vul, Edward and Tenenbaum, Joshua B",
  howpublished = "\url{https://gershmanlab.com/pubs/GershmanVulTenenbaum09.pdf}",
  note         = "Accessed: 2023-1-19",
  keywords     = "comp-cog-sci;project 1"
}

@ARTICLE{Wilson2013-cg,
  title    = "Embodied Cognition is Not What you Think it is",
  author   = "Wilson, Andrew D and Golonka, Sabrina",
  abstract = "The most exciting hypothesis in cognitive science right now is
              the theory that cognition is embodied. Like all good ideas in
              cognitive science, however, embodiment immediately came to mean
              six different things. The most common definitions involve the
              straight-forward claim that ``states of the body modify states of
              the mind.'' However, the implications of embodiment are actually
              much more radical than this. If cognition can span the brain,
              body, and the environment, then the ``states of mind'' of
              disembodied cognitive science won't exist to be modified.
              Cognition will instead be an extended system assembled from a
              broad array of resources. Taking embodiment seriously therefore
              requires both new methods and theory. Here we outline four key
              steps that research programs should follow in order to fully
              engage with the implications of embodiment. The first step is to
              conduct a task analysis, which characterizes from a first person
              perspective the specific task that a perceiving-acting cognitive
              agent is faced with. The second step is to identify the
              task-relevant resources the agent has access to in order to solve
              the task. These resources can span brain, body, and environment.
              The third step is to identify how the agent can assemble these
              resources into a system capable of solving the problem at hand.
              The last step is to test the agent's performance to confirm that
              agent is actually using the solution identified in step 3. We
              explore these steps in more detail with reference to two useful
              examples (the outfielder problem and the A-not-B error), and
              introduce how to apply this analysis to the thorny question of
              language use. Embodied cognition is more than we think it is, and
              we have the tools we need to realize its full potential.",
  journal  = "Front. Psychol.",
  volume   =  4,
  pages    = "58",
  month    =  feb,
  year     =  2013,
  keywords = "A-not-B error; dynamical systems; embodied cognition; language;
              outfielder problem; replacement hypothesis; robotics;project
              1;cog-sci",
  language = "en",
  issn     = "1664-1078",
  pmid     = "23408669",
  doi      = "10.3389/fpsyg.2013.00058",
  pmc      = "PMC3569617"
}

@UNPUBLISHED{Schulz2017-ij,
  title    = "Strategic exploration in human adaptive control",
  author   = "Schulz, Eric and Klenske, Edgar D and Bramley, Neil R and
              Speekenbrink, Maarten",
  abstract = "Abstract How do people explore in order to gain rewards in
              uncertain dynamical systems? Within a reinforcement learning
              paradigm, control normally involves trading off between
              exploration (i.e. trying out actions in order to gain more
              knowledge about the system) and exploitation (i.e. using current
              knowledge of the system to maximize reward). We study a novel
              control task in which participants must steer a boat on a grid,
              aiming to follow a path of high reward whilst learning how their
              actions affect the boat's position. We find that participants
              explore strategically yet conservatively, exploring more when
              mistakes are less costly and practicing actions that will be
              required later on.",
  journal  = "bioRxiv",
  pages    = "110486",
  month    =  may,
  year     =  2017,
  keywords = "project 1",
  language = "en",
  doi      = "10.1101/110486"
}

@ARTICLE{Thevenot2008-ob,
  title    = "A generalization of the representational change theory from
              insight to non-insight problems: the case of arithmetic word
              problems",
  author   = "Thevenot, Catherine and Oakhill, Jane",
  abstract = "This paper provides evidence for a possible generalization of
              Knoblich and colleagues' representational change theory
              [Knoblich, G., Ohlsson, S., Haider, H., \& Rhenius, D. (1999).
              Constraint relaxation and chunk decomposition in insight problem
              solving. Journal of Experimental Psychology: Learning, Memory,
              and Cognition, 25, 1534-1555; Knoblich, G., Ohlsson, S., \&
              Raney, G. E. (2001). An eye movement study of insight problem.
              Memory and Cognition, 29, 1000-1009] outside its original scope
              of application. While this theory has been proposed to explain
              insight problem solving, we demonstrate here that its main
              concepts, namely, constraint relaxation and chunk decomposition,
              are applicable to incremental problem solving. In a first
              experiment, we confirm, as already shown by problem solving and
              reasoning researchers, that individuals avoid the construction of
              alternative representations of the problems when possible. In the
              second and third experiments, we show that alternative
              representations of arithmetic problems are easier to construct
              and maintain when they violate constraints of narrow rather than
              wide scope. The specificity of insight problem solving is
              discussed in the light of these new findings.",
  journal  = "Acta Psychol.",
  volume   =  129,
  number   =  3,
  pages    = "315--324",
  month    =  nov,
  year     =  2008,
  keywords = "project 1",
  language = "en",
  issn     = "0001-6918, 1873-6297",
  pmid     = "18834964",
  doi      = "10.1016/j.actpsy.2008.08.008"
}

@ARTICLE{Ollinger2008-fw,
  title    = "Investigating the effect of mental set on insight problem solving",
  author   = "Ollinger, Michael and Jones, Gary and Knoblich, G{\"u}nther",
  abstract = "Mental set is the tendency to solve certain problems in a fixed
              way based on previous solutions to similar problems. The moment
              of insight occurs when a problem cannot be solved using solution
              methods suggested by prior experience and the problem solver
              suddenly realizes that the solution requires different solution
              methods. Mental set and insight have often been linked together
              and yet no attempt thus far has systematically examined the
              interplay between the two. Three experiments are presented that
              examine the extent to which sets of noninsight and insight
              problems affect the subsequent solutions of insight test
              problems. The results indicate a subtle interplay between mental
              set and insight: when the set involves noninsight problems, no
              mental set effects are shown for the insight test problems, yet
              when the set involves insight problems, both facilitation and
              inhibition can be seen depending on the type of insight problem
              presented in the set. A two process model is detailed to explain
              these findings that combines the representational change
              mechanism with that of proceduralization.",
  journal  = "Exp. Psychol.",
  volume   =  55,
  number   =  4,
  pages    = "269--282",
  year     =  2008,
  keywords = "project 1",
  language = "en",
  issn     = "1618-3169",
  pmid     = "18683624",
  doi      = "10.1027/1618-3169.55.4.269"
}

@INCOLLECTION{McClelland1988-qm,
  title     = "The appeal of parallel distributed processing",
  booktitle = "Readings in cognitive science: A perspective from psychology and
               artificial intelligence , (pp",
  author    = "McClelland, James L and Rumelhart, David E and Hinton, G E",
  editor    = "Collins, Allan M",
  abstract  = "multiple simultaneous constraints parallel distributed
               processing [PDP] / examples of PDP models representation and
               learning in PDP models origins of parallel distributed
               processing (PsycInfo Database Record (c) 2022 APA, all rights
               reserved)",
  volume    =  661,
  pages     = "52--72",
  year      =  1988,
  keywords  = "read;ccm2023;comp-cog-sci"
}

@ARTICLE{Elman1990-pd,
  title     = "Finding structure in time",
  author    = "Elman, Jeffrey L",
  abstract  = "Time underlies many interesting human behaviors. Thus, the
               question of how to represent time in connectionist models is
               very important. One approach is to represent time implicitly by
               its effects on processing rather than explicitly (as in a
               spatial representation). The current report develops a proposal
               along these lines first described by Jordan (1986) which
               involves the use of recurrent links in order to provide networks
               with a dynamic memory. In this approach, hidden unit patterns
               are fed back to themselves; the internal representations which
               develop thus reflect task demands in the context of prior
               internal states. A set of simulations is reported which range
               from relatively simple problems (temporal version of XOR) to
               discovering syntactic/semantic features for words. The networks
               are able to learn interesting internal representations which
               incorporate task demands with memory demands; indeed, in this
               approach the notion of memory is inextricably bound up with task
               processing. These representations reveal a rich structure, which
               allows them to be highly context-dependent while also expressing
               generalizations across classes of items. These representations
               suggest a method for representing lexical categories and the
               type/token distinction.",
  journal   = "Cogn. Sci.",
  publisher = "Wiley",
  volume    =  14,
  number    =  2,
  pages     = "179--211",
  month     =  mar,
  year      =  1990,
  keywords  = "read;ccm2023;comp-cog-sci",
  language  = "en",
  issn      = "0364-0213, 1551-6709",
  doi       = "10.1207/s15516709cog1402\_1"
}

@ARTICLE{Ollinger2014-qq,
  title    = "The dynamics of search, impasse, and representational change
              provide a coherent explanation of difficulty in the nine-dot
              problem",
  author   = "{\"O}llinger, Michael and Jones, Gary and Knoblich, G{\"u}nther",
  abstract = "The nine-dot problem is often used to demonstrate and explain
              mental impasse, creativity, and out of the box thinking. The
              present study investigated the interplay of a restricted initial
              search space, the likelihood of invoking a representational
              change, and the subsequent constraining of an unrestricted search
              space. In three experimental conditions, participants worked on
              different versions of the nine-dot problem that hinted at
              removing particular sources of difficulty from the standard
              problem. The hints were incremental such that the first suggested
              a possible route for a solution attempt; the second additionally
              indicated the dot at which lines meet on the solution path; and
              the final condition also provided non-dot locations that appear
              in the solution path. The results showed that in the experimental
              conditions, representational change is encountered more quickly
              and problems are solved more often than for the control group. We
              propose a cognitive model that focuses on general problem-solving
              heuristics and representational change to explain problem
              difficulty.",
  journal  = "Psychol. Res.",
  volume   =  78,
  number   =  2,
  pages    = "266--275",
  month    =  mar,
  year     =  2014,
  keywords = "read;project 1",
  language = "en",
  issn     = "0340-0727, 1430-2772",
  pmid     = "23708954",
  doi      = "10.1007/s00426-013-0494-8"
}

@ARTICLE{Xue2023-uc,
  title     = "{Phy-Q} as a measure for physical reasoning intelligence",
  author    = "Xue, Cheng and Pinto, Vimukthini and Gamage, Chathura and
               Nikonova, Ekaterina and Zhang, Peng and Renz, Jochen",
  abstract  = "Humans are well versed in reasoning about the behaviours of
               physical objects and choosing actions accordingly to accomplish
               tasks, while this remains a major challenge for artificial
               intelligence. To facilitate research addressing this problem, we
               propose a new testbed that requires an agent to reason about
               physical scenarios and take an action appropriately. Inspired by
               the physical knowledge acquired in infancy and the capabilities
               required for robots to operate in real-world environments, we
               identify 15 essential physical scenarios. We create a wide
               variety of distinct task templates, and we ensure that all the
               task templates within the same scenario can be solved by using
               one specific strategic physical rule. By having such a design,
               we evaluate two distinct levels of generalization, namely local
               generalization and broad generalization. We conduct an extensive
               evaluation with human players, learning agents with various
               input types and architectures, and heuristic agents with
               different strategies. Inspired by how the human intelligence
               quotient is calculated, we define the physical reasoning
               quotient (Phy-Q score) that reflects the physical reasoning
               intelligence of an agent using the physical scenarios we
               considered. Our evaluation shows that (1) all the agents are far
               below human performance, and (2) learning agents, even with good
               local generalization ability, struggle to learn the underlying
               physical reasoning rules and fail to generalize broadly. We
               encourage the development of intelligent agents that can reach
               the human-level Phy-Q score. When it comes to reasoning about
               the motion of physical objects, humans have natural intuitive
               physics knowledge. To test how good artificial learning agents
               are in similar predictive abilities, Xue and colleagues present
               a benchmark based on a two-dimensional physics environment in
               which 15 physical reasoning skills are measured.",
  journal   = "Nature Machine Intelligence",
  publisher = "Nature Publishing Group",
  volume    =  5,
  number    =  1,
  pages     = "83--93",
  month     =  jan,
  year      =  2023,
  keywords  = "read;comp-cog-sci;project 2",
  language  = "en",
  issn      = "2522-5839, 2522-5839",
  doi       = "10.1038/s42256-022-00583-4"
}

@ARTICLE{Goyal2021-dr,
  title         = "Neural Production Systems: Learning {Rule-Governed} Visual
                   Dynamics",
  author        = "Goyal, Anirudh and Didolkar, Aniket and Ke, Nan Rosemary and
                   Blundell, Charles and Beaudoin, Philippe and Heess, Nicolas
                   and Mozer, Michael and Bengio, Yoshua",
  abstract      = "Visual environments are structured, consisting of distinct
                   objects or entities. These entities have properties -- both
                   visible and latent -- that determine the manner in which
                   they interact with one another. To partition images into
                   entities, deep-learning researchers have proposed structural
                   inductive biases such as slot-based architectures. To model
                   interactions among entities, equivariant graph neural nets
                   (GNNs) are used, but these are not particularly well suited
                   to the task for two reasons. First, GNNs do not predispose
                   interactions to be sparse, as relationships among
                   independent entities are likely to be. Second, GNNs do not
                   factorize knowledge about interactions in an
                   entity-conditional manner. As an alternative, we take
                   inspiration from cognitive science and resurrect a classic
                   approach, production systems, which consist of a set of rule
                   templates that are applied by binding placeholder variables
                   in the rules to specific entities. Rules are scored on their
                   match to entities, and the best fitting rules are applied to
                   update entity properties. In a series of experiments, we
                   demonstrate that this architecture achieves a flexible,
                   dynamic flow of control and serves to factorize
                   entity-specific and rule-based information. This
                   disentangling of knowledge achieves robust future-state
                   prediction in rich visual environments, outperforming
                   state-of-the-art methods using GNNs, and allows for the
                   extrapolation from simple (few object) environments to more
                   complex environments.",
  month         =  mar,
  year          =  2021,
  keywords      = "compling-cogsci2023",
  archivePrefix = "arXiv",
  eprint        = "2103.01937",
  primaryClass  = "cs.AI",
  arxivid       = "2103.01937"
}

@ARTICLE{Sumers2023-kl,
  title    = "Show or tell? Exploring when (and why) teaching with language
              outperforms demonstration",
  author   = "Sumers, Theodore R and Ho, Mark K and Hawkins, Robert D and
              Griffiths, Thomas L",
  abstract = "People use a wide range of communicative acts across different
              modalities, from concrete demonstrations to abstract language.
              While these modalities are typically studied independently, we
              take a comparative approach and ask when and why one modality
              might outperform another. We present a series of real-time,
              multi-player experiments asking participants to teach concepts
              using either demonstrations or language. Our first experiment
              (N=416) asks when language might outperform demonstration. We
              manipulate the complexity of the concept being taught and find
              that language communicates complex concepts more effectively than
              demonstration. We then ask why language succeeds in this setting.
              We hypothesized that language allowed teachers to reference
              abstract object features (e.g., shapes and colors), while
              demonstration teachers could only provide concrete examples
              (specific positive or negative objects). To test this hypothesis,
              our second experiment (N=568) ablated object features from the
              teacher's interface. This manipulation severely impaired
              linguistic (but not demonstrative) teaching. Our findings suggest
              that language communicates complex concepts by directly
              transmitting abstract rules. In contrast, demonstrations transmit
              examples, requiring the learner to infer the rules.",
  journal  = "Cognition",
  volume   =  232,
  pages    = "105326",
  month    =  mar,
  year     =  2023,
  keywords = "Abstraction; Communication; Demonstration; Language;
              Pedagogy;comp-cog-sci",
  language = "en",
  issn     = "0010-0277, 1873-7838",
  pmid     = "36473238",
  doi      = "10.1016/j.cognition.2022.105326"
}

@MISC{Kosoy_undated-ah,
  title    = "Learning Causal Overhypotheses through Exploration in Children
              and Computational Models",
  author   = "Kosoy, Eliza and Liu, Adrian and Collins, Jasmine and Chan, David
              M and Hamrick, Jessica B and Rosemary, Nan and Huang, Sandy Han
              and Kaufmann, Bryanna and Gopnik, Alison and Sch{\"o}lkopf,
              Bernhard and Uhler, Caroline and Zhang, Kun and Ke, N R and
              Canny, J",
  keywords = "comp-cog-sci;development",
  arxivid  = "2202.10430v1"
}

@ARTICLE{Lynch2019-eb,
  title         = "Learning latent plans from play",
  author        = "Lynch, Corey and Khansari, Mohi and Xiao, Ted and Kumar,
                   Vikash and Tompson, Jonathan and Levine, Sergey and
                   Sermanet, Pierre",
  abstract      = "Acquiring a diverse repertoire of general-purpose skills
                   remains an open challenge for robotics. In this work, we
                   propose self-supervising control on top of human
                   teleoperated play data as a way to scale up skill learning.
                   Play has two properties that make it attractive compared to
                   conventional task demonstrations. Play is cheap, as it can
                   be collected in large quantities quickly without task
                   segmenting, labeling, or resetting to an initial state. Play
                   is naturally rich, covering ~4x more interaction space than
                   task demonstrations for the same amount of collection time.
                   To learn control from play, we introduce Play-LMP, a
                   self-supervised method that learns to organize play
                   behaviors in a latent space, then reuse them at test time to
                   achieve specific goals. Combining self-supervised control
                   with a diverse play dataset shifts the focus of skill
                   learning from a narrow and discrete set of tasks to the full
                   continuum of behaviors available in an environment. We find
                   that this combination generalizes well empirically---after
                   self-supervising on unlabeled play, our method substantially
                   outperforms individual expert-trained policies on 18
                   difficult user-specified visual manipulation tasks in a
                   simulated robotic tabletop environment. We additionally find
                   that play-supervised models, unlike their expert-trained
                   counterparts, are more robust to perturbations and exhibit
                   retrying-till-success behaviors. Finally, we find that our
                   agent organizes its latent plan space around functional
                   tasks, despite never being trained with task labels. Videos,
                   code and data are available at learning-from-play.github.io",
  month         =  mar,
  year          =  2019,
  keywords      = "comp-cog-sci;ARC Project",
  copyright     = "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
  archivePrefix = "arXiv",
  eprint        = "1903.01973",
  primaryClass  = "cs.RO",
  arxivid       = "1903.01973"
}

@ARTICLE{Knoblich1999-jd,
  title    = "Constraint relaxation and chunk decomposition in insight problem
              solving",
  author   = "Knoblich, G{\"u}nther and Ohlsson, Stellan and Haider, Hilde and
              Rhenius, Detlef",
  abstract = "Insight problem solving is characterized by impasses, states of
              mind in which the thinker does not know what to do next. The
              authors hypothesized that impasses are broken by changing the
              problem representation, and 2 hypothetical mechanisms for
              representational change are described: the relaxation of
              constraints on the solution and the decomposition of perceptual
              chunks. These 2 mechanisms generate specific predictions about
              the relative difficulty of individual problems and about
              differential transfer effects. The predictions were tested in 4
              experiments using matchstick arithmetic problems. The results
              were consistent with the predictions. Representational change is
              a more powerful explanation for insight than alternative
              hypotheses, if the hypothesized change processes are specified in
              detail. Overcoming impasses in insight is a special case of the
              general need to override the imperatives of past experience in
              the face of novel conditions. (PsycINFO Database Record (c) 2016
              APA, all rights reserved)",
  journal  = "J. Exp. Psychol. Learn. Mem. Cogn.",
  volume   =  25,
  number   =  6,
  pages    = "1534--1555",
  month    =  nov,
  year     =  1999,
  issn     = "0278-7393, 1939-1285",
  doi      = "10.1037/0278-7393.25.6.1534"
}

@ARTICLE{Meltzoff2009-eq,
  title    = "Foundations for a new science of learning",
  author   = "Meltzoff, Andrew N and Kuhl, Patricia K and Movellan, Javier and
              Sejnowski, Terrence J",
  abstract = "Human learning is distinguished by the range and complexity of
              skills that can be learned and the degree of abstraction that can
              be achieved compared with those of other species. Homo sapiens is
              also the only species that has developed formal ways to enhance
              learning: teachers, schools, and curricula. Human infants have an
              intense interest in people and their behavior and possess
              powerful implicit learning mechanisms that are affected by social
              interaction. Neuroscientists are beginning to understand the
              brain mechanisms underlying learning and how shared brain systems
              for perception and action support social learning. Machine
              learning algorithms are being developed that allow robots and
              computers to learn autonomously. New insights from many different
              fields are converging to create a new science of learning that
              may transform educational practices.",
  journal  = "Science",
  volume   =  325,
  number   =  5938,
  pages    = "284--288",
  month    =  jul,
  year     =  2009,
  keywords = "read;learning\&memory2023;cog-sci",
  language = "en",
  issn     = "0036-8075, 1095-9203",
  pmid     = "19608908",
  doi      = "10.1126/science.1175626",
  pmc      = "PMC2776823"
}

@ARTICLE{Zador2019-hq,
  title    = "A critique of pure learning and what artificial neural networks
              can learn from animal brains",
  author   = "Zador, Anthony M",
  abstract = "Artificial neural networks (ANNs) have undergone a revolution,
              catalyzed by better supervised learning algorithms. However, in
              stark contrast to young animals (including humans), training such
              networks requires enormous numbers of labeled examples, leading
              to the belief that animals must rely instead mainly on
              unsupervised learning. Here we argue that most animal behavior is
              not the result of clever learning algorithms-supervised or
              unsupervised-but is encoded in the genome. Specifically, animals
              are born with highly structured brain connectivity, which enables
              them to learn very rapidly. Because the wiring diagram is far too
              complex to be specified explicitly in the genome, it must be
              compressed through a ``genomic bottleneck''. The genomic
              bottleneck suggests a path toward ANNs capable of rapid learning.",
  journal  = "Nat. Commun.",
  volume   =  10,
  number   =  1,
  pages    = "3770",
  month    =  aug,
  year     =  2019,
  keywords = "read;cog-sci;learning\&memory2023",
  language = "en",
  issn     = "2041-1723",
  pmid     = "31434893",
  doi      = "10.1038/s41467-019-11786-6",
  pmc      = "PMC6704116"
}

@ARTICLE{McClelland2003-bz,
  title    = "The parallel distributed processing approach to semantic
              cognition",
  author   = "McClelland, James L and Rogers, Timothy T",
  journal  = "Nat. Rev. Neurosci.",
  volume   =  4,
  number   =  4,
  pages    = "310--322",
  month    =  apr,
  year     =  2003,
  keywords = "read;comp-cog-sci;ccm2023",
  language = "en",
  issn     = "1471-003X",
  pmid     = "12671647",
  doi      = "10.1038/nrn1076"
}

@ARTICLE{Kaplan1990-zd,
  title    = "In search of insight",
  author   = "Kaplan, Craig A and Simon, Herbert A",
  abstract = "This paper describes the process of attaining the insight
              required to solve a particular problem---the Mutilated
              Checkerboard (MC) problem. It shows that attaining insight
              requires discovering an effective problem representation, and
              that performance on insight problems can be predicted from the
              availability of generators and constraints in the search for such
              a representation. To test these claims we varied the salience of
              features leading to the critical concept of parity in the MC
              problem. Using chronometric measures, verbal protocols, and
              computer simulations, we explored first why it is difficult to
              find a representation for the Checkerboard problem, and then
              tested four potential sources of search constraint for reducing
              the difficulty: cue salience manipulations, prior knowledge,
              hints, and heuristics. While subjects used each of these four
              sources of constraint, a particular heuristic---noticing
              properties of the situation that remained invariant during
              solution attempts (the Notice Invariants heuristic)---proved to
              be a particularly powerful means for focusing search. In
              conjunction with hints and independently, it played a major part
              in producing the insight that yielded an effective problem
              representation and solution.",
  journal  = "Cogn. Psychol.",
  volume   =  22,
  number   =  3,
  pages    = "374--419",
  month    =  jul,
  year     =  1990,
  keywords = "comp-cog-sci;project 1",
  issn     = "0010-0285",
  doi      = "10.1016/0010-0285(90)90008-R"
}

@ARTICLE{Nosofsky2022-fh,
  title    = "Generalization in Distant Regions of a {Rule-Described} Category
              Space: a Mixed Exemplar and {Logical-Rule-Based} Account",
  author   = "Nosofsky, Robert M and Hu, Mingjia",
  abstract = "An important question in the cognitive-psychology of category
              learning concerns the manner in which observers generalize their
              trained category knowledge at time of transfer. In recent work,
              Conaway and Kurtz (Conaway and Kurtz, Psychonomic Bulletin \&
              Review 24:1312--1323, 2017) reported results from a novel
              paradigm in which participants learned rule-described categories
              defined over two dimensions and then classified test items in
              distant transfer regions of the category space. The paradigm
              yielded results that challenged the predictions from both
              exemplar-based and logical-rule-based models of categorization
              but that the authors suggested were as predicted by a divergent
              auto-encoder (DIVA) model (Kurtz, Psychonomic Bulletin \& Review
              14:560--576, 2007, Kurtz, Psychology of learning and motivation,
              Academic Press, New York, 2015). In this article, we pursue these
              challenges by conducting replications and extensions of the
              original experiment and fitting a variety of computational models
              to the resulting data. We find that even an extended version of
              the exemplar model that makes allowance for learning-during-test
              (LDT) processes fails to account for the results. In addition,
              models that presume a mixture of salient logical rules also fail
              to account for the findings. However, as a proof of concept, we
              illustrate that a model that assumes a mixture of strategies
              across subjects---some relying on exemplar-based memories with
              LDT, and others on salient logical rules---provides an
              outstanding account of the data. By comparison, DIVA performs
              considerably worse than does this LDT-exemplar-rule mixture
              account. These results converge with past ones reported in the
              literature that point to multiple forms of category
              representation as well as to the role of LDT processes in
              influencing how observers generalize their category knowledge.",
  journal  = "Computational Brain \& Behavior",
  volume   =  5,
  number   =  4,
  pages    = "435--466",
  month    =  dec,
  year     =  2022,
  keywords = "comp-cog-sci",
  issn     = "2522-087X",
  doi      = "10.1007/s42113-022-00151-4"
}

@ARTICLE{Ash2006-bc,
  title    = "The nature of restructuring in insight: an individual-differences
              approach",
  author   = "Ash, Ivan K and Wiley, Jennifer",
  abstract = "The insightful problem-solving process has been proposed to
              involve three main phases: an initial representation phase, in
              which the solver inappropriately represents the problem; an
              initial search through the faulty problem space that may lead to
              impasse; and a postimpasse restructuring phase. Some theories
              propose that the restructuring phase involves controlled search
              processes, whereas other theories propose that restructuring is
              achieved through the automatic redistribution of activation in
              long-term memory. In this study, we used correlations between
              working memory (WM) span measures and problem-solving success to
              test the predictions of these different theories. One group of
              participants received a set of insight problems that allowed for
              a large initial faulty search space, whereas another group
              received a matched set that constrained the initial faulty search
              space in order to isolate the restructuring phase of the
              insightful process. The results suggest that increased ability to
              control attention (as measured by WM span tasks) predicts an
              individual's ability to successfully solve problems that involve
              both the initial search phase and the restructuring phase.
              However, individual differences in ability to control attention
              do not predict success on problems that isolate the restructuring
              phase. These results are interpreted as supporting an
              automatic-redistribution-of-activation account of restructuring.",
  journal  = "Psychon. Bull. Rev.",
  volume   =  13,
  number   =  1,
  pages    = "66--73",
  month    =  feb,
  year     =  2006,
  keywords = "project 1;cog-sci",
  language = "en",
  issn     = "1069-9384",
  pmid     = "16724770",
  doi      = "10.3758/bf03193814"
}

@ARTICLE{Jones2003-sh,
  title    = "Testing two cognitive theories of insight",
  author   = "Jones, Gary",
  abstract = "Insight in problem solving occurs when the problem solver fails
              to see how to solve a problem and then--``aha!''--there is a
              sudden realization how to solve it. Two contemporary theories
              have been proposed to explain insight. The representational
              change theory (e.g., G. Knoblich, S. Ohlsson, \& G. E. Rainey,
              2001) proposes that insight occurs through relaxing self-imposed
              constraints on a problem and by decomposing chunked items in the
              problem. The progress monitoring theory (e.g., J. N. MacGregor,
              T. C. Ormerod, \& E. P. Chronicle, 2001) proposes that insight is
              only sought once it becomes apparent that the distance to the
              goal is unachievable in the moves remaining. These 2 theories are
              tested in an unlimited move problem, to which neither theory has
              previously been applied. The results lend support to both, but
              experimental manipulations to the problem suggest that the
              representational change theory is the better indicator of
              performance. The findings suggest that testable opposing
              predictions can be made to examine theories of insight and that
              the use of eye movement data is a fruitful method of both
              examining insight and testing theories of insight.",
  journal  = "J. Exp. Psychol. Learn. Mem. Cogn.",
  volume   =  29,
  number   =  5,
  pages    = "1017--1027",
  month    =  sep,
  year     =  2003,
  keywords = "project 1;cog-sci",
  language = "en",
  issn     = "0278-7393",
  pmid     = "14516232",
  doi      = "10.1037/0278-7393.29.5.1017"
}

@ARTICLE{Ollinger2013-zu,
  title    = "Cognitive mechanisms of insight: the role of heuristics and
              representational change in solving the eight-coin problem",
  author   = "{\"O}llinger, Michael and Jones, Gary and Faber, Amory H and
              Knoblich, G{\"u}nther",
  abstract = "The 8-coin insight problem requires the problem solver to move 2
              coins so that each coin touches exactly 3 others. Ormerod,
              MacGregor, and Chronicle (2002) explained differences in task
              performance across different versions of the 8-coin problem using
              the availability of particular moves in a 2-dimensional search
              space. We explored 2 further explanations by developing 6 new
              versions of the 8-coin problem in order to investigate the
              influence of grouping and self-imposed constraints on solutions.
              The results identified 2 sources of problem difficulty: first,
              the necessity to overcome the constraint that a solution can be
              found in 2-dimensional space and, second, the necessity to
              decompose perceptual groupings. A detailed move analysis
              suggested that the selection of moves was driven by the
              established representation rather than the application of the
              appropriate heuristics. Both results support the assumptions of
              representational change theory (Ohlsson, 1992).",
  journal  = "J. Exp. Psychol. Learn. Mem. Cogn.",
  volume   =  39,
  number   =  3,
  pages    = "931--939",
  month    =  may,
  year     =  2013,
  keywords = "project 1;cog-sci",
  language = "en",
  issn     = "0278-7393, 1939-1285",
  pmid     = "22799283",
  doi      = "10.1037/a0029194"
}

@ARTICLE{Battaglia2013-eg,
  title    = "Simulation as an engine of physical scene understanding",
  author   = "Battaglia, Peter W and Hamrick, Jessica B and Tenenbaum, Joshua B",
  abstract = "In a glance, we can perceive whether a stack of dishes will
              topple, a branch will support a child's weight, a grocery bag is
              poorly packed and liable to tear or crush its contents, or a tool
              is firmly attached to a table or free to be lifted. Such rapid
              physical inferences are central to how people interact with the
              world and with each other, yet their computational underpinnings
              are poorly understood. We propose a model based on an ``intuitive
              physics engine,'' a cognitive mechanism similar to computer
              engines that simulate rich physics in video games and graphics,
              but that uses approximate, probabilistic simulations to make
              robust and fast inferences in complex natural scenes where
              crucial information is unobserved. This single model fits data
              from five distinct psychophysical tasks, captures several
              illusions and biases, and explains core aspects of human mental
              models and common-sense reasoning that are instrumental to how
              humans understand their everyday world.",
  journal  = "Proc. Natl. Acad. Sci. U. S. A.",
  volume   =  110,
  number   =  45,
  pages    = "18327--18332",
  month    =  nov,
  year     =  2013,
  keywords = "project 2;comp-cog-sci",
  language = "en",
  issn     = "0027-8424, 1091-6490",
  pmid     = "24145417",
  doi      = "10.1073/pnas.1306572110",
  pmc      = "PMC3831455"
}

@ARTICLE{Gallistel2021-ft,
  title    = "The physical basis of memory",
  author   = "Gallistel, C R",
  abstract = "Neuroscientists are searching for the engram within the
              conceptual framework established by John Locke's theory of mind.
              This framework was elaborated before the development of
              information theory, before the development of information
              processing machines and the science of computation, before the
              discovery that molecules carry hereditary information, before the
              discovery of the codon code and the molecular machinery for
              editing the messages written in this code and translating it into
              transcription factors that mark abstract features of organic
              structure such as anterior and distal. The search for the engram
              needs to abandon Locke's conceptual framework and work within a
              framework informed by these developments. The engram is the
              medium by which information extracted from past experience is
              transmitted to the computations that inform future behavior. The
              information-conveying symbols in the engram are rapidly generated
              in the course of computations, which implies that they are
              molecules.",
  journal  = "Cognition",
  volume   =  213,
  pages    = "104533",
  month    =  aug,
  year     =  2021,
  keywords = "Communication channel; Engram; Molecules; Plastic
              synapse;comp-cog-sci;learning\&memory2023",
  language = "en",
  issn     = "0010-0277, 1873-7838",
  pmid     = "33375954",
  doi      = "10.1016/j.cognition.2020.104533"
}

@ARTICLE{Kershaw2013-hb,
  title     = "Multiple paths to transfer and constraint relaxation in insight
               problem solving",
  author    = "Kershaw, Trina C and Flynn, Christopher K and Gordon, Leamarie T",
  abstract  = "In two experiments participants received various training
               methods designed to relax constraints present in the Four-Tree
               problem (deBono, 1967), a difficult insight problem. Geometry
               misconceptions were corrected via direct instruction.
               Participants? difficulty with developing three-dimensional
               representations was addressed via spontaneous analogical
               transfer (Experiment 1) or via cued analogical transfer
               (Experiment 2). We found that, while both training methods were
               effective, alleviating multiple constraints was more effective
               than the alleviation of single constraints via training
               programmes (c.f. Kershaw Nokes \& Ohlsson, 2005) and multiple
               constraints are discussed.",
  journal   = "Think. Reason.",
  publisher = "Routledge",
  volume    =  19,
  number    =  1,
  pages     = "96--136",
  month     =  feb,
  year      =  2013,
  keywords  = "cog-sci;project 1",
  issn      = "1354-6783",
  doi       = "10.1080/13546783.2012.742852"
}

@ARTICLE{Chu2007-xx,
  title    = "Theory Driven Hints in the Cheap Necklace Problem: A Preliminary
              Investigation",
  author   = "Chu, Yun and Dewald, Andrew D and Chronicle, Edward P",
  abstract = "Three experiments investigated the effects of two hints derived
              from the Criterion for Satisfactory Progress theory (CSP) and
              Representational Change Theory (RCT) on the cheap necklace
              problem (insight problem). In Experiment 1, fewer participants
              given the CSP hint used an incorrect (maximizing) first move than
              participants given the RCT hint or control participants given no
              hint on a single attempt at the problem. Experiment 2 found the
              number of trials to solution was fewer in the CSP condition than
              in the control over ten trials, and there were fewer incorrect
              first moves in the CSP. The results appear to support the CSP
              theory. However, in Experiment 3, the CSP and RCT hints were
              combined yielding a 75\% solution rate over 34.88\% in the
              control. Perhaps aspects from both theories are employed during
              the problem solving process.",
  journal  = "The Journal of Problem Solving",
  volume   =  1,
  number   =  2,
  pages    = "4",
  year     =  2007,
  keywords = "project 1",
  issn     = "1932-6246",
  doi      = "10.7771/1932-6246.1010"
}

@ARTICLE{Chater2013-hv,
  title    = "Programs as causal models: speculations on mental programs and
              mental representation",
  author   = "Chater, Nick and Oaksford, Mike",
  abstract = "Judea Pearl has argued that counterfactuals and causality are
              central to intelligence, whether natural or artificial, and has
              helped create a rich mathematical and computational framework for
              formally analyzing causality. Here, we draw out connections
              between these notions and various current issues in cognitive
              science, including the nature of mental ``programs'' and mental
              representation. We argue that programs (consisting of algorithms
              and data structures) have a causal (counterfactual-supporting)
              structure; these counterfactuals can reveal the nature of mental
              representations. Programs can also provide a causal model of the
              external world. Such models are, we suggest, ubiquitous in
              perception, cognition, and language processing.",
  journal  = "Cogn. Sci.",
  volume   =  37,
  number   =  6,
  pages    = "1171--1191",
  month    =  aug,
  year     =  2013,
  keywords = "comp-cog-sci;project 1;project 2",
  language = "en",
  issn     = "0364-0213, 1551-6709",
  pmid     = "23855554",
  doi      = "10.1111/cogs.12062"
}

@ARTICLE{Chang2016-qi,
  title         = "A Compositional {Object-Based} Approach to Learning Physical
                   Dynamics",
  author        = "Chang, Michael B and Ullman, Tomer and Torralba, Antonio and
                   Tenenbaum, Joshua B",
  abstract      = "We present the Neural Physics Engine (NPE), a framework for
                   learning simulators of intuitive physics that naturally
                   generalize across variable object count and different scene
                   configurations. We propose a factorization of a physical
                   scene into composable object-based representations and a
                   neural network architecture whose compositional structure
                   factorizes object dynamics into pairwise interactions. Like
                   a symbolic physics engine, the NPE is endowed with generic
                   notions of objects and their interactions; realized as a
                   neural network, it can be trained via stochastic gradient
                   descent to adapt to specific object properties and dynamics
                   of different worlds. We evaluate the efficacy of our
                   approach on simple rigid body dynamics in two-dimensional
                   worlds. By comparing to less structured architectures, we
                   show that the NPE's compositional representation of the
                   structure in physical interactions improves its ability to
                   predict movement, generalize across variable object count
                   and different scene configurations, and infer latent
                   properties of objects such as mass.",
  month         =  dec,
  year          =  2016,
  keywords      = "project 2",
  archivePrefix = "arXiv",
  eprint        = "1612.00341",
  primaryClass  = "cs.AI",
  arxivid       = "1612.00341"
}

@ARTICLE{Van_Schijndel2021-qq,
  title    = "{Single-Stage} Prediction Models Do Not Explain the Magnitude of
              Syntactic Disambiguation Difficulty",
  author   = "van Schijndel, Marten and Linzen, Tal",
  abstract = "The disambiguation of a syntactically ambiguous sentence in favor
              of a less preferred parse can lead to slower reading at the
              disambiguation point. This phenomenon, referred to as a
              garden-path effect, has motivated models in which readers
              initially maintain only a subset of the possible parses of the
              sentence, and subsequently require time-consuming reanalysis to
              reconstruct a discarded parse. A more recent proposal argues that
              the garden-path effect can be reduced to surprisal arising in a
              fully parallel parser: words consistent with the initially
              dispreferred but ultimately correct parse are simply less
              predictable than those consistent with the incorrect parse. Since
              predictability has pervasive effects in reading far beyond
              garden-path sentences, this account, which dispenses with
              reanalysis mechanisms, is more parsimonious. Crucially, it
              predicts a linear effect of surprisal: the garden-path effect is
              expected to be proportional to the difference in word surprisal
              between the ultimately correct and ultimately incorrect
              interpretations. To test this prediction, we used recurrent
              neural network language models to estimate word-by-word surprisal
              for three temporarily ambiguous constructions. We then estimated
              the slowdown attributed to each bit of surprisal from human
              self-paced reading times, and used that quantity to predict
              syntactic disambiguation difficulty. Surprisal successfully
              predicted the existence of garden-path effects, but drastically
              underpredicted their magnitude, and failed to predict their
              relative severity across constructions. We conclude that a full
              explanation of syntactic disambiguation difficulty may require
              recovery mechanisms beyond predictability.",
  journal  = "Cogn. Sci.",
  volume   =  45,
  number   =  6,
  pages    = "e12988",
  month    =  jun,
  year     =  2021,
  keywords = "Garden paths; Information theory; Neural networks; Self-paced
              reading; Surprisal;compling-cogsci2023",
  language = "en",
  issn     = "0364-0213, 1551-6709",
  pmid     = "34170031",
  doi      = "10.1111/cogs.12988"
}

@ARTICLE{Arehalli2022-xn,
  title         = "Syntactic Surprisal From Neural Models Predicts, But
                   Underestimates, Human Processing Difficulty From Syntactic
                   Ambiguities",
  author        = "Arehalli, Suhas and Dillon, Brian and Linzen, Tal",
  abstract      = "Humans exhibit garden path effects: When reading sentences
                   that are temporarily structurally ambiguous, they slow down
                   when the structure is disambiguated in favor of the less
                   preferred alternative. Surprisal theory (Hale, 2001; Levy,
                   2008), a prominent explanation of this finding, proposes
                   that these slowdowns are due to the unpredictability of each
                   of the words that occur in these sentences. Challenging this
                   hypothesis, van Schijndel \& Linzen (2021) find that
                   estimates of the cost of word predictability derived from
                   language models severely underestimate the magnitude of
                   human garden path effects. In this work, we consider whether
                   this underestimation is due to the fact that humans weight
                   syntactic factors in their predictions more highly than
                   language models do. We propose a method for estimating
                   syntactic predictability from a language model, allowing us
                   to weigh the cost of lexical and syntactic predictability
                   independently. We find that treating syntactic
                   predictability independently from lexical predictability
                   indeed results in larger estimates of garden path. At the
                   same time, even when syntactic predictability is
                   independently weighted, surprisal still greatly
                   underestimate the magnitude of human garden path effects.
                   Our results support the hypothesis that predictability is
                   not the only factor responsible for the processing cost
                   associated with garden path sentences.",
  month         =  oct,
  year          =  2022,
  keywords      = "compling-cogsci2023",
  archivePrefix = "arXiv",
  eprint        = "2210.12187",
  primaryClass  = "cs.CL",
  arxivid       = "2210.12187"
}

@ARTICLE{Almaatouq2022-xz,
  title    = "Beyond Playing 20 Questions with Nature: Integrative Experiment
              Design in the Social and Behavioral Sciences",
  author   = "Almaatouq, Abdullah and Griffiths, Thomas L and Suchow, Jordan W
              and Whiting, Mark E and Evans, James and Watts, Duncan J",
  abstract = "The dominant paradigm of experiments in the social and behavioral
              sciences views an experiment as a test of a theory, where the
              theory is assumed to generalize beyond the experiment's specific
              conditions. According to this view, which Alan Newell once
              characterized as ``playing twenty questions with nature,'' theory
              is advanced one experiment at a time, and the integration of
              disparate findings is assumed to happen via the scientific
              publishing process. In this article, we argue that the process of
              integration is at best inefficient, and at worst it does not, in
              fact, occur. We further show that the challenge of integration
              cannot be adequately addressed by recently proposed reforms that
              focus on the reliability and replicability of individual
              findings, nor simply by conducting more or larger experiments.
              Rather, the problem arises from the imprecise nature of social
              and behavioral theories and, consequently, a lack of
              commensurability across experiments conducted under different
              conditions. Therefore, researchers must fundamentally rethink how
              they design experiments and how the experiments relate to theory.
              We specifically describe an alternative framework, integrative
              experiment design, which intrinsically promotes commensurability
              and continuous integration of knowledge. In this paradigm,
              researchers explicitly map the design space of possible
              experiments associated with a given research question, embracing
              many potentially relevant theories rather than focusing on just
              one. The researchers then iteratively generate theories and test
              them with experiments explicitly sampled from the design space,
              allowing results to be integrated across experiments. Given
              recent methodological and technological developments, we conclude
              that this approach is feasible and would generate more-reliable,
              more-cumulative empirical and theoretical knowledge than the
              current paradigm-and with far greater efficiency.",
  journal  = "Behav. Brain Sci.",
  pages    = "1--55",
  month    =  dec,
  year     =  2022,
  keywords = "(in)commensurability; cumulative knowledge; experiments;
              generalizability",
  language = "en",
  issn     = "0140-525X, 1469-1825",
  pmid     = "36539303",
  doi      = "10.1017/S0140525X22002874"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@MISC{Eichenbaum2008-pi,
  title        = "Learning \& memory",
  author       = "Eichenbaum, H",
  abstract     = " Next, Eichenbaum incorporates animal and human  Eichenbaum
                  organizes the text around multiple memory systems, moving
                  from simple to more complex forms of learning and memory ",
  publisher    = "aabmc.org",
  year         =  2008,
  howpublished = "\url{https://aabmc.org/sites/default/files/webform/stories-photos/pdf-learning--memory-howard-eichenbaum-pdf-download-free-book-3e8075a.pdf}",
  note         = "Accessed: 2023-1-30",
  keywords     = "learning\&memory2023"
}

@ARTICLE{Ormerod2002-tb,
  title    = "Dynamics and constraints in insight problem solving",
  author   = "Ormerod, Thomas C and MacGregor, James N and Chronicle, Edward P",
  abstract = "This article reports 2 experiments that investigated performance
              on a novel insight problem, the 8-coin problem. The authors
              hypothesized that participants would make certain initial moves
              (strategic moves) that seemed to make progress according to the
              problem instructions but that nonetheless would guarantee failure
              to solve the problem. Experiment 1 manipulated the starting state
              of the problem and showed that overall solution rates were lower
              when such strategic moves were available. Experiment 2 showed
              that failure to capitalize on visual hints about the correct
              first move was also associated with the availability of strategic
              moves. The results are interpreted in terms of an
              information-processing framework previously applied to the 9-dot
              problem. The authors argue that in addition to the operation of
              inappropriate constraints, a full account of insight problem
              solving must incorporate a dynamic that steers solution-seeking
              activity toward the constraints.",
  journal  = "J. Exp. Psychol. Learn. Mem. Cogn.",
  volume   =  28,
  number   =  4,
  pages    = "791--799",
  month    =  jul,
  year     =  2002,
  keywords = "cog-sci;project 1",
  language = "en",
  issn     = "0278-7393",
  pmid     = "12109769",
  doi      = "10.1037//0278-7393.28.4.791"
}

@ARTICLE{Gilhooly2005-zf,
  title     = "Differentiating insight from non-insight problems",
  author    = "Gilhooly, K J and Murphy, P",
  abstract  = "This study aimed to investigate whether a range of tasks that
               have been generally classed as requiring insight form an
               empirically separable group of tasks distinct from tasks
               generally classed as non-insight. In this study, 24 insight
               tasks, 10 non-insight tasks, and tests of individual differences
               in cognitive abilities and working memory were administered to
               60 participants. Cluster analysis of the problem-solving tasks
               indicated that the presumed insight problems did tend to cluster
               with other presumed insight problems, and similarly the presumed
               non-insight problems tended to cluster with other presumed
               non-insight tasks. Performance on presumed insight problems was
               particularly linked to measures of ideational flexibility with a
               different pattern of results for the non-insight tasks. Spatial
               insight problems were linked to spatial flexibility and verbal
               insight tasks were linked to vocabulary scores. The results are
               discussed in relation to recent developments of dual process
               theories of thinking.",
  journal   = "Think. Reason.",
  publisher = "Routledge",
  volume    =  11,
  number    =  3,
  pages     = "279--302",
  month     =  aug,
  year      =  2005,
  keywords  = "cog-sci;project 1",
  issn      = "1354-6783",
  doi       = "10.1080/13546780442000187"
}

@ARTICLE{Schilling2005-bz,
  title     = "A ``{Small-World}'' Network Model of Cognitive Insight",
  author    = "Schilling, Melissa A",
  abstract  = "Despite many decades of study, scientists still puzzle over the
               process of insight. By what mechanism does a person experience
               that ``Aha!'' moment, when sudden clarity emerges from a tangled
               web of thoughts and ideas? This research integrates
               psychological work on insight with graph theoretic work on
               ``small-world'' phenomenon, to construct a theory that explains
               how insight occurs, how it is similar to and different from more
               typical learning processes, and why it yields an affective
               response in the individual. I propose that cognitive insight
               occurs when an atypical association, forged through random
               recombination or directed search, results in a ``shortcut'' in
               an individual's network of representations. This causes a rapid
               decrease in path length, reorients the individual's
               understanding of the relationships within and among the affected
               representations, and can prompt a cascade of other connections.
               This result is demonstrated by applying graph theoretical
               analysis to network translations of commonly used insight
               problems.",
  journal   = "Creat. Res. J.",
  publisher = "Routledge",
  volume    =  17,
  number    = "2-3",
  pages     = "131--154",
  month     =  jul,
  year      =  2005,
  keywords  = "cog-sci;project 1",
  issn      = "1040-0419",
  doi       = "10.1080/10400419.2005.9651475"
}

@ARTICLE{Lakretz2021-go,
  title    = "Mechanisms for handling nested dependencies in neural-network
              language models and humans",
  author   = "Lakretz, Yair and Hupkes, Dieuwke and Vergallito, Alessandra and
              Marelli, Marco and Baroni, Marco and Dehaene, Stanislas",
  abstract = "Recursive processing in sentence comprehension is considered a
              hallmark of human linguistic abilities. However, its underlying
              neural mechanisms remain largely unknown. We studied whether a
              modern artificial neural network trained with ``deep learning''
              methods mimics a central aspect of human sentence processing,
              namely the storing of grammatical number and gender information
              in working memory and its use in long-distance agreement (e.g.,
              capturing the correct number agreement between subject and verb
              when they are separated by other phrases). Although the network,
              a recurrent architecture with Long Short-Term Memory units, was
              solely trained to predict the next word in a large corpus,
              analysis showed the emergence of a very sparse set of specialized
              units that successfully handled local and long-distance syntactic
              agreement for grammatical number. However, the simulations also
              showed that this mechanism does not support full recursion and
              fails with some long-range embedded dependencies. We tested the
              model's predictions in a behavioral experiment where humans
              detected violations in number agreement in sentences with
              systematic variations in the singular/plural status of multiple
              nouns, with or without embedding. Human and model error patterns
              were remarkably similar, showing that the model echoes various
              effects observed in human data. However, a key difference was
              that, with embedded long-range dependencies, humans remained
              above chance level, while the model's systematic errors brought
              it below chance. Overall, our study shows that exploring the ways
              in which modern artificial neural networks process sentences
              leads to precise and testable hypotheses about human linguistic
              performance.",
  journal  = "Cognition",
  volume   =  213,
  pages    = "104699",
  month    =  aug,
  year     =  2021,
  keywords = "Grammatical agreement; Language models; Long-range dependencies;
              Recurrent neural networks; Recursion; Relative clauses; Syntactic
              processing;read;compling-cogsci2023",
  language = "en",
  issn     = "0010-0277, 1873-7838",
  pmid     = "33941375",
  doi      = "10.1016/j.cognition.2021.104699"
}

@ARTICLE{Lampinen2022-oy,
  title         = "Can language models handle recursively nested grammatical
                   structures? A case study on comparing models and humans",
  author        = "Lampinen, Andrew Kyle",
  abstract      = "How should we compare the capabilities of language models
                   and humans? Here, I consider a case study: processing of
                   recursively nested grammatical structures. Prior work has
                   suggested that language models cannot handle these
                   structures as reliably as humans can. However, the humans
                   were provided with instructions and training before being
                   evaluated, while the language models were evaluated
                   zero-shot. I therefore attempt to more closely match the
                   evaluation paradigms by providing language models with
                   few-shot prompts. A simple prompt, which contains
                   substantially less content than the human training, allows
                   large language models to consistently outperform the human
                   results. The same prompt even allows extrapolation to more
                   deeply nested conditions than have been tested in humans.
                   Further, a reanalysis of the prior human experiments
                   suggests that the humans may not perform above chance at the
                   difficult structures initially. These results suggest that
                   large language models can in fact process recursively nested
                   grammatical structures comparably to humans. This case study
                   highlights how discrepancies in the quantity of
                   experiment-specific context can confound comparisons of
                   language models and humans. I use this case study to reflect
                   on the broader challenge of comparing human and model
                   capabilities, and to suggest that there is an important
                   difference between evaluating cognitive models of a specific
                   phenomenon and evaluating broadly-trained models.",
  month         =  oct,
  year          =  2022,
  keywords      = "read;compling-cogsci2023",
  archivePrefix = "arXiv",
  eprint        = "2210.15303",
  primaryClass  = "cs.CL",
  arxivid       = "2210.15303"
}

@ARTICLE{Josselyn2020-xn,
  title    = "Memory engrams: Recalling the past and imagining the future",
  author   = "Josselyn, Sheena A and Tonegawa, Susumu",
  abstract = "In 1904, Richard Semon introduced the term ``engram'' to describe
              the neural substrate for storing memories. An experience, Semon
              proposed, activates a subset of cells that undergo off-line,
              persistent chemical and/or physical changes to become an engram.
              Subsequent reactivation of this engram induces memory retrieval.
              Although Semon's contributions were largely ignored in his
              lifetime, new technologies that allow researchers to image and
              manipulate the brain at the level of individual neurons has
              reinvigorated engram research. We review recent progress in
              studying engrams, including an evaluation of evidence for the
              existence of engrams, the importance of intrinsic excitability
              and synaptic plasticity in engrams, and the lifetime of an
              engram. Together, these findings are beginning to define an
              engram as the basic unit of memory.",
  journal  = "Science",
  volume   =  367,
  number   =  6473,
  month    =  jan,
  year     =  2020,
  keywords = "read;cog-neuro;learning\&memory2023",
  language = "en",
  issn     = "0036-8075, 1095-9203",
  pmid     = "31896692",
  doi      = "10.1126/science.aaw4325",
  pmc      = "PMC7577560"
}

@ARTICLE{Scoville1957-dh,
  title    = "Loss of recent memory after bilateral hippocampal lesions",
  author   = "Scoville, W B and Milner, B",
  journal  = "J. Neurol. Neurosurg. Psychiatry",
  volume   =  20,
  number   =  1,
  pages    = "11--21",
  month    =  feb,
  year     =  1957,
  keywords = "MEMORY; TEMPORAL LOBE/surgery;read;learning\&memory2023;cog-neuro",
  language = "en",
  issn     = "0022-3050",
  pmid     = "13406589",
  doi      = "10.1136/jnnp.20.1.11",
  pmc      = "PMC497229"
}

@ARTICLE{Whittington2021-sj,
  title         = "Relating transformers to models and neural representations
                   of the hippocampal formation",
  author        = "Whittington, James C R and Warren, Joseph and Behrens,
                   Timothy E J",
  abstract      = "Many deep neural network architectures loosely based on
                   brain networks have recently been shown to replicate neural
                   firing patterns observed in the brain. One of the most
                   exciting and promising novel architectures, the Transformer
                   neural network, was developed without the brain in mind. In
                   this work, we show that transformers, when equipped with
                   recurrent position encodings, replicate the precisely tuned
                   spatial representations of the hippocampal formation; most
                   notably place and grid cells. Furthermore, we show that this
                   result is no surprise since it is closely related to current
                   hippocampal models from neuroscience. We additionally show
                   the transformer version offers dramatic performance gains
                   over the neuroscience version. This work continues to bind
                   computations of artificial and brain networks, offers a
                   novel understanding of the hippocampal-cortical interaction,
                   and suggests how wider cortical areas may perform complex
                   tasks beyond current neuroscience models such as language
                   comprehension.",
  month         =  dec,
  year          =  2021,
  archivePrefix = "arXiv",
  eprint        = "2112.04035",
  primaryClass  = "cs.NE",
  arxivid       = "2112.04035"
}

@MISC{Lampinen_undated-zq,
  title    = "Tell me why! Explanations support learning relational and causal
              structure",
  author   = "Lampinen, Andrew K and Roy, Nicholas A and Dasgupta, Ishita and
              Chan, Stephanie C Y and Tam, Allison C and Mc Clelland, James L
              and Yan, Chen and Santoro, Adam and Rabinowitz, Neil C and Wang,
              Jane X and Hill, Felix",
  keywords = "ARC Project;comp-cog-sci"
}

@ARTICLE{Goldstone1998-ne,
  title    = "Perceptual learning",
  author   = "Goldstone, R L",
  abstract = "Perceptual learning involves relatively long-lasting changes to
              an organism's perceptual system that improve its ability to
              respond to its environment. Four mechanisms of perceptual
              learning are discussed: attention weighting, imprinting,
              differentiation, and unitization. By attention weighting,
              perception becomes adapted to tasks and environments by
              increasing the attention paid to important dimensions and
              features. By imprinting, receptors are developed that are
              specialized for stimuli or parts of stimuli. By differentiation,
              stimuli that were once indistinguishable become psychologically
              separated. By unitization, tasks that originally required
              detection of several parts are accomplished by detecting a single
              constructed unit representing a complex configuration. Research
              from cognitive psychology, psychophysics, neuroscience,
              expert/novice differences, development, computer science, and
              cross-cultural differences is described that relates to these
              mechanisms. The locus, limits, and applications of perceptual
              learning are also discussed.",
  journal  = "Annu. Rev. Psychol.",
  volume   =  49,
  pages    = "585--612",
  year     =  1998,
  keywords = "read;learning\&memory2023",
  language = "en",
  issn     = "0066-4308",
  pmid     = "9496632",
  doi      = "10.1146/annurev.psych.49.1.585"
}

@ARTICLE{Barlow1989-pm,
  title     = "Unsupervised learning",
  author    = "Barlow, H B",
  abstract  = "What use can the brain make of the massive flow of sensory
               information that occurs without any associated rewards or
               punishments? This question is reviewed in the light of
               connectionist models of unsupervised learning and some older
               ideas, namely the cognitive maps and working models of Tolman
               and Craik, and the idea that redundancy is important for
               understanding perception (Attneave 1954), the physiology of
               sensory pathways (Barlow 1959), and pattern recognition
               (Watanabe 1960). It is argued that (1) The redundancy of sensory
               messages provides the knowledge incorporated in the maps or
               models. (2) Some of this knowledge can be obtained by
               observations of mean, variance, and covariance of sensory
               messages, and perhaps also by a method called ``minimum entropy
               coding.'' (3) Such knowledge may be incorporated in a model of
               ``what usually happens'' with which incoming messages are
               automatically compared, enabling unexpected discrepancies to be
               immediately identified. (4) Knowledge of the sort incorporated
               into such a filter is a necessary prerequisite of ordinary
               learning, and a representation whose elements are independent
               makes it possible to form associations with logical functions of
               the elements, not just with the elements themselves.",
  journal   = "Neural Comput.",
  publisher = "MIT Press - Journals",
  volume    =  1,
  number    =  3,
  pages     = "295--311",
  month     =  sep,
  year      =  1989,
  keywords  = "read;learning\&memory2023",
  language  = "en",
  issn      = "0899-7667, 1530-888X",
  doi       = "10.1162/neco.1989.1.3.295"
}

@ARTICLE{Aslin2012-rt,
  title    = "Statistical learning: From acquiring specific items to forming
              general rules",
  author   = "Aslin, Richard N and Newport, Elissa L",
  abstract = "Statistical learning is a rapid and robust mechanism that enables
              adults and infants to extract patterns of stimulation embedded in
              both language and visual domains. Importantly, statistical
              learning operates implicitly, without instruction, through mere
              exposure to a set of input stimuli. However, much of what
              learners must acquire about a structured domain consists of
              principles or rules that can be applied to novel inputs. Although
              it has been claimed that statistical learning and rule learning
              are separate mechanisms, here we review evidence and provide a
              unifying perspective that argues for a single mechanism of
              statistical learning that accounts for both the learning of the
              input stimuli and the generalization to novel instances. The
              balance between instance-learning and generalization is based on
              two factors: the strength of perceptual biases that highlight
              structural regularities, and the consistency of unique versus
              overlapping contexts in the input.",
  journal  = "Curr. Dir. Psychol. Sci.",
  volume   =  21,
  number   =  3,
  pages    = "170--176",
  month    =  jun,
  year     =  2012,
  keywords = "generalization; infants; rule learning; statistical
              learning;read;learning\&memory2023",
  language = "en",
  issn     = "0963-7214",
  pmid     = "24000273",
  doi      = "10.1177/0963721412436806",
  pmc      = "PMC3758750"
}

@ARTICLE{Krathwohl2002-bb,
  title     = "A revision of bloom's taxonomy: An overview",
  author    = "Krathwohl, David R",
  abstract  = "From One Dimension to Two Dimensions Objectives that describe
               intended learning outcomes as the result of instruction are
               usually framed in terms of (a) some subject matter content and
               (b) a description of what is to be done with or to that content.
               [...]statements of objectives typically consist of a noun or
               noun phrase-the subject matter content-and a verb or verb
               phrase-the cognitive process(es). [...]any objective could be
               classified in the Taxonomy Table in one or more cells that
               correspond with the intersection of the columns) appropriate for
               categorizing the verbs) and the rows) appropriate for
               categorizing the nouns) or noun phrase(s). Analyze, of course,
               would be 4. Since both categories of cognitive processes are
               likely to be involved (with students being expected to analyze
               before they create), we would place this objective in two cells
               of the Taxonomy Table: B4, Analyze Conceptual Knowledge, and B6,
               Create [based on] Conceptual Knowledge (see Figure 1). In
               addition to showing what was included, the Taxonomy Table also
               suggests what might have been but wasn't. [...]in Figure 2, the
               two blank bottom rows raise questions about whether there might
               have been procedural or metacognitive knowledge objectives that
               could have been included.",
  journal   = "Theory Pract.",
  publisher = "Informa UK Limited",
  volume    =  41,
  number    =  4,
  pages     = "212--218",
  month     =  nov,
  year      =  2002,
  address   = "New York, United States, Columbus",
  keywords  = "project 2",
  language  = "en",
  issn      = "0040-5841, 1543-0421",
  doi       = "10.1207/s15430421tip4104\_2"
}

@ARTICLE{Ho2022-iy,
  title    = "People construct simplified mental representations to plan",
  author   = "Ho, Mark K and Abel, David and Correa, Carlos G and Littman,
              Michael L and Cohen, Jonathan D and Griffiths, Thomas L",
  abstract = "One of the most striking features of human cognition is the
              ability to plan. Two aspects of human planning stand out-its
              efficiency and flexibility. Efficiency is especially impressive
              because plans must often be made in complex environments, and yet
              people successfully plan solutions to many everyday problems
              despite having limited cognitive resources1-3. Standard accounts
              in psychology, economics and artificial intelligence have
              suggested that human planning succeeds because people have a
              complete representation of a task and then use heuristics to plan
              future actions in that representation4-11. However, this approach
              generally assumes that task representations are fixed. Here we
              propose that task representations can be controlled and that such
              control provides opportunities to quickly simplify problems and
              more easily reason about them. We propose a computational account
              of this simplification process and, in a series of preregistered
              behavioural experiments, show that it is subject to online
              cognitive control12-14 and that people optimally balance the
              complexity of a task representation and its utility for planning
              and acting. These results demonstrate how strategically
              perceiving and conceiving problems facilitates the effective use
              of limited cognitive resources.",
  journal  = "Nature",
  volume   =  606,
  number   =  7912,
  pages    = "129--136",
  month    =  jun,
  year     =  2022,
  keywords = "read;project 1;comp-cog-sci;project 2",
  language = "en",
  issn     = "0028-0836, 1476-4687",
  pmid     = "35589843",
  doi      = "10.1038/s41586-022-04743-9",
  pmc      = "5111694"
}

@ARTICLE{Carta2023-ng,
  title         = "Grounding Large Language Models in Interactive Environments
                   with Online Reinforcement Learning",
  author        = "Carta, Thomas and Romac, Cl{\'e}ment and Wolf, Thomas and
                   Lamprier, Sylvain and Sigaud, Olivier and Oudeyer,
                   Pierre-Yves",
  abstract      = "Recent works successfully leveraged Large Language Models'
                   (LLM) abilities to capture abstract knowledge about world's
                   physics to solve decision-making problems. Yet, the
                   alignment between LLMs' knowledge and the environment can be
                   wrong and limit functional competence due to lack of
                   grounding. In this paper, we study an approach to achieve
                   this alignment through functional grounding: we consider an
                   agent using an LLM as a policy that is progressively updated
                   as the agent interacts with the environment, leveraging
                   online Reinforcement Learning to improve its performance to
                   solve goals. Using an interactive textual environment
                   designed to study higher-level forms of functional
                   grounding, and a set of spatial and navigation tasks, we
                   study several scientific questions: 1) Can LLMs boost sample
                   efficiency for online learning of various RL tasks? 2) How
                   can it boost different forms of generalization? 3) What is
                   the impact of online learning? We study these questions by
                   functionally grounding several variants (size, architecture)
                   of FLAN-T5.",
  month         =  feb,
  year          =  2023,
  keywords      = "ARC Project;comp-cog-sci",
  archivePrefix = "arXiv",
  eprint        = "2302.02662",
  primaryClass  = "cs.LG",
  arxivid       = "2302.02662"
}

@ARTICLE{Koh2023-oc,
  title         = "Grounding Language Models to Images for Multimodal
                   Generation",
  author        = "Koh, Jing Yu and Salakhutdinov, Ruslan and Fried, Daniel",
  abstract      = "We propose an efficient method to ground pretrained
                   text-only language models to the visual domain, enabling
                   them to process and generate arbitrarily interleaved
                   image-and-text data. Our method leverages the abilities of
                   language models learnt from large scale text-only
                   pretraining, such as in-context learning and free-form text
                   generation. We keep the language model frozen, and finetune
                   input and output linear layers to enable cross-modality
                   interactions. This allows our model to process arbitrarily
                   interleaved image-and-text inputs, and generate free-form
                   text interleaved with retrieved images. We achieve strong
                   zero-shot performance on grounded tasks such as contextual
                   image retrieval and multimodal dialogue, and showcase
                   compelling interactive abilities. Our approach works with
                   any off-the-shelf language model and paves the way towards
                   an effective, general solution for leveraging pretrained
                   language models in visually grounded settings.",
  month         =  jan,
  year          =  2023,
  keywords      = "compling-cogsci2023",
  archivePrefix = "arXiv",
  eprint        = "2301.13823",
  primaryClass  = "cs.CL",
  arxivid       = "2301.13823"
}

@ARTICLE{Firestone2020-rp,
  title    = "Performance vs. competence in human-machine comparisons",
  author   = "Firestone, Chaz",
  abstract = "Does the human mind resemble the machines that can behave like
              it? Biologically inspired machine-learning systems approach
              ``human-level'' accuracy in an astounding variety of domains, and
              even predict human brain activity-raising the exciting
              possibility that such systems represent the world like we do.
              However, even seemingly intelligent machines fail in strange and
              ``unhumanlike'' ways, threatening their status as models of our
              minds. How can we know when human-machine behavioral differences
              reflect deep disparities in their underlying capacities, vs. when
              such failures are only superficial or peripheral? This article
              draws on a foundational insight from cognitive science-the
              distinction between performance and competence-to encourage
              ``species-fair'' comparisons between humans and machines. The
              performance/competence distinction urges us to consider whether
              the failure of a system to behave as ideally hypothesized, or the
              failure of one creature to behave like another, arises not
              because the system lacks the relevant knowledge or internal
              capacities (``competence''), but instead because of superficial
              constraints on demonstrating that knowledge (``performance''). I
              argue that this distinction has been neglected by research
              comparing human and machine behavior, and that it should be
              essential to any such comparison. Focusing on the domain of image
              classification, I identify three factors contributing to the
              species-fairness of human-machine comparisons, extracted from
              recent work that equates such constraints. Species-fair
              comparisons level the playing field between natural and
              artificial intelligence, so that we can separate more superficial
              differences from those that may be deep and enduring.",
  journal  = "Proc. Natl. Acad. Sci. U. S. A.",
  volume   =  117,
  number   =  43,
  pages    = "26562--26571",
  month    =  oct,
  year     =  2020,
  keywords = "artificial intelligence; cognition; deep learning; development;
              perception;read;compling-cogsci2023",
  language = "en",
  issn     = "0027-8424, 1091-6490",
  pmid     = "33051296",
  doi      = "10.1073/pnas.1905334117",
  pmc      = "PMC7604508"
}

@UNPUBLISHED{Radford2021-jz,
  title    = "Learning {{Transferable Visual Models From Natural Language
              Supervision}}",
  author   = "Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh,
              Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish
              and Askell, Amanda and Mishkin, Pamela and Clark, Jack and
              Krueger, Gretchen and Sutskever, Ilya",
  abstract = "State-of-the-art computer vision systems are trained to predict a
              fixed set of predetermined object categories. This restricted
              form of supervision limits their generality and usability since
              additional labeled data is needed to specify any other visual
              concept. Learning directly from raw text about images is a
              promising alternative which leverages a much broader source of
              supervision. We demonstrate that the simple pre-training task of
              predicting which caption goes with which image is an efficient
              and scalable way to learn SOTA image representations from scratch
              on a dataset of 400 million (image, text) pairs collected from
              the internet. After pre-training, natural language is used to
              reference learned visual concepts (or describe new ones) enabling
              zero-shot transfer of the model to downstream tasks. We study the
              performance of this approach by benchmarking on over 30 different
              existing computer vision datasets, spanning tasks such as OCR,
              action recognition in videos, geo-localization, and many types of
              fine-grained object classification. The model transfers
              non-trivially to most tasks and is often competitive with a fully
              supervised baseline without the need for any dataset specific
              training. For instance, we match the accuracy of the original
              ResNet-50 on ImageNet zero-shot without needing to use any of the
              1.28 million training examples it was trained on. We release our
              code and pre-trained model weights at
              https://github.com/OpenAI/CLIP.",
  month    =  feb,
  year     =  2021,
  keywords = "Computer Science - Computer Vision and Pattern
              Recognition,Computer Science - Machine
              Learning;skimmed;machine-learning;compling-cogsci2023"
}

@ARTICLE{Lu2021-on,
  title         = "Pretrained Transformers as Universal Computation Engines",
  author        = "Lu, Kevin and Grover, Aditya and Abbeel, Pieter and
                   Mordatch, Igor",
  abstract      = "We investigate the capability of a transformer pretrained on
                   natural language to generalize to other modalities with
                   minimal finetuning -- in particular, without finetuning of
                   the self-attention and feedforward layers of the residual
                   blocks. We consider such a model, which we call a Frozen
                   Pretrained Transformer (FPT), and study finetuning it on a
                   variety of sequence classification tasks spanning numerical
                   computation, vision, and protein fold prediction. In
                   contrast to prior works which investigate finetuning on the
                   same modality as the pretraining dataset, we show that
                   pretraining on natural language can improve performance and
                   compute efficiency on non-language downstream tasks.
                   Additionally, we perform an analysis of the architecture,
                   comparing the performance of a random initialized
                   transformer to a random LSTM. Combining the two insights, we
                   find language-pretrained transformers can obtain strong
                   performance on a variety of non-language tasks.",
  month         =  mar,
  year          =  2021,
  keywords      = "ARC Project;comp-cog-sci;machine-learning",
  archivePrefix = "arXiv",
  eprint        = "2103.05247",
  primaryClass  = "cs.LG",
  arxivid       = "2103.05247"
}

@ARTICLE{Adaptive_Agent_Team2023-vt,
  title         = "{Human-Timescale} Adaptation in an {Open-Ended} Task Space",
  author        = "{Adaptive Agent Team} and Bauer, Jakob and Baumli, Kate and
                   Baveja, Satinder and Behbahani, Feryal and Bhoopchand,
                   Avishkar and Bradley-Schmieg, Nathalie and Chang, Michael
                   and Clay, Natalie and Collister, Adrian and Dasagi,
                   Vibhavari and Gonzalez, Lucy and Gregor, Karol and Hughes,
                   Edward and Kashem, Sheleem and Loks-Thompson, Maria and
                   Openshaw, Hannah and Parker-Holder, Jack and Pathak, Shreya
                   and Perez-Nieves, Nicolas and Rakicevic, Nemanja and
                   Rockt{\"a}schel, Tim and Schroecker, Yannick and Sygnowski,
                   Jakub and Tuyls, Karl and York, Sarah and Zacherl, Alexander
                   and Zhang, Lei",
  abstract      = "Foundation models have shown impressive adaptation and
                   scalability in supervised and self-supervised learning
                   problems, but so far these successes have not fully
                   translated to reinforcement learning (RL). In this work, we
                   demonstrate that training an RL agent at scale leads to a
                   general in-context learning algorithm that can adapt to
                   open-ended novel embodied 3D problems as quickly as humans.
                   In a vast space of held-out environment dynamics, our
                   adaptive agent (AdA) displays on-the-fly hypothesis-driven
                   exploration, efficient exploitation of acquired knowledge,
                   and can successfully be prompted with first-person
                   demonstrations. Adaptation emerges from three ingredients:
                   (1) meta-reinforcement learning across a vast, smooth and
                   diverse task distribution, (2) a policy parameterised as a
                   large-scale attention-based memory architecture, and (3) an
                   effective automated curriculum that prioritises tasks at the
                   frontier of an agent's capabilities. We demonstrate
                   characteristic scaling laws with respect to network size,
                   memory length, and richness of the training task
                   distribution. We believe our results lay the foundation for
                   increasingly general and adaptive RL agents that perform
                   well across ever-larger open-ended domains.",
  month         =  jan,
  year          =  2023,
  keywords      = "comp-cog-sci",
  archivePrefix = "arXiv",
  eprint        = "2301.07608",
  primaryClass  = "cs.LG",
  arxivid       = "2301.07608"
}

@MISC{noauthor_undated-vu,
  title        = "3-second-naive-physics-manifesto.pdf",
  howpublished = "\url{http://www.cs.unibo.it/~nuzzoles/courses/intelligenza-artificiale/exam/3-second-naive-physics-manifesto.pdf}",
  keywords     = "skimmed;comp-cog-sci;project 2"
}

@ARTICLE{Hinton2002-on,
  title    = "Training products of experts by minimizing contrastive divergence",
  author   = "Hinton, Geoffrey E",
  abstract = "It is possible to combine multiple latent-variable models of the
              same data by multiplying their probability distributions together
              and then renormalizing. This way of combining individual
              ``expert'' models makes it hard to generate samples from the
              combined model but easy to infer the values of the latent
              variables of each expert, because the combination rule ensures
              that the latent variables of different experts are conditionally
              independent when given the data. A product of experts (PoE) is
              therefore an interesting candidate for a perceptual system in
              which rapid inference is vital and generation is unnecessary.
              Training a PoE by maximizing the likelihood of the data is
              difficult because it is hard even to approximate the derivatives
              of the renormalization term in the combination rule. Fortunately,
              a PoE can be trained using a different objective function called
              ``contrastive divergence'' whose derivatives with regard to the
              parameters can be approximated accurately and efficiently.
              Examples are presented of contrastive divergence learning using
              several types of expert on several types of data.",
  journal  = "Neural Comput.",
  volume   =  14,
  number   =  8,
  pages    = "1771--1800",
  month    =  aug,
  year     =  2002,
  language = "en",
  issn     = "0899-7667",
  pmid     = "12180402",
  doi      = "10.1162/089976602760128018"
}

@ARTICLE{Yao2022-vk,
  title         = "{ReAct}: Synergizing Reasoning and Acting in Language Models",
  author        = "Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and
                   Shafran, Izhak and Narasimhan, Karthik and Cao, Yuan",
  abstract      = "While large language models (LLMs) have demonstrated
                   impressive capabilities across tasks in language
                   understanding and interactive decision making, their
                   abilities for reasoning (e.g. chain-of-thought prompting)
                   and acting (e.g. action plan generation) have primarily been
                   studied as separate topics. In this paper, we explore the
                   use of LLMs to generate both reasoning traces and
                   task-specific actions in an interleaved manner, allowing for
                   greater synergy between the two: reasoning traces help the
                   model induce, track, and update action plans as well as
                   handle exceptions, while actions allow it to interface with
                   external sources, such as knowledge bases or environments,
                   to gather additional information. We apply our approach,
                   named ReAct, to a diverse set of language and decision
                   making tasks and demonstrate its effectiveness over
                   state-of-the-art baselines, as well as improved human
                   interpretability and trustworthiness over methods without
                   reasoning or acting components. Concretely, on question
                   answering (HotpotQA) and fact verification (Fever), ReAct
                   overcomes issues of hallucination and error propagation
                   prevalent in chain-of-thought reasoning by interacting with
                   a simple Wikipedia API, and generates human-like
                   task-solving trajectories that are more interpretable than
                   baselines without reasoning traces. On two interactive
                   decision making benchmarks (ALFWorld and WebShop), ReAct
                   outperforms imitation and reinforcement learning methods by
                   an absolute success rate of 34\% and 10\% respectively,
                   while being prompted with only one or two in-context
                   examples. Project site with code: https://react-lm.github.io",
  month         =  oct,
  year          =  2022,
  keywords      = "read;ARC Project;comp-cog-sci",
  archivePrefix = "arXiv",
  eprint        = "2210.03629",
  primaryClass  = "cs.CL",
  arxivid       = "2210.03629"
}

@ARTICLE{Zelikman2022-xw,
  title         = "{STaR}: Bootstrapping Reasoning With Reasoning",
  author        = "Zelikman, Eric and Wu, Yuhuai and Mu, Jesse and Goodman,
                   Noah D",
  abstract      = "Generating step-by-step ``chain-of-thought'' rationales
                   improves language model performance on complex reasoning
                   tasks like mathematics or commonsense question-answering.
                   However, inducing language model rationale generation
                   currently requires either constructing massive rationale
                   datasets or sacrificing accuracy by using only few-shot
                   inference. We propose a technique to iteratively leverage a
                   small number of rationale examples and a large dataset
                   without rationales, to bootstrap the ability to perform
                   successively more complex reasoning. This technique, the
                   ``Self-Taught Reasoner'' (STaR), relies on a simple loop:
                   generate rationales to answer many questions, prompted with
                   a few rationale examples; if the generated answers are
                   wrong, try again to generate a rationale given the correct
                   answer; fine-tune on all the rationales that ultimately
                   yielded correct answers; repeat. We show that STaR
                   significantly improves performance on multiple datasets
                   compared to a model fine-tuned to directly predict final
                   answers, and performs comparably to fine-tuning a 30$\times$
                   larger state-of-the-art language model on CommensenseQA.
                   Thus, STaR lets a model improve itself by learning from its
                   own generated reasoning.",
  month         =  mar,
  year          =  2022,
  archivePrefix = "arXiv",
  eprint        = "2203.14465",
  primaryClass  = "cs.LG",
  arxivid       = "2203.14465"
}

@ARTICLE{Shridhar2020-qs,
  title         = "{ALFWorld}: Aligning Text and Embodied Environments for
                   Interactive Learning",
  author        = "Shridhar, Mohit and Yuan, Xingdi and C{\^o}t{\'e},
                   Marc-Alexandre and Bisk, Yonatan and Trischler, Adam and
                   Hausknecht, Matthew",
  abstract      = "Given a simple request like Put a washed apple in the
                   kitchen fridge, humans can reason in purely abstract terms
                   by imagining action sequences and scoring their likelihood
                   of success, prototypicality, and efficiency, all without
                   moving a muscle. Once we see the kitchen in question, we can
                   update our abstract plans to fit the scene. Embodied agents
                   require the same abilities, but existing work does not yet
                   provide the infrastructure necessary for both reasoning
                   abstractly and executing concretely. We address this
                   limitation by introducing ALFWorld, a simulator that enables
                   agents to learn abstract, text based policies in TextWorld
                   (C\textbackslash^ot\textbackslash'e et al., 2018) and then
                   execute goals from the ALFRED benchmark (Shridhar et al.,
                   2020) in a rich visual environment. ALFWorld enables the
                   creation of a new BUTLER agent whose abstract knowledge,
                   learned in TextWorld, corresponds directly to concrete,
                   visually grounded actions. In turn, as we demonstrate
                   empirically, this fosters better agent generalization than
                   training only in the visually grounded environment. BUTLER's
                   simple, modular design factors the problem to allow
                   researchers to focus on models for improving every piece of
                   the pipeline (language understanding, planning, navigation,
                   and visual scene understanding).",
  month         =  oct,
  year          =  2020,
  keywords      = "ARC Project",
  archivePrefix = "arXiv",
  eprint        = "2010.03768",
  primaryClass  = "cs.CL",
  arxivid       = "2010.03768"
}

@ARTICLE{Mialon2023-jz,
  title         = "Augmented Language Models: a Survey",
  author        = "Mialon, Gr{\'e}goire and Dess{\`\i}, Roberto and Lomeli,
                   Maria and Nalmpantis, Christoforos and Pasunuru, Ram and
                   Raileanu, Roberta and Rozi{\`e}re, Baptiste and Schick, Timo
                   and Dwivedi-Yu, Jane and Celikyilmaz, Asli and Grave,
                   Edouard and LeCun, Yann and Scialom, Thomas",
  abstract      = "This survey reviews works in which language models (LMs) are
                   augmented with reasoning skills and the ability to use
                   tools. The former is defined as decomposing a potentially
                   complex task into simpler subtasks while the latter consists
                   in calling external modules such as a code interpreter. LMs
                   can leverage these augmentations separately or in
                   combination via heuristics, or learn to do so from
                   demonstrations. While adhering to a standard missing tokens
                   prediction objective, such augmented LMs can use various,
                   possibly non-parametric external modules to expand their
                   context processing ability, thus departing from the pure
                   language modeling paradigm. We therefore refer to them as
                   Augmented Language Models (ALMs). The missing token
                   objective allows ALMs to learn to reason, use tools, and
                   even act, while still performing standard natural language
                   tasks and even outperforming most regular LMs on several
                   benchmarks. In this work, after reviewing current advance in
                   ALMs, we conclude that this new research direction has the
                   potential to address common limitations of traditional LMs
                   such as interpretability, consistency, and scalability
                   issues.",
  month         =  feb,
  year          =  2023,
  keywords      = "ARC Project",
  archivePrefix = "arXiv",
  eprint        = "2302.07842",
  primaryClass  = "cs.CL",
  arxivid       = "2302.07842"
}

@ARTICLE{Wei2022-mg,
  title         = "{Chain-of-Thought} Prompting Elicits Reasoning in Large
                   Language Models",
  author        = "Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma,
                   Maarten and Ichter, Brian and Xia, Fei and Chi, Ed and Le,
                   Quoc and Zhou, Denny",
  abstract      = "We explore how generating a chain of thought -- a series of
                   intermediate reasoning steps -- significantly improves the
                   ability of large language models to perform complex
                   reasoning. In particular, we show how such reasoning
                   abilities emerge naturally in sufficiently large language
                   models via a simple method called chain of thought
                   prompting, where a few chain of thought demonstrations are
                   provided as exemplars in prompting. Experiments on three
                   large language models show that chain of thought prompting
                   improves performance on a range of arithmetic, commonsense,
                   and symbolic reasoning tasks. The empirical gains can be
                   striking. For instance, prompting a 540B-parameter language
                   model with just eight chain of thought exemplars achieves
                   state of the art accuracy on the GSM8K benchmark of math
                   word problems, surpassing even finetuned GPT-3 with a
                   verifier.",
  month         =  jan,
  year          =  2022,
  keywords      = "ARC Project",
  archivePrefix = "arXiv",
  eprint        = "2201.11903",
  primaryClass  = "cs.CL",
  arxivid       = "2201.11903"
}

@ARTICLE{Nye2021-dw,
  title         = "Show Your Work: Scratchpads for Intermediate Computation
                   with Language Models",
  author        = "Nye, Maxwell and Andreassen, Anders Johan and Gur-Ari, Guy
                   and Michalewski, Henryk and Austin, Jacob and Bieber, David
                   and Dohan, David and Lewkowycz, Aitor and Bosma, Maarten and
                   Luan, David and Sutton, Charles and Odena, Augustus",
  abstract      = "Large pre-trained language models perform remarkably well on
                   tasks that can be done ``in one pass'', such as generating
                   realistic text or synthesizing computer programs. However,
                   they struggle with tasks that require unbounded multi-step
                   computation, such as adding integers or executing programs.
                   Surprisingly, we find that these same models are able to
                   perform complex multi-step computations -- even in the
                   few-shot regime -- when asked to perform the operation
                   ``step by step'', showing the results of intermediate
                   computations. In particular, we train transformers to
                   perform multi-step computations by asking them to emit
                   intermediate computation steps into a ``scratchpad''. On a
                   series of increasingly complex tasks ranging from long
                   addition to the execution of arbitrary programs, we show
                   that scratchpads dramatically improve the ability of
                   language models to perform multi-step computations.",
  month         =  nov,
  year          =  2021,
  keywords      = "ARC Project;comp-cog-sci",
  archivePrefix = "arXiv",
  eprint        = "2112.00114",
  primaryClass  = "cs.LG",
  arxivid       = "2112.00114"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Rescorla1972-fu,
  title     = "A theory of Pavlovian conditioning: Variations in the
               effectiveness of reinforcement and non-reinforcement",
  author    = "Rescorla, Robert A",
  abstract  = "A theory of Pavlovian conditioning : Variations in the
               effectiveness of reinforcement and non - reinforcement | CiNii
               Research  A theory of Pavlovian conditioning : Variations in
               the effectiveness of reinforcement and non - reinforcement 
               Classical conditioning , Current research and theory 2 64-69,
               1972 ",
  journal   = "Classical conditioning, Current research and theory",
  publisher = "Appleton-Century-Crofts",
  volume    =  2,
  pages     = "64--69",
  year      =  1972,
  keywords  = "skimmed;learning\&memory2023"
}

@INCOLLECTION{Gureckis2015-eh,
  title     = "Reinforcement learning: A computational perspective",
  booktitle = "Oxford handbook of computational and mathematical psychology",
  author    = "Gureckis, Todd and Love, B C",
  publisher = "Oxford University Press",
  year      =  2015,
  keywords  = "read;RL;ccm2023"
}

@ARTICLE{Rescorla1988-hl,
  title    = "Pavlovian conditioning: It's not what you think it is",
  author   = "Rescorla, Robert A",
  abstract = "Current thinking about Pavlovian conditioning differs
              substantially from that of 20 years ago. Yet the changes that
              have taken place remain poorly appreciated by psychologists
              generally. Traditional descriptions of conditioning as the
              acquired ability of one stimulus to evoke the original response
              to another because of their pairing are shown to be inadequate.
              They fail to characterize adequately the circumstances producing
              learning, the content of that learning, or the manner in which
              that learning influences performance. Instead, conditioning is
              now described as the learning of relations among events so as to
              allow the organism to represent its environment. Within this
              framework, the study of Pavlovian conditioning continues to be an
              intellectually active area, full of new discoveries and
              information relevant to other areas of psychology. (PsycINFO
              Database Record (c) 2016 APA, all rights reserved)",
  journal  = "Am. Psychol.",
  volume   =  43,
  number   =  3,
  pages    = "151--160",
  month    =  mar,
  year     =  1988,
  keywords = "skimmed;learning\&memory2023",
  issn     = "0003-066X",
  doi      = "10.1037/0003-066X.43.3.151"
}

@ARTICLE{Wang2010-xb,
  title    = "On the cognitive process of human problem solving",
  author   = "Wang, Yingxu and Chiew, Vincent",
  abstract = "One of the fundamental human cognitive processes is problem
              solving. As a higher-layer cognitive process, problem solving
              interacts with many other cognitive processes such as
              abstraction, searching, learning, decision making, inference,
              analysis, and synthesis on the basis of internal knowledge
              representation by the object--attribute-relation (OAR) model.
              Problem solving is a cognitive process of the brain that searches
              a solution for a given problem or finds a path to reach a given
              goal. When a problem object is identified, problem solving can be
              perceived as a search process in the memory space for finding a
              relationship between a set of solution goals and a set of
              alternative paths. This paper presents both a cognitive model and
              a mathematical model of the problem solving process. The
              cognitive structures of the brain and the mechanisms of internal
              knowledge representation behind the cognitive process of problem
              solving are explained. The cognitive process is formally
              described using real-time process algebra (RTPA) and concept
              algebra. This work is a part of the cognitive computing project
              that designed to reveal and simulate the fundamental mechanisms
              and processes of the brain according to Wang's layered reference
              model of the brain (LRMB), which is expected to lead to the
              development of future generation methodologies for cognitive
              computing and novel cognitive computers that are capable of
              think, learn, and perceive.",
  journal  = "Cogn. Syst. Res.",
  volume   =  11,
  number   =  1,
  pages    = "81--92",
  month    =  mar,
  year     =  2010,
  keywords = "Cognitive informatics; Cognitive computing; Brain informatics;
              Computational intelligence; Reference model of the brain;
              Cognitive processes; Problem solving; Mathematical model; Concept
              algebra; RTPA;project 1",
  issn     = "1389-0417",
  doi      = "10.1016/j.cogsys.2008.08.003"
}

@ARTICLE{Courville2006-en,
  title    = "Bayesian theories of conditioning in a changing world",
  author   = "Courville, Aaron C and Daw, Nathaniel D and Touretzky, David S",
  abstract = "The recent flowering of Bayesian approaches invites the
              re-examination of classic issues in behavior, even in areas as
              venerable as Pavlovian conditioning. A statistical account can
              offer a new, principled interpretation of behavior, and previous
              experiments and theories can inform many unexplored aspects of
              the Bayesian enterprise. Here we consider one such issue: the
              finding that surprising events provoke animals to learn faster.
              We suggest that, in a statistical account of conditioning,
              surprise signals change and therefore uncertainty and the need
              for new learning. We discuss inference in a world that changes
              and show how experimental results involving surprise can be
              interpreted from this perspective, and also how, thus understood,
              these phenomena help constrain statistical theories of animal and
              human learning.",
  journal  = "Trends Cogn. Sci.",
  volume   =  10,
  number   =  7,
  pages    = "294--300",
  month    =  jul,
  year     =  2006,
  keywords = "skimmed;learning\&memory2023;comp-cog-sci",
  language = "en",
  issn     = "1364-6613",
  pmid     = "16793323",
  doi      = "10.1016/j.tics.2006.05.004"
}

@INCOLLECTION{Daw2014-xf,
  title     = "Chapter 16 - Advanced Reinforcement Learning",
  booktitle = "Neuroeconomics (Second Edition)",
  author    = "Daw, Nathaniel D",
  editor    = "Glimcher, Paul W and Fehr, Ernst",
  abstract  = "This chapter reviews issues of current research in reinforcement
               learning theories and their neural substrates. We consider how
               the formal constructs of states, actions, and rewards that these
               theories describe can be understood to map onto counterparts
               experienced by biological organisms learning in the real world.
               In each case, this correspondence involves significant
               difficulties. However, elaborated theoretical accounts from
               computer science clarify, in each case, how to extend these
               theories to more realistic circumstances while still preserving
               the core prediction error-driven learning mechanism that has
               been prominent in neuroeconomic accounts.",
  publisher = "Academic Press",
  pages     = "299--320",
  month     =  jan,
  year      =  2014,
  address   = "San Diego",
  keywords  = "Dopamine; Hierarchical reinforcement learning; Reinforcement
               learning; Uncertainty;RL;ccm2023",
  isbn      = "9780124160088",
  doi       = "10.1016/B978-0-12-416008-8.00016-4"
}

@ARTICLE{Niv2008-ki,
  title    = "Dialogues on prediction errors",
  author   = "Niv, Yael and Schoenbaum, Geoffrey",
  abstract = "The recognition that computational ideas from reinforcement
              learning are relevant to the study of neural circuits has taken
              the cognitive neuroscience community by storm. A central tenet of
              these models is that discrepancies between actual and expected
              outcomes can be used for learning. Neural correlates of such
              prediction-error signals have been observed now in midbrain
              dopaminergic neurons, striatum, amygdala and even prefrontal
              cortex, and models incorporating prediction errors have been
              invoked to explain complex phenomena such as the transition from
              goal-directed to habitual behavior. Yet, like any revolution, the
              fast-paced progress has left an uneven understanding in its wake.
              Here, we provide answers to ten simple questions about prediction
              errors, with the aim of exposing both the strengths and the
              limitations of this active area of neuroscience research.",
  journal  = "Trends Cogn. Sci.",
  volume   =  12,
  number   =  7,
  pages    = "265--272",
  month    =  jul,
  year     =  2008,
  keywords = "RL;ccm2023",
  language = "en",
  issn     = "1364-6613",
  pmid     = "18567531",
  doi      = "10.1016/j.tics.2008.03.006"
}

@ARTICLE{Daw2006-xl,
  title    = "Cortical substrates for exploratory decisions in humans",
  author   = "Daw, Nathaniel D and O'Doherty, John P and Dayan, Peter and
              Seymour, Ben and Dolan, Raymond J",
  abstract = "Decision making in an uncertain environment poses a conflict
              between the opposing demands of gathering and exploiting
              information. In a classic illustration of this
              'exploration-exploitation' dilemma, a gambler choosing between
              multiple slot machines balances the desire to select what seems,
              on the basis of accumulated experience, the richest option,
              against the desire to choose a less familiar option that might
              turn out more advantageous (and thereby provide information for
              improving future decisions). Far from representing idle
              curiosity, such exploration is often critical for organisms to
              discover how best to harvest resources such as food and water. In
              appetitive choice, substantial experimental evidence, underpinned
              by computational reinforcement learning (RL) theory, indicates
              that a dopaminergic, striatal and medial prefrontal network
              mediates learning to exploit. In contrast, although exploration
              has been well studied from both theoretical and ethological
              perspectives, its neural substrates are much less clear. Here we
              show, in a gambling task, that human subjects' choices can be
              characterized by a computationally well-regarded strategy for
              addressing the explore/exploit dilemma. Furthermore, using this
              characterization to classify decisions as exploratory or
              exploitative, we employ functional magnetic resonance imaging to
              show that the frontopolar cortex and intraparietal sulcus are
              preferentially active during exploratory decisions. In contrast,
              regions of striatum and ventromedial prefrontal cortex exhibit
              activity characteristic of an involvement in value-based
              exploitative decision making. The results suggest a model of
              action selection under uncertainty that involves switching
              between exploratory and exploitative behavioural modes, and
              provide a computationally precise characterization of the
              contribution of key decision-related brain systems to each of
              these functions.",
  journal  = "Nature",
  volume   =  441,
  number   =  7095,
  pages    = "876--879",
  month    =  jun,
  year     =  2006,
  keywords = "RL;ccm2023",
  language = "en",
  issn     = "0028-0836, 1476-4687",
  pmid     = "16778890",
  doi      = "10.1038/nature04766",
  pmc      = "PMC2635947"
}

@ARTICLE{Sutton1988-ad,
  title     = "Learning to predict by the methods of temporal differences",
  author    = "Sutton, Richard S",
  abstract  = "This article introduces a class of incremental learning
               procedures specialized for prediction-that is, for using past
               experience with an incompletely known system to predict its
               future behavior. Whereas conventional prediction-learning
               methods assign credit by means of the difference between
               predicted and actual outcomes, the new methods assign credit by
               means of the difference between temporally successive
               predictions. Although such temporal-difference methods have been
               used in Samuel's checker player, Holland's bucket brigade, and
               the author's Adaptive Heuristic Critic, they have remained
               poorly understood. Here we prove their convergence and
               optimality for special cases and relate them to
               supervised-learning methods. For most real-world prediction
               problems, temporal-difference methods require less memory and
               less peak computation than conventional methods and they produce
               more accurate predictions. We argue that most problems to which
               supervised learning is currently applied are really prediction
               problems of the sort to which temporal-difference methods can be
               applied to advantage.",
  journal   = "Mach. Learn.",
  publisher = "Springer",
  volume    =  3,
  number    =  1,
  pages     = "9--44",
  month     =  aug,
  year      =  1988,
  keywords  = "RL;ccm2023",
  issn      = "0885-6125, 1573-0565",
  doi       = "10.1007/BF00115009"
}

@ARTICLE{Hinton2022-lf,
  title         = "The {Forward-Forward} Algorithm: Some Preliminary
                   Investigations",
  author        = "Hinton, Geoffrey",
  abstract      = "The aim of this paper is to introduce a new learning
                   procedure for neural networks and to demonstrate that it
                   works well enough on a few small problems to be worth
                   further investigation. The Forward-Forward algorithm
                   replaces the forward and backward passes of backpropagation
                   by two forward passes, one with positive (i.e. real) data
                   and the other with negative data which could be generated by
                   the network itself. Each layer has its own objective
                   function which is simply to have high goodness for positive
                   data and low goodness for negative data. The sum of the
                   squared activities in a layer can be used as the goodness
                   but there are many other possibilities, including minus the
                   sum of the squared activities. If the positive and negative
                   passes could be separated in time, the negative passes could
                   be done offline, which would make the learning much simpler
                   in the positive pass and allow video to be pipelined through
                   the network without ever storing activities or stopping to
                   propagate derivatives.",
  month         =  dec,
  year          =  2022,
  keywords      = "machine-learning",
  archivePrefix = "arXiv",
  eprint        = "2212.13345",
  primaryClass  = "cs.LG",
  arxivid       = "2212.13345"
}

@ARTICLE{Batchelder2012-xv,
  title    = "Insight Problem Solving: A Critical Examination of the
              Possibility of Formal Theory",
  author   = "Batchelder, William H and Alexander, Gregory E",
  abstract = "This paper provides a critical examination of the current state
              and future possibility of formal cognitive theory for insight
              problem solving and its associated ``aha!'' experience. Insight
              problems are contrasted with move problems, which have been
              formally defined and studied extensively by cognitive
              psychologists since the pioneering work of Alan Newell and
              Herbert Simon. To facilitate our discussion, a number of
              classical brainteasers are presented along with their solutions
              and some conclusions derived from observing the behavior of many
              students trying to solve them. Some of these problems are
              interesting in their own right, and many of them have not been
              discussed before in the psychological literature. The main
              purpose of presenting the brainteasers is to assist in discussing
              the status of formal cognitive theory for insight problem
              solving, which is argued to be considerably weaker than that
              found in other areas of higher cognition such as human memory,
              decision-making, categorization, and perception. We discuss
              theoretical barriers that have plagued the development of
              successful formal theory for insight problem solving. A few
              suggestions are made that might serve to advance the field.",
  journal  = "The Journal of Problem Solving",
  volume   =  5,
  number   =  1,
  pages    = "6",
  year     =  2012,
  issn     = "1932-6246",
  doi      = "10.7771/1932-6246.1143"
}
